{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Tensorflow Lite](https://www.tensorflow.org/lite/images/convert/workflow.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic Requirement: tensorflow version >= 1.9.0**\n",
    "\n",
    "* `tf.contrib.lite.TFLiteConverter`: convert tensorflow models to tensor flow lite\n",
    "    * `TFLiteConverter` provides class methods based on the original format of the model.\n",
    "    * `TFLiteConverter.from_session()` is available for GraphDefs.\n",
    "    * `TFLiteConverter.from_saved_model()` is available for SavedModels.\n",
    "    * `TFLiteConverter.from_keras_model_file()` is available for `tf.Keras` files.\n",
    "* `tf.contrib.lite.Interpreter`: calling Python interpreter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting a GraphDef from tf.Session\n",
    "\n",
    "Convert a Tensorflow GraphDef into a Tensorflow Lite Flatbuffer from a `tf.Session` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf_nightly in /anaconda3/lib/python3.6/site-packages (1.13.0.dev20181101)\n",
      "Requirement already satisfied: tb-nightly<1.14.0a0,>=1.13.0a0 in /anaconda3/lib/python3.6/site-packages (from tf_nightly) (1.13.0a20181101)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /anaconda3/lib/python3.6/site-packages (from tf_nightly) (3.6.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /anaconda3/lib/python3.6/site-packages (from tf_nightly) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /anaconda3/lib/python3.6/site-packages (from tf_nightly) (0.5.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /anaconda3/lib/python3.6/site-packages (from tf_nightly) (0.32.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /anaconda3/lib/python3.6/site-packages (from tf_nightly) (1.14.3)\n",
      "Requirement already satisfied: gast>=0.2.0 in /anaconda3/lib/python3.6/site-packages (from tf_nightly) (0.2.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /anaconda3/lib/python3.6/site-packages (from tf_nightly) (1.15.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /anaconda3/lib/python3.6/site-packages (from tf_nightly) (1.0.6)\n",
      "Requirement already satisfied: tensorflow-estimator>=1.10.0 in /anaconda3/lib/python3.6/site-packages (from tf_nightly) (1.10.12)\n",
      "Requirement already satisfied: six>=1.10.0 in /anaconda3/lib/python3.6/site-packages (from tf_nightly) (1.11.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /anaconda3/lib/python3.6/site-packages (from tf_nightly) (0.7.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /anaconda3/lib/python3.6/site-packages (from tf_nightly) (1.0.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /anaconda3/lib/python3.6/site-packages (from tb-nightly<1.14.0a0,>=1.13.0a0->tf_nightly) (3.0.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /anaconda3/lib/python3.6/site-packages (from tb-nightly<1.14.0a0,>=1.13.0a0->tf_nightly) (0.14.1)\n",
      "Requirement already satisfied: setuptools in /anaconda3/lib/python3.6/site-packages (from protobuf>=3.6.1->tf_nightly) (39.1.0)\n",
      "Requirement already satisfied: h5py in /anaconda3/lib/python3.6/site-packages (from keras-applications>=1.0.6->tf_nightly) (2.7.1)\n",
      "Requirement already satisfied: mock>=2.0.0 in /anaconda3/lib/python3.6/site-packages (from tensorflow-estimator>=1.10.0->tf_nightly) (2.0.0)\n",
      "Requirement already satisfied: pbr>=0.11 in /anaconda3/lib/python3.6/site-packages (from mock>=2.0.0->tensorflow-estimator>=1.10.0->tf_nightly) (5.1.0)\n",
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# if you encounter module 'tensorflow.contrib.lite.python.lite' has no attribute 'TFLiteConverter'\n",
    "!pip install tf_nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def sessionExport():\n",
    "    img = tf.placeholder(name=\"img\", dtype=tf.float32, shape=(1, 64, 64, 3))\n",
    "    var = tf.get_variable(\"weights\", dtype=tf.float32, shape=(1, 64, 64, 3))\n",
    "    val = img + var\n",
    "    out = tf.identity(val, name=\"out\")\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        converter = tf.contrib.lite.TFLiteConverter.from_session(sess, [img], [out])\n",
    "        tflite_model = converter.convert()\n",
    "        open(\"converted_model.tflite\", \"wb\").write(tflite_model)\n",
    "        \n",
    "#sessionExport()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting a GraphDef from file\n",
    "\n",
    "Convert a Tensorflow GraphDef stored in a file (`.pb` or `.pbtxt`) into Tensorflow Lite FlatBuffer.\n",
    "\n",
    "You can download a frozen example model from \n",
    "https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_1.0_224_frozen.tgz\n",
    "\n",
    "if you prepare the your own model, please make sure using [freeze_graph.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py) to freeze the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def frozenExport():\n",
    "    graph_def_file = \"./mobilenet_v1_1.0_224/frozen_graph.pb\"\n",
    "    input_arrays = [\"input\"]\n",
    "    output_arrays = [\"MobilenetV1/Predictions/Softmax\"]\n",
    "\n",
    "    converter = tf.contrib.lite.TFLiteConverter.from_frozen_graph(graph_def_file, input_arrays, output_arrays)\n",
    "    tflite_model = converter.convert()\n",
    "    open(\"converted_model.tflite\", \"wb\").write(tflite_model)\n",
    "    \n",
    "#frozenExport()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting a SavedModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SaveModel` is the checkpoint-based way to conserve the model. Usually it is the folder conversing a checkpoint, and lots of `.ckpt` or `ckpt-{epoch}` style filename of files.\n",
    "\n",
    "For more complex SavedModels, the optional parameters that can be passed into `TFLiteConverter.from_saved_model()` are `input_arrays`, `input_shapes`, `output_arrays`, `tag_set` and `signature_key`. Details of each parameter are available by running `help(tf.contrib.lite.TFLiteConverter)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def ckptExport():\n",
    "    converter = tf.contrib.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "    tflite_model = converter.convert()\n",
    "    open(\"converted_model.tflite\", \"wb\").write(tflite_model)\n",
    "\n",
    "#ckptExport()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export a tf.keras file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in /anaconda3/lib/python3.6/site-packages (2.7.1)\n",
      "Requirement already satisfied: numpy>=1.7 in /anaconda3/lib/python3.6/site-packages (from h5py) (1.14.3)\n",
      "Requirement already satisfied: six in /anaconda3/lib/python3.6/site-packages (from h5py) (1.11.0)\n",
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# make sure you have installed h5py\n",
    "!pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def h5Export():\n",
    "    converter = tf.contrib.lite.TFLiteConverter.from_keras_model_file(\"keras_model.h5\")\n",
    "    tflite_model = converter.convert()\n",
    "    open(\"converted_model.tflite\", \"wb\").write(tflite_model)\n",
    "    \n",
    "#h5Export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export a tf.keras network\n",
    "\n",
    "You have to export the `.h5` file first and then convert it into tensorflow lite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def kerasExport():\n",
    "    # Generate tf.keras model.\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(2, input_shape=(3,)))\n",
    "    model.add(tf.keras.layers.RepeatVector(3))\n",
    "    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(3)))\n",
    "    model.compile(loss=tf.keras.losses.MSE,\n",
    "                  optimizer=tf.keras.optimizers.RMSprop(lr=0.0001),\n",
    "                  metrics=[tf.keras.metrics.categorical_accuracy],\n",
    "                  sample_weight_mode='temporal')\n",
    "\n",
    "    x = np.random.random((1, 3))\n",
    "    y = np.random.random((1, 3, 3))\n",
    "    model.train_on_batch(x, y)\n",
    "    model.predict(x)\n",
    "\n",
    "    # Save tf.keras model in HDF5 format.\n",
    "    keras_file = \"keras_model.h5\"\n",
    "    tf.keras.models.save_model(model, keras_file)\n",
    "\n",
    "    # Convert to TensorFlow Lite model.\n",
    "    converter = tf.contrib.lite.TFLiteConverter.from_keras_model_file(keras_file)\n",
    "    tflite_model = converter.convert()\n",
    "    open(\"converted_model.tflite\", \"wb\").write(tflite_model)\n",
    "\n",
    "#kerasExport()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adcanced Converting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantized GraphDef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def quantExport():\n",
    "    img = tf.placeholder(name=\"img\", dtype=tf.float32, shape=(1, 64, 64, 3))\n",
    "    const = tf.constant([1., 2., 3.]) + tf.constant([1., 4., 4.])\n",
    "    val = img + const\n",
    "    out = tf.fake_quant_with_min_max_args(val, min=0., max=1., name=\"output\")\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        converter = tf.contrib.lite.TFLiteConverter.from_session(sess, [img], [out])\n",
    "        # you have to transform int into QUANTIZED_UINT8 before exporting\n",
    "        converter.inference_type = tf.contrib.lite.constants.QUANTIZED_UINT8\n",
    "        input_arrays = converter.get_input_arrays()\n",
    "        converter.quantized_input_stats = {input_arrays[0] : (0., 1.)}  # mean, std_dev\n",
    "        tflite_model = converter.convert()\n",
    "        open(\"converted_model.tflite\", \"wb\").write(tflite_model)\n",
    "        \n",
    "#quantExport()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Lite Python Interpreter\n",
    "\n",
    "## Load and use a `.tflite` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1 224 224   3]\n",
      "[   1 1001]\n",
      "[311]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "def tfLitePyInterpreter(tflitefile):\n",
    "    # Load TFLite model and allocate tensors.\n",
    "    interpreter = tf.contrib.lite.Interpreter(model_path=tflitefile)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    # Get input and output tensors.\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    # Test model on random input data.\n",
    "    input_shape = input_details[0]['shape']\n",
    "    input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    print(input_shape)\n",
    "    print(output_details[0]['shape'])\n",
    "\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    print(np.argmax(output_data, 1))\n",
    "    \n",
    "tflitefile = os.path.join(\"/Users/jiankaiwang/Google_Drive_Devops_Sync/sophia/tmp/converted_model.tflite\")\n",
    "assert os.path.exists(tflitefile), \"no such tflite file\"\n",
    "tfLitePyInterpreter(tflitefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
