{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello world, Deep Learning and Tensorflow!'\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "dl = tf.constant('Hello world, Deep Learning and Tensorflow!')\n",
    "val1 = tf.constant(2)\n",
    "val2 = tf.constant(3)\n",
    "mul_val = tf.multiply(val1, val2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(dl))\n",
    "    print(sess.run(mul_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor vs. Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor is different from variable. Tensor is active data flow between the layers in neural network and it vanishs after sesson finish. Variable can be preserved among different sessions, it can be updated during training, it can be kept storing in memory and it can be stored after learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Others tensors to initialize the tf.variables\n",
    "tf.zeros()\n",
    "tf.ones()\n",
    "tf.random_normal()\n",
    "tf.truncated_normal()\n",
    "tf.random_uniform()\n",
    "\"\"\"\n",
    "weights = tf.Variable(tf.random_normal([300,200], stddev=0.5), name=\"weights\", trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requires `tf.initialize_all_variables()` or `tf.initialize_variables(var1, var2, var3, ...)` to initialize tensors in variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operations in Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations in tensorflow represent to transform tensor.\n",
    "\n",
    "| Class | Examples |\n",
    "|--|--|\n",
    "| Element-based Calculation | Add, Sub, Mul, Div, Exp, Log, Equal, ... |\n",
    "| Array Operation | Concat, Slice, Split, Constant, Rank, Shape, Shuffle, ... |\n",
    "| Matrix Operation | MatMul, MatrixInverse, MatrixDeterminant, ... |\n",
    "| Status Operation | Variable, Assign, AssignAdd, ... |\n",
    "| Neural Network Construction | Softmax, Sigmoid, ReLu, Convolutional2D, Maxpool, ... |\n",
    "| Checkpoint Operation | Save, Restore, ... |\n",
    "| Queue, Sync Operation | Enqueue, Dequeue, MutexAcquire, MutexRelease, ... |\n",
    "| Flow Control | Merge, Switch, Enter, Leave, NextIteration, ... |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placeholder is the data entry point (tensor) to neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, name=\"x\", shape=[None, 784])   # None can be any size in minibatch\n",
    "W = tf.Variable(tf.random_uniform([784,10], minval=-1, maxval=1), name=\"W\")\n",
    "multiply_val = tf.matmul(x, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session in Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tensor(Data/Operations), Variables(Weights) and Graphs(Nerual Network) are executed in session.\n",
    "* All operations listed above, including initialization, are working in session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import tensorflow as tf\n",
    "from read_data import get_minibatch\n",
    "\n",
    "# simple neural network\n",
    "x = tf.placeholder(tf.float32, name=\"x\", shape=[None, 784])   # None can be any size in minibatch\n",
    "W = tf.Variable(tf.random_uniform([784,10], minval=-1, maxval=1), name=\"W\")\n",
    "b = tf.Variable(tf.zeros([10]), name=\"biases\")\n",
    "output = tf.matmul(x, W) + b\n",
    "\n",
    "# initialization\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# start the session\n",
    "with tf.Session() as sess:\n",
    "    # initialize all variables at the beginning\n",
    "    sess.run(init)\n",
    "    \n",
    "    # use feed_dict to fill the data into placeholder\n",
    "    # and calculate around the whole graph\n",
    "    feed_dict_data = {\"x\": get_minibatch()}\n",
    "    sess.run(output, feed_dict = feed_dict_data)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scope in Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use `tf.get_variable()` instead of `tf.Variable()` to check whether the variable is initialized already, if it is not, tensorflow would initialize the variable as the same with `tf.Variable()`.\n",
    "\n",
    "* Use `tf.variable_scope()` as `scope` and script `scope.reuse_variables()` to allow reusing shared variables among minibatch training. (For the sake of information security, tensorflow is not allowed to shared variables by default.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better Variable Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(input, weight_shape, bias_shape):\n",
    "    weight_init = tf.random_uniform_initializer(minval=-1, maxval=1)\n",
    "    bias_init = tf.constant_initializer(value=0)\n",
    "    W = tf.get_variable(\"W\", shape=weight_shape, initializer=weight_init)\n",
    "    b = tf.get_variable(\"b\", shape=bias_shape, initializer=bias_init)\n",
    "    return tf.matmul(input, W) + b\n",
    "\n",
    "def network(input):\n",
    "    \"\"\"\n",
    "    A four-layer neural network example \n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope(\"layer_1\"):\n",
    "        output_1 = layer(input, [784,100], [100])\n",
    "    \n",
    "    with tf.variable_scope(\"layer_2\"):\n",
    "        output_2 = layer(output_1, [100, 50], [50])\n",
    "        \n",
    "    with tf.variable_scope(\"layer_3\"):\n",
    "        output_3 = layer(output_2, [50, 10], [10])\n",
    "        \n",
    "    return output_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"shared_variables\") as scope:\n",
    "    i_1 = tf.placeholder(tf.float32, [1000, 784], name=\"i_1\")\n",
    "    network(i_1)\n",
    "    \n",
    "    # you should add the script to allow sharing variables\n",
    "    scope.reuse_variables()\n",
    "    \n",
    "    i_2 = tf.placeholder(tf.float32, [1000, 784], name=\"i_2\")\n",
    "    network(i_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use CPU / GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "# use the first CPU\n",
    "/cpu:0\n",
    "\n",
    "# use the first gpu\n",
    "/gpu:0\n",
    "\n",
    "# use the second gpu\n",
    "/gpu:1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 7154796531582009912]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check supported devices\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-10.]\n",
      " [-10.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:1'):\n",
    "    \n",
    "    # use tf.device() to assign the computing resource\n",
    "    a = tf.constant([1., 2., 3., 4.], shape=[2,2], name='a')\n",
    "    b = tf.constant([10., -10.], shape=[2,1], name='b')\n",
    "    c = tf.matmul(a, b)\n",
    "    \n",
    "    # allow_soft_placement: if device is not available to use, we allow tensorflow to change CPU or GPU:0, ...\n",
    "    # log_device_placement: record which devices we use\n",
    "    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "        print(sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tower-like fashion way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-20.]\n",
      " [-20.]]\n"
     ]
    }
   ],
   "source": [
    "c = []\n",
    "\n",
    "for d in ['/gpu:0', '/gpu:1']:\n",
    "    with tf.device(d):\n",
    "        a = tf.constant([1., 2., 3., 4.], shape=[2,2], name='a')\n",
    "        b = tf.constant([10., -10.], shape=[2,1], name='b')\n",
    "        c.append(tf.matmul(a,b))\n",
    "        \n",
    "with tf.device('/cpu:0'):\n",
    "    sumAll = tf.add_n(c)\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "    print(sess.run(sumAll))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_inference(x):\n",
    "    init = tf.constant_initializer(value=0)\n",
    "    W = tf.get_variable(name=\"W\", shape=[784,10], initializer=init)\n",
    "    b = tf.get_variable(name=\"b\", shape=[10], initializer=init)\n",
    "    output = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(input, weight_shape, bias_shape):\n",
    "    weight_std = (2.0 / weight_shape[0]) ** 0.5\n",
    "    w_init = tf.random_normal_initializer(stddev=weight_std)\n",
    "    b_init = tf.constant_initializer(value=0)\n",
    "    W = tf.get_variable(name=\"W\", shape=weight_shape, initializer=w_init)\n",
    "    b = tf.get_variable(name=\"b\", shape=bias_shape, initializer=b_init)\n",
    "    return tf.nn.relu(tf.matmul(input, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(x):\n",
    "    with tf.variable_scope(\"hidden_1\"):\n",
    "        hidden_1 = layer(x, [784, 256], [256])\n",
    "        \n",
    "    with tf.variable_scope(\"hidden_2\"):\n",
    "        hidden_2 = layer(hidden_1, [256, 256], [256])\n",
    "    \n",
    "    with tf.variable_scope(\"output\"):\n",
    "        output = layer(hidden_2, [256, 10], [10])\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_loss(output, y):\n",
    "    product = y * tf.log(output)\n",
    "    # 0: column, 1: row\n",
    "    cross_entropy = -tf.reduce_sum(product, reduction_indices=1)\n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(output, y):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=output, labels=y)\n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(cost, global_step):\n",
    "    tf.summary.scalar(\"cost\", cost)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    train_opt = optimizer.minimize(cost, global_step=global_step)\n",
    "    return train_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(output, y, name):\n",
    "    compare = tf.equal(tf.argmax(output, axis=1), tf.argmax(y, axis=1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(compare, tf.float32))\n",
    "    tf.summary.scalar(\"eval/{}\".format(str(name)), accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_training = True\n",
    "learning_rate = 1e-2\n",
    "training_epochs = 1000 if full_training else 1\n",
    "batch_size = 100 if full_training else 1000\n",
    "display_step = 1000 if full_training else 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-c6e8dc1cf347>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /Users/jiankaiwang/Desktop/devops/tmp/MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /Users/jiankaiwang/Desktop/devops/tmp/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /Users/jiankaiwang/Desktop/devops/tmp/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/jiankaiwang/Desktop/devops/tmp/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# uncomment the below line to download the data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/Users/jiankaiwang/Desktop/devops/tmp/MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1198 Vaildation Error: 0.8801999986171722\n",
      "Accuracy: 0.1252 Vaildation Error: 0.8747999966144562\n",
      "Accuracy: 0.1322 Vaildation Error: 0.8677999973297119\n",
      "Accuracy: 0.1386 Vaildation Error: 0.8613999933004379\n",
      "Accuracy: 0.142 Vaildation Error: 0.8579999953508377\n",
      "Accuracy: 0.1534 Vaildation Error: 0.8465999960899353\n",
      "Accuracy: 0.164 Vaildation Error: 0.835999995470047\n",
      "Accuracy: 0.171 Vaildation Error: 0.8289999961853027\n",
      "Accuracy: 0.1826 Vaildation Error: 0.8173999935388565\n",
      "Accuracy: 0.1906 Vaildation Error: 0.8094000071287155\n",
      "Accuracy: 0.1982 Vaildation Error: 0.8017999976873398\n",
      "Accuracy: 0.2046 Vaildation Error: 0.7953999936580658\n",
      "Accuracy: 0.2114 Vaildation Error: 0.7885999977588654\n",
      "Accuracy: 0.2192 Vaildation Error: 0.780799999833107\n",
      "Accuracy: 0.221 Vaildation Error: 0.778999999165535\n",
      "Accuracy: 0.226 Vaildation Error: 0.7740000039339066\n",
      "Accuracy: 0.2314 Vaildation Error: 0.7686000019311905\n",
      "Accuracy: 0.2362 Vaildation Error: 0.7637999951839447\n",
      "Accuracy: 0.241 Vaildation Error: 0.7590000033378601\n",
      "Accuracy: 0.2442 Vaildation Error: 0.7557999938726425\n",
      "Accuracy: 0.247 Vaildation Error: 0.7530000060796738\n",
      "Accuracy: 0.248 Vaildation Error: 0.7520000040531158\n",
      "Accuracy: 0.2524 Vaildation Error: 0.7475999891757965\n",
      "Accuracy: 0.2528 Vaildation Error: 0.7472000122070312\n",
      "Accuracy: 0.255 Vaildation Error: 0.7450000047683716\n",
      "Accuracy: 0.2596 Vaildation Error: 0.7403999865055084\n",
      "Accuracy: 0.2618 Vaildation Error: 0.7382000088691711\n",
      "Accuracy: 0.2632 Vaildation Error: 0.7367999851703644\n",
      "Accuracy: 0.265 Vaildation Error: 0.7350000143051147\n",
      "Accuracy: 0.2674 Vaildation Error: 0.7326000034809113\n",
      "Accuracy: 0.2712 Vaildation Error: 0.7287999987602234\n",
      "Accuracy: 0.271 Vaildation Error: 0.7290000021457672\n",
      "Accuracy: 0.2738 Vaildation Error: 0.7262000143527985\n",
      "Accuracy: 0.273 Vaildation Error: 0.7269999980926514\n",
      "Accuracy: 0.2738 Vaildation Error: 0.7262000143527985\n",
      "Accuracy: 0.2774 Vaildation Error: 0.7226000130176544\n",
      "Accuracy: 0.2778 Vaildation Error: 0.7222000062465668\n",
      "Accuracy: 0.2772 Vaildation Error: 0.7227999866008759\n",
      "Accuracy: 0.2788 Vaildation Error: 0.7211999893188477\n",
      "Accuracy: 0.2802 Vaildation Error: 0.7197999954223633\n",
      "Accuracy: 0.2816 Vaildation Error: 0.7184000015258789\n",
      "Accuracy: 0.282 Vaildation Error: 0.7179999947547913\n",
      "Accuracy: 0.287 Vaildation Error: 0.7129999995231628\n",
      "Accuracy: 0.2868 Vaildation Error: 0.7132000029087067\n",
      "Accuracy: 0.2872 Vaildation Error: 0.712799996137619\n",
      "Accuracy: 0.293 Vaildation Error: 0.7069999873638153\n",
      "Accuracy: 0.298 Vaildation Error: 0.7019999921321869\n",
      "Accuracy: 0.2958 Vaildation Error: 0.7041999995708466\n",
      "Accuracy: 0.3016 Vaildation Error: 0.6983999907970428\n",
      "Accuracy: 0.3042 Vaildation Error: 0.6958000063896179\n",
      "Accuracy: 0.3062 Vaildation Error: 0.6938000023365021\n",
      "Accuracy: 0.309 Vaildation Error: 0.6910000145435333\n",
      "Accuracy: 0.3068 Vaildation Error: 0.6931999921798706\n",
      "Accuracy: 0.308 Vaildation Error: 0.69200000166893\n",
      "Accuracy: 0.311 Vaildation Error: 0.6890000104904175\n",
      "Accuracy: 0.3098 Vaildation Error: 0.690200001001358\n",
      "Accuracy: 0.3114 Vaildation Error: 0.6886000037193298\n",
      "Accuracy: 0.312 Vaildation Error: 0.6879999935626984\n",
      "Accuracy: 0.3102 Vaildation Error: 0.6897999942302704\n",
      "Accuracy: 0.3074 Vaildation Error: 0.6926000118255615\n",
      "Accuracy: 0.3076 Vaildation Error: 0.6924000084400177\n",
      "Accuracy: 0.3094 Vaildation Error: 0.6906000077724457\n",
      "Accuracy: 0.312 Vaildation Error: 0.6879999935626984\n",
      "Accuracy: 0.3122 Vaildation Error: 0.6877999901771545\n",
      "Accuracy: 0.3138 Vaildation Error: 0.6861999928951263\n",
      "Accuracy: 0.316 Vaildation Error: 0.6839999854564667\n",
      "Accuracy: 0.3182 Vaildation Error: 0.6818000078201294\n",
      "Accuracy: 0.3196 Vaildation Error: 0.680400013923645\n",
      "Accuracy: 0.3208 Vaildation Error: 0.6791999936103821\n",
      "Accuracy: 0.3228 Vaildation Error: 0.6771999895572662\n",
      "Accuracy: 0.3222 Vaildation Error: 0.6777999997138977\n",
      "Accuracy: 0.321 Vaildation Error: 0.6789999902248383\n",
      "Accuracy: 0.3224 Vaildation Error: 0.6775999963283539\n",
      "Accuracy: 0.3238 Vaildation Error: 0.6762000024318695\n",
      "Accuracy: 0.3234 Vaildation Error: 0.6766000092029572\n",
      "Accuracy: 0.3248 Vaildation Error: 0.6751999855041504\n",
      "Accuracy: 0.3262 Vaildation Error: 0.673799991607666\n",
      "Accuracy: 0.3288 Vaildation Error: 0.6712000072002411\n",
      "Accuracy: 0.3334 Vaildation Error: 0.6665999889373779\n",
      "Accuracy: 0.335 Vaildation Error: 0.6649999916553497\n",
      "Accuracy: 0.3368 Vaildation Error: 0.6631999909877777\n",
      "Accuracy: 0.34 Vaildation Error: 0.6599999964237213\n",
      "Accuracy: 0.342 Vaildation Error: 0.6579999923706055\n",
      "Accuracy: 0.3452 Vaildation Error: 0.6547999978065491\n",
      "Accuracy: 0.3444 Vaildation Error: 0.6556000113487244\n",
      "Accuracy: 0.3458 Vaildation Error: 0.6541999876499176\n",
      "Accuracy: 0.3454 Vaildation Error: 0.6545999944210052\n",
      "Accuracy: 0.3432 Vaildation Error: 0.6568000018596649\n",
      "Accuracy: 0.3434 Vaildation Error: 0.6565999984741211\n",
      "Accuracy: 0.3418 Vaildation Error: 0.6581999957561493\n",
      "Accuracy: 0.3416 Vaildation Error: 0.6583999991416931\n",
      "Accuracy: 0.3396 Vaildation Error: 0.660400003194809\n",
      "Accuracy: 0.3388 Vaildation Error: 0.6611999869346619\n",
      "Accuracy: 0.3394 Vaildation Error: 0.6606000065803528\n",
      "Accuracy: 0.3402 Vaildation Error: 0.6597999930381775\n",
      "Accuracy: 0.3432 Vaildation Error: 0.6568000018596649\n",
      "Accuracy: 0.346 Vaildation Error: 0.6540000140666962\n",
      "Accuracy: 0.3448 Vaildation Error: 0.6552000045776367\n",
      "Accuracy: 0.347 Vaildation Error: 0.652999997138977\n",
      "Accuracy: 0.348 Vaildation Error: 0.6520000100135803\n",
      "Accuracy: 0.3514 Vaildation Error: 0.6486000120639801\n",
      "Accuracy: 0.3544 Vaildation Error: 0.6455999910831451\n",
      "Accuracy: 0.3564 Vaildation Error: 0.6435999870300293\n",
      "Accuracy: 0.3588 Vaildation Error: 0.6412000060081482\n",
      "Accuracy: 0.362 Vaildation Error: 0.6380000114440918\n",
      "Accuracy: 0.362 Vaildation Error: 0.6380000114440918\n",
      "Accuracy: 0.3616 Vaildation Error: 0.6383999884128571\n",
      "Accuracy: 0.3608 Vaildation Error: 0.6392000019550323\n",
      "Accuracy: 0.3626 Vaildation Error: 0.6374000012874603\n",
      "Accuracy: 0.3644 Vaildation Error: 0.6356000006198883\n",
      "Accuracy: 0.3644 Vaildation Error: 0.6356000006198883\n",
      "Accuracy: 0.3656 Vaildation Error: 0.6344000101089478\n",
      "Accuracy: 0.3652 Vaildation Error: 0.634799987077713\n",
      "Accuracy: 0.367 Vaildation Error: 0.632999986410141\n",
      "Accuracy: 0.3662 Vaildation Error: 0.6337999999523163\n",
      "Accuracy: 0.3656 Vaildation Error: 0.6344000101089478\n",
      "Accuracy: 0.3654 Vaildation Error: 0.6346000134944916\n",
      "Accuracy: 0.3652 Vaildation Error: 0.634799987077713\n",
      "Accuracy: 0.3662 Vaildation Error: 0.6337999999523163\n",
      "Accuracy: 0.3668 Vaildation Error: 0.6331999897956848\n",
      "Accuracy: 0.3688 Vaildation Error: 0.631199985742569\n",
      "Accuracy: 0.3702 Vaildation Error: 0.6297999918460846\n",
      "Accuracy: 0.3698 Vaildation Error: 0.6301999986171722\n",
      "Accuracy: 0.3722 Vaildation Error: 0.6277999877929688\n",
      "Accuracy: 0.3712 Vaildation Error: 0.6288000047206879\n",
      "Accuracy: 0.3714 Vaildation Error: 0.628600001335144\n",
      "Accuracy: 0.3742 Vaildation Error: 0.6258000135421753\n",
      "Accuracy: 0.3782 Vaildation Error: 0.6218000054359436\n",
      "Accuracy: 0.3756 Vaildation Error: 0.6243999898433685\n",
      "Accuracy: 0.3774 Vaildation Error: 0.6225999891757965\n",
      "Accuracy: 0.3798 Vaildation Error: 0.6202000081539154\n",
      "Accuracy: 0.3798 Vaildation Error: 0.6202000081539154\n",
      "Accuracy: 0.3816 Vaildation Error: 0.6184000074863434\n",
      "Accuracy: 0.379 Vaildation Error: 0.6209999918937683\n",
      "Accuracy: 0.3824 Vaildation Error: 0.6175999939441681\n",
      "Accuracy: 0.3834 Vaildation Error: 0.6166000068187714\n",
      "Accuracy: 0.3862 Vaildation Error: 0.6137999892234802\n",
      "Accuracy: 0.3864 Vaildation Error: 0.6135999858379364\n",
      "Accuracy: 0.3886 Vaildation Error: 0.6114000082015991\n",
      "Accuracy: 0.3906 Vaildation Error: 0.6094000041484833\n",
      "Accuracy: 0.3926 Vaildation Error: 0.6074000000953674\n",
      "Accuracy: 0.3988 Vaildation Error: 0.6012000143527985\n",
      "Accuracy: 0.3966 Vaildation Error: 0.6033999919891357\n",
      "Accuracy: 0.4 Vaildation Error: 0.5999999940395355\n",
      "Accuracy: 0.406 Vaildation Error: 0.5940000116825104\n",
      "Accuracy: 0.4062 Vaildation Error: 0.5938000082969666\n",
      "Accuracy: 0.4088 Vaildation Error: 0.5911999940872192\n",
      "Accuracy: 0.4108 Vaildation Error: 0.5891999900341034\n",
      "Accuracy: 0.4086 Vaildation Error: 0.5913999974727631\n",
      "Accuracy: 0.41 Vaildation Error: 0.5900000035762787\n",
      "Accuracy: 0.4146 Vaildation Error: 0.5853999853134155\n",
      "Accuracy: 0.4174 Vaildation Error: 0.5825999975204468\n",
      "Accuracy: 0.418 Vaildation Error: 0.5819999873638153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4238 Vaildation Error: 0.576200008392334\n",
      "Accuracy: 0.4278 Vaildation Error: 0.5722000002861023\n",
      "Accuracy: 0.4324 Vaildation Error: 0.5676000118255615\n",
      "Accuracy: 0.4384 Vaildation Error: 0.561599999666214\n",
      "Accuracy: 0.4416 Vaildation Error: 0.5584000051021576\n",
      "Accuracy: 0.4416 Vaildation Error: 0.5584000051021576\n",
      "Accuracy: 0.4416 Vaildation Error: 0.5584000051021576\n",
      "Accuracy: 0.4424 Vaildation Error: 0.5575999915599823\n",
      "Accuracy: 0.4464 Vaildation Error: 0.553600013256073\n",
      "Accuracy: 0.4508 Vaildation Error: 0.5491999983787537\n",
      "Accuracy: 0.4534 Vaildation Error: 0.5466000139713287\n",
      "Accuracy: 0.4514 Vaildation Error: 0.5485999882221222\n",
      "Accuracy: 0.4548 Vaildation Error: 0.545199990272522\n",
      "Accuracy: 0.4546 Vaildation Error: 0.5453999936580658\n",
      "Accuracy: 0.4586 Vaildation Error: 0.5413999855518341\n",
      "Accuracy: 0.4626 Vaildation Error: 0.5374000072479248\n",
      "Accuracy: 0.4618 Vaildation Error: 0.5381999909877777\n",
      "Accuracy: 0.4638 Vaildation Error: 0.5361999869346619\n",
      "Accuracy: 0.4632 Vaildation Error: 0.5367999970912933\n",
      "Accuracy: 0.4654 Vaildation Error: 0.5345999896526337\n",
      "Accuracy: 0.466 Vaildation Error: 0.5340000092983246\n",
      "Accuracy: 0.4662 Vaildation Error: 0.5338000059127808\n",
      "Accuracy: 0.4684 Vaildation Error: 0.5315999984741211\n",
      "Accuracy: 0.4678 Vaildation Error: 0.5322000086307526\n",
      "Accuracy: 0.4696 Vaildation Error: 0.5304000079631805\n",
      "Accuracy: 0.4704 Vaildation Error: 0.5295999944210052\n",
      "Accuracy: 0.4668 Vaildation Error: 0.5331999957561493\n",
      "Accuracy: 0.4636 Vaildation Error: 0.5363999903202057\n",
      "Accuracy: 0.4614 Vaildation Error: 0.5385999977588654\n",
      "Accuracy: 0.4612 Vaildation Error: 0.5388000011444092\n",
      "Accuracy: 0.4656 Vaildation Error: 0.5343999862670898\n",
      "Accuracy: 0.4672 Vaildation Error: 0.5327999889850616\n",
      "Accuracy: 0.4692 Vaildation Error: 0.5308000147342682\n",
      "Accuracy: 0.4718 Vaildation Error: 0.5282000005245209\n",
      "Accuracy: 0.473 Vaildation Error: 0.5270000100135803\n",
      "Accuracy: 0.4746 Vaildation Error: 0.5254000127315521\n",
      "Accuracy: 0.4772 Vaildation Error: 0.5227999985218048\n",
      "Accuracy: 0.4774 Vaildation Error: 0.522599995136261\n",
      "Accuracy: 0.4782 Vaildation Error: 0.5218000113964081\n",
      "Accuracy: 0.4822 Vaildation Error: 0.5178000032901764\n",
      "Accuracy: 0.4876 Vaildation Error: 0.5124000012874603\n",
      "Accuracy: 0.4884 Vaildation Error: 0.511599987745285\n",
      "Accuracy: 0.489 Vaildation Error: 0.511000007390976\n",
      "Accuracy: 0.4904 Vaildation Error: 0.5096000134944916\n",
      "Accuracy: 0.4912 Vaildation Error: 0.5087999999523163\n",
      "Accuracy: 0.4902 Vaildation Error: 0.509799987077713\n",
      "Accuracy: 0.4894 Vaildation Error: 0.5106000006198883\n",
      "Accuracy: 0.4888 Vaildation Error: 0.5112000107765198\n",
      "Accuracy: 0.4898 Vaildation Error: 0.5101999938488007\n",
      "Accuracy: 0.4898 Vaildation Error: 0.5101999938488007\n",
      "Accuracy: 0.4896 Vaildation Error: 0.5103999972343445\n",
      "Accuracy: 0.4896 Vaildation Error: 0.5103999972343445\n",
      "Accuracy: 0.4932 Vaildation Error: 0.5067999958992004\n",
      "Accuracy: 0.494 Vaildation Error: 0.5060000121593475\n",
      "Accuracy: 0.4938 Vaildation Error: 0.506199985742569\n",
      "Accuracy: 0.4916 Vaildation Error: 0.5083999931812286\n",
      "Accuracy: 0.4942 Vaildation Error: 0.5058000087738037\n",
      "Accuracy: 0.4954 Vaildation Error: 0.5045999884605408\n",
      "Accuracy: 0.4992 Vaildation Error: 0.5008000135421753\n",
      "Accuracy: 0.4986 Vaildation Error: 0.5013999938964844\n",
      "Accuracy: 0.5008 Vaildation Error: 0.4991999864578247\n",
      "Accuracy: 0.5002 Vaildation Error: 0.49980002641677856\n",
      "Accuracy: 0.5 Vaildation Error: 0.5\n",
      "Accuracy: 0.5006 Vaildation Error: 0.4994000196456909\n",
      "Accuracy: 0.5008 Vaildation Error: 0.4991999864578247\n",
      "Accuracy: 0.501 Vaildation Error: 0.49900001287460327\n",
      "Accuracy: 0.5004 Vaildation Error: 0.49959999322891235\n",
      "Accuracy: 0.5028 Vaildation Error: 0.49720001220703125\n",
      "Accuracy: 0.5034 Vaildation Error: 0.4965999722480774\n",
      "Accuracy: 0.5042 Vaildation Error: 0.4958000183105469\n",
      "Accuracy: 0.505 Vaildation Error: 0.4950000047683716\n",
      "Accuracy: 0.505 Vaildation Error: 0.4950000047683716\n",
      "Accuracy: 0.5044 Vaildation Error: 0.49559998512268066\n",
      "Accuracy: 0.5044 Vaildation Error: 0.49559998512268066\n",
      "Accuracy: 0.5076 Vaildation Error: 0.49239999055862427\n",
      "Accuracy: 0.5054 Vaildation Error: 0.49459999799728394\n",
      "Accuracy: 0.5044 Vaildation Error: 0.49559998512268066\n",
      "Accuracy: 0.5044 Vaildation Error: 0.49559998512268066\n",
      "Accuracy: 0.5048 Vaildation Error: 0.495199978351593\n",
      "Accuracy: 0.5036 Vaildation Error: 0.49639999866485596\n",
      "Accuracy: 0.503 Vaildation Error: 0.49699997901916504\n",
      "Accuracy: 0.5066 Vaildation Error: 0.493399977684021\n",
      "Accuracy: 0.5066 Vaildation Error: 0.493399977684021\n",
      "Accuracy: 0.507 Vaildation Error: 0.49299997091293335\n",
      "Accuracy: 0.5076 Vaildation Error: 0.49239999055862427\n",
      "Accuracy: 0.5066 Vaildation Error: 0.493399977684021\n",
      "Accuracy: 0.5072 Vaildation Error: 0.4927999973297119\n",
      "Accuracy: 0.5074 Vaildation Error: 0.4926000237464905\n",
      "Accuracy: 0.5086 Vaildation Error: 0.49140000343322754\n",
      "Accuracy: 0.5082 Vaildation Error: 0.4918000102043152\n",
      "Accuracy: 0.508 Vaildation Error: 0.4919999837875366\n",
      "Accuracy: 0.5092 Vaildation Error: 0.49080002307891846\n",
      "Accuracy: 0.509 Vaildation Error: 0.4909999966621399\n",
      "Accuracy: 0.5094 Vaildation Error: 0.49059998989105225\n",
      "Accuracy: 0.5092 Vaildation Error: 0.49080002307891846\n",
      "Accuracy: 0.5126 Vaildation Error: 0.48739999532699585\n",
      "Accuracy: 0.513 Vaildation Error: 0.4869999885559082\n",
      "Accuracy: 0.5144 Vaildation Error: 0.48559999465942383\n",
      "Accuracy: 0.5132 Vaildation Error: 0.48680001497268677\n",
      "Accuracy: 0.513 Vaildation Error: 0.4869999885559082\n",
      "Accuracy: 0.5142 Vaildation Error: 0.48580002784729004\n",
      "Accuracy: 0.5132 Vaildation Error: 0.48680001497268677\n",
      "Accuracy: 0.514 Vaildation Error: 0.4860000014305115\n",
      "Accuracy: 0.5142 Vaildation Error: 0.48580002784729004\n",
      "Accuracy: 0.5132 Vaildation Error: 0.48680001497268677\n",
      "Accuracy: 0.5126 Vaildation Error: 0.48739999532699585\n",
      "Accuracy: 0.5118 Vaildation Error: 0.48820000886917114\n",
      "Accuracy: 0.5138 Vaildation Error: 0.4861999750137329\n",
      "Accuracy: 0.5136 Vaildation Error: 0.4864000082015991\n",
      "Accuracy: 0.515 Vaildation Error: 0.48500001430511475\n",
      "Accuracy: 0.516 Vaildation Error: 0.484000027179718\n",
      "Accuracy: 0.5184 Vaildation Error: 0.48159998655319214\n",
      "Accuracy: 0.5184 Vaildation Error: 0.48159998655319214\n",
      "Accuracy: 0.5232 Vaildation Error: 0.47680002450942993\n",
      "Accuracy: 0.5278 Vaildation Error: 0.4721999764442444\n",
      "Accuracy: 0.5264 Vaildation Error: 0.47359997034072876\n",
      "Accuracy: 0.5304 Vaildation Error: 0.46960002183914185\n",
      "Accuracy: 0.5354 Vaildation Error: 0.4646000266075134\n",
      "Accuracy: 0.5406 Vaildation Error: 0.4593999981880188\n",
      "Accuracy: 0.5428 Vaildation Error: 0.45719999074935913\n",
      "Accuracy: 0.546 Vaildation Error: 0.45399999618530273\n",
      "Accuracy: 0.5548 Vaildation Error: 0.44520002603530884\n",
      "Accuracy: 0.5604 Vaildation Error: 0.43959999084472656\n",
      "Accuracy: 0.5636 Vaildation Error: 0.43639999628067017\n",
      "Accuracy: 0.5632 Vaildation Error: 0.4368000030517578\n",
      "Accuracy: 0.5624 Vaildation Error: 0.4376000165939331\n",
      "Accuracy: 0.5644 Vaildation Error: 0.4355999827384949\n",
      "Accuracy: 0.5644 Vaildation Error: 0.4355999827384949\n",
      "Accuracy: 0.5694 Vaildation Error: 0.43059998750686646\n",
      "Accuracy: 0.5736 Vaildation Error: 0.42640000581741333\n",
      "Accuracy: 0.5746 Vaildation Error: 0.4254000186920166\n",
      "Accuracy: 0.578 Vaildation Error: 0.421999990940094\n",
      "Accuracy: 0.586 Vaildation Error: 0.4139999747276306\n",
      "Accuracy: 0.5884 Vaildation Error: 0.4115999937057495\n",
      "Accuracy: 0.5916 Vaildation Error: 0.4083999991416931\n",
      "Accuracy: 0.5992 Vaildation Error: 0.4007999897003174\n",
      "Accuracy: 0.6022 Vaildation Error: 0.3978000283241272\n",
      "Accuracy: 0.605 Vaildation Error: 0.39499998092651367\n",
      "Accuracy: 0.6112 Vaildation Error: 0.3888000249862671\n",
      "Accuracy: 0.6172 Vaildation Error: 0.38279998302459717\n",
      "Accuracy: 0.6126 Vaildation Error: 0.38739997148513794\n",
      "Accuracy: 0.6224 Vaildation Error: 0.3776000142097473\n",
      "Accuracy: 0.6234 Vaildation Error: 0.3766000270843506\n",
      "Accuracy: 0.625 Vaildation Error: 0.375\n",
      "Accuracy: 0.6222 Vaildation Error: 0.37779998779296875\n",
      "Accuracy: 0.624 Vaildation Error: 0.37599998712539673\n",
      "Accuracy: 0.6238 Vaildation Error: 0.37620002031326294\n",
      "Accuracy: 0.6258 Vaildation Error: 0.3741999864578247\n",
      "Accuracy: 0.6324 Vaildation Error: 0.3676000237464905\n",
      "Accuracy: 0.634 Vaildation Error: 0.3659999966621399\n",
      "Accuracy: 0.6368 Vaildation Error: 0.36320000886917114\n",
      "Accuracy: 0.6492 Vaildation Error: 0.3507999777793884\n",
      "Accuracy: 0.6534 Vaildation Error: 0.3465999960899353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6588 Vaildation Error: 0.34119999408721924\n",
      "Accuracy: 0.6652 Vaildation Error: 0.33480000495910645\n",
      "Accuracy: 0.6644 Vaildation Error: 0.33560001850128174\n",
      "Accuracy: 0.6644 Vaildation Error: 0.33560001850128174\n",
      "Accuracy: 0.666 Vaildation Error: 0.33399999141693115\n",
      "Accuracy: 0.6662 Vaildation Error: 0.3338000178337097\n",
      "Accuracy: 0.6654 Vaildation Error: 0.33459997177124023\n",
      "Accuracy: 0.6716 Vaildation Error: 0.32840001583099365\n",
      "Accuracy: 0.6696 Vaildation Error: 0.3303999900817871\n",
      "Accuracy: 0.6654 Vaildation Error: 0.33459997177124023\n",
      "Accuracy: 0.6702 Vaildation Error: 0.329800009727478\n",
      "Accuracy: 0.6724 Vaildation Error: 0.32760000228881836\n",
      "Accuracy: 0.6696 Vaildation Error: 0.3303999900817871\n",
      "Accuracy: 0.6748 Vaildation Error: 0.32520002126693726\n",
      "Accuracy: 0.6768 Vaildation Error: 0.323199987411499\n",
      "Accuracy: 0.6802 Vaildation Error: 0.3198000192642212\n",
      "Accuracy: 0.681 Vaildation Error: 0.3190000057220459\n",
      "Accuracy: 0.6776 Vaildation Error: 0.32239997386932373\n",
      "Accuracy: 0.6784 Vaildation Error: 0.3216000199317932\n",
      "Accuracy: 0.678 Vaildation Error: 0.32200002670288086\n",
      "Accuracy: 0.6776 Vaildation Error: 0.32239997386932373\n",
      "Accuracy: 0.6788 Vaildation Error: 0.32120001316070557\n",
      "Accuracy: 0.681 Vaildation Error: 0.3190000057220459\n",
      "Accuracy: 0.6802 Vaildation Error: 0.3198000192642212\n",
      "Accuracy: 0.6784 Vaildation Error: 0.3216000199317932\n",
      "Accuracy: 0.6816 Vaildation Error: 0.3184000253677368\n",
      "Accuracy: 0.6838 Vaildation Error: 0.31620001792907715\n",
      "Accuracy: 0.6842 Vaildation Error: 0.3158000111579895\n",
      "Accuracy: 0.6856 Vaildation Error: 0.3144000172615051\n",
      "Accuracy: 0.6844 Vaildation Error: 0.3155999779701233\n",
      "Accuracy: 0.6856 Vaildation Error: 0.3144000172615051\n",
      "Accuracy: 0.684 Vaildation Error: 0.31599998474121094\n",
      "Accuracy: 0.6852 Vaildation Error: 0.3148000240325928\n",
      "Accuracy: 0.6844 Vaildation Error: 0.3155999779701233\n",
      "Accuracy: 0.6842 Vaildation Error: 0.3158000111579895\n",
      "Accuracy: 0.6844 Vaildation Error: 0.3155999779701233\n",
      "Accuracy: 0.6858 Vaildation Error: 0.3141999840736389\n",
      "Accuracy: 0.6838 Vaildation Error: 0.31620001792907715\n",
      "Accuracy: 0.6862 Vaildation Error: 0.31379997730255127\n",
      "Accuracy: 0.6872 Vaildation Error: 0.31279999017715454\n",
      "Accuracy: 0.6886 Vaildation Error: 0.31139999628067017\n",
      "Accuracy: 0.6886 Vaildation Error: 0.31139999628067017\n",
      "Accuracy: 0.6878 Vaildation Error: 0.31220000982284546\n",
      "Accuracy: 0.6872 Vaildation Error: 0.31279999017715454\n",
      "Accuracy: 0.6876 Vaildation Error: 0.3123999834060669\n",
      "Accuracy: 0.69 Vaildation Error: 0.3100000023841858\n",
      "Accuracy: 0.6904 Vaildation Error: 0.30959999561309814\n",
      "Accuracy: 0.6916 Vaildation Error: 0.3083999752998352\n",
      "Accuracy: 0.6922 Vaildation Error: 0.3077999949455261\n",
      "Accuracy: 0.6922 Vaildation Error: 0.3077999949455261\n",
      "Accuracy: 0.6928 Vaildation Error: 0.30720001459121704\n",
      "Accuracy: 0.6928 Vaildation Error: 0.30720001459121704\n",
      "Accuracy: 0.694 Vaildation Error: 0.3059999942779541\n",
      "Accuracy: 0.6948 Vaildation Error: 0.3051999807357788\n",
      "Accuracy: 0.6938 Vaildation Error: 0.3062000274658203\n",
      "Accuracy: 0.6954 Vaildation Error: 0.3046000003814697\n",
      "Accuracy: 0.696 Vaildation Error: 0.30400002002716064\n",
      "Accuracy: 0.697 Vaildation Error: 0.30299997329711914\n",
      "Accuracy: 0.6986 Vaildation Error: 0.30140000581741333\n",
      "Accuracy: 0.6984 Vaildation Error: 0.30159997940063477\n",
      "Accuracy: 0.6974 Vaildation Error: 0.30260002613067627\n",
      "Accuracy: 0.696 Vaildation Error: 0.30400002002716064\n",
      "Accuracy: 0.6988 Vaildation Error: 0.3011999726295471\n",
      "Accuracy: 0.6968 Vaildation Error: 0.30320000648498535\n",
      "Accuracy: 0.6974 Vaildation Error: 0.30260002613067627\n",
      "Accuracy: 0.6986 Vaildation Error: 0.30140000581741333\n",
      "Accuracy: 0.7008 Vaildation Error: 0.29919999837875366\n",
      "Accuracy: 0.7006 Vaildation Error: 0.2993999719619751\n",
      "Accuracy: 0.6998 Vaildation Error: 0.3001999855041504\n",
      "Accuracy: 0.6992 Vaildation Error: 0.30080002546310425\n",
      "Accuracy: 0.6998 Vaildation Error: 0.3001999855041504\n",
      "Accuracy: 0.6988 Vaildation Error: 0.3011999726295471\n",
      "Accuracy: 0.6982 Vaildation Error: 0.301800012588501\n",
      "Accuracy: 0.6988 Vaildation Error: 0.3011999726295471\n",
      "Accuracy: 0.7006 Vaildation Error: 0.2993999719619751\n",
      "Accuracy: 0.701 Vaildation Error: 0.2990000247955322\n",
      "Accuracy: 0.7026 Vaildation Error: 0.29739999771118164\n",
      "Accuracy: 0.7026 Vaildation Error: 0.29739999771118164\n",
      "Accuracy: 0.7008 Vaildation Error: 0.29919999837875366\n",
      "Accuracy: 0.7016 Vaildation Error: 0.29839998483657837\n",
      "Accuracy: 0.7028 Vaildation Error: 0.2972000241279602\n",
      "Accuracy: 0.7022 Vaildation Error: 0.2978000044822693\n",
      "Accuracy: 0.7038 Vaildation Error: 0.2961999773979187\n",
      "Accuracy: 0.7032 Vaildation Error: 0.29680001735687256\n",
      "Accuracy: 0.704 Vaildation Error: 0.29600000381469727\n",
      "Accuracy: 0.7034 Vaildation Error: 0.29659998416900635\n",
      "Accuracy: 0.7046 Vaildation Error: 0.2954000234603882\n",
      "Accuracy: 0.705 Vaildation Error: 0.29500001668930054\n",
      "Accuracy: 0.704 Vaildation Error: 0.29600000381469727\n",
      "Accuracy: 0.7024 Vaildation Error: 0.2975999712944031\n",
      "Accuracy: 0.7042 Vaildation Error: 0.29579997062683105\n",
      "Accuracy: 0.7034 Vaildation Error: 0.29659998416900635\n",
      "Accuracy: 0.7052 Vaildation Error: 0.2947999835014343\n",
      "Accuracy: 0.707 Vaildation Error: 0.2929999828338623\n",
      "Accuracy: 0.7064 Vaildation Error: 0.29360002279281616\n",
      "Accuracy: 0.707 Vaildation Error: 0.2929999828338623\n",
      "Accuracy: 0.7076 Vaildation Error: 0.2924000024795532\n",
      "Accuracy: 0.7084 Vaildation Error: 0.29159998893737793\n",
      "Accuracy: 0.7076 Vaildation Error: 0.2924000024795532\n",
      "Accuracy: 0.709 Vaildation Error: 0.29100000858306885\n",
      "Accuracy: 0.7092 Vaildation Error: 0.29079997539520264\n",
      "Accuracy: 0.7102 Vaildation Error: 0.2897999882698059\n",
      "Accuracy: 0.7102 Vaildation Error: 0.2897999882698059\n",
      "Accuracy: 0.7118 Vaildation Error: 0.2882000207901001\n",
      "Accuracy: 0.7118 Vaildation Error: 0.2882000207901001\n",
      "Accuracy: 0.71 Vaildation Error: 0.2900000214576721\n",
      "Accuracy: 0.7096 Vaildation Error: 0.29040002822875977\n",
      "Accuracy: 0.71 Vaildation Error: 0.2900000214576721\n",
      "Accuracy: 0.7096 Vaildation Error: 0.29040002822875977\n",
      "Accuracy: 0.7096 Vaildation Error: 0.29040002822875977\n",
      "Accuracy: 0.7104 Vaildation Error: 0.2896000146865845\n",
      "Accuracy: 0.71 Vaildation Error: 0.2900000214576721\n",
      "Accuracy: 0.7128 Vaildation Error: 0.2871999740600586\n",
      "Accuracy: 0.7128 Vaildation Error: 0.2871999740600586\n",
      "Accuracy: 0.71 Vaildation Error: 0.2900000214576721\n",
      "Accuracy: 0.7114 Vaildation Error: 0.28860002756118774\n",
      "Accuracy: 0.711 Vaildation Error: 0.2889999747276306\n",
      "Accuracy: 0.7108 Vaildation Error: 0.2892000079154968\n",
      "Accuracy: 0.7116 Vaildation Error: 0.28839999437332153\n",
      "Accuracy: 0.7104 Vaildation Error: 0.2896000146865845\n",
      "Accuracy: 0.7092 Vaildation Error: 0.29079997539520264\n",
      "Accuracy: 0.7106 Vaildation Error: 0.28939998149871826\n",
      "Accuracy: 0.7076 Vaildation Error: 0.2924000024795532\n",
      "Accuracy: 0.711 Vaildation Error: 0.2889999747276306\n",
      "Accuracy: 0.712 Vaildation Error: 0.2879999876022339\n",
      "Accuracy: 0.713 Vaildation Error: 0.28700000047683716\n",
      "Accuracy: 0.7126 Vaildation Error: 0.2874000072479248\n",
      "Accuracy: 0.7138 Vaildation Error: 0.28619998693466187\n",
      "Accuracy: 0.7134 Vaildation Error: 0.2865999937057495\n",
      "Accuracy: 0.7114 Vaildation Error: 0.28860002756118774\n",
      "Accuracy: 0.7124 Vaildation Error: 0.28759998083114624\n",
      "Accuracy: 0.713 Vaildation Error: 0.28700000047683716\n",
      "Accuracy: 0.7126 Vaildation Error: 0.2874000072479248\n",
      "Accuracy: 0.7136 Vaildation Error: 0.2864000201225281\n",
      "Accuracy: 0.7142 Vaildation Error: 0.2857999801635742\n",
      "Accuracy: 0.7152 Vaildation Error: 0.2847999930381775\n",
      "Accuracy: 0.7136 Vaildation Error: 0.2864000201225281\n",
      "Accuracy: 0.7144 Vaildation Error: 0.2856000065803528\n",
      "Accuracy: 0.7144 Vaildation Error: 0.2856000065803528\n",
      "Accuracy: 0.713 Vaildation Error: 0.28700000047683716\n",
      "Accuracy: 0.7122 Vaildation Error: 0.28780001401901245\n",
      "Accuracy: 0.7128 Vaildation Error: 0.2871999740600586\n",
      "Accuracy: 0.7138 Vaildation Error: 0.28619998693466187\n",
      "Accuracy: 0.713 Vaildation Error: 0.28700000047683716\n",
      "Accuracy: 0.713 Vaildation Error: 0.28700000047683716\n",
      "Accuracy: 0.713 Vaildation Error: 0.28700000047683716\n",
      "Accuracy: 0.7132 Vaildation Error: 0.2868000268936157\n",
      "Accuracy: 0.7132 Vaildation Error: 0.2868000268936157\n",
      "Accuracy: 0.7132 Vaildation Error: 0.2868000268936157\n",
      "Accuracy: 0.7142 Vaildation Error: 0.2857999801635742\n",
      "Accuracy: 0.7136 Vaildation Error: 0.2864000201225281\n",
      "Accuracy: 0.7136 Vaildation Error: 0.2864000201225281\n",
      "Accuracy: 0.7136 Vaildation Error: 0.2864000201225281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.714 Vaildation Error: 0.28600001335144043\n",
      "Accuracy: 0.7138 Vaildation Error: 0.28619998693466187\n",
      "Accuracy: 0.7154 Vaildation Error: 0.28460001945495605\n",
      "Accuracy: 0.7158 Vaildation Error: 0.2842000126838684\n",
      "Accuracy: 0.7146 Vaildation Error: 0.2853999733924866\n",
      "Accuracy: 0.7158 Vaildation Error: 0.2842000126838684\n",
      "Accuracy: 0.716 Vaildation Error: 0.2839999794960022\n",
      "Accuracy: 0.7148 Vaildation Error: 0.28519999980926514\n",
      "Accuracy: 0.7162 Vaildation Error: 0.28380000591278076\n",
      "Accuracy: 0.7164 Vaildation Error: 0.28359997272491455\n",
      "Accuracy: 0.7166 Vaildation Error: 0.2833999991416931\n",
      "Accuracy: 0.7162 Vaildation Error: 0.28380000591278076\n",
      "Accuracy: 0.716 Vaildation Error: 0.2839999794960022\n",
      "Accuracy: 0.7168 Vaildation Error: 0.2832000255584717\n",
      "Accuracy: 0.716 Vaildation Error: 0.2839999794960022\n",
      "Accuracy: 0.7158 Vaildation Error: 0.2842000126838684\n",
      "Accuracy: 0.7152 Vaildation Error: 0.2847999930381775\n",
      "Accuracy: 0.714 Vaildation Error: 0.28600001335144043\n",
      "Accuracy: 0.7146 Vaildation Error: 0.2853999733924866\n",
      "Accuracy: 0.715 Vaildation Error: 0.2850000262260437\n",
      "Accuracy: 0.7148 Vaildation Error: 0.28519999980926514\n",
      "Accuracy: 0.715 Vaildation Error: 0.2850000262260437\n",
      "Accuracy: 0.7188 Vaildation Error: 0.28119999170303345\n",
      "Accuracy: 0.7188 Vaildation Error: 0.28119999170303345\n",
      "Accuracy: 0.7176 Vaildation Error: 0.2824000120162964\n",
      "Accuracy: 0.718 Vaildation Error: 0.28200000524520874\n",
      "Accuracy: 0.7168 Vaildation Error: 0.2832000255584717\n",
      "Accuracy: 0.7186 Vaildation Error: 0.28140002489089966\n",
      "Accuracy: 0.7186 Vaildation Error: 0.28140002489089966\n",
      "Accuracy: 0.7192 Vaildation Error: 0.2807999849319458\n",
      "Accuracy: 0.7188 Vaildation Error: 0.28119999170303345\n",
      "Accuracy: 0.7204 Vaildation Error: 0.27960002422332764\n",
      "Accuracy: 0.7192 Vaildation Error: 0.2807999849319458\n",
      "Accuracy: 0.7192 Vaildation Error: 0.2807999849319458\n",
      "Accuracy: 0.7202 Vaildation Error: 0.2797999978065491\n",
      "Accuracy: 0.719 Vaildation Error: 0.281000018119812\n",
      "Accuracy: 0.7204 Vaildation Error: 0.27960002422332764\n",
      "Accuracy: 0.719 Vaildation Error: 0.281000018119812\n",
      "Accuracy: 0.7202 Vaildation Error: 0.2797999978065491\n",
      "Accuracy: 0.7212 Vaildation Error: 0.27880001068115234\n",
      "Accuracy: 0.7202 Vaildation Error: 0.2797999978065491\n",
      "Accuracy: 0.72 Vaildation Error: 0.2799999713897705\n",
      "Accuracy: 0.7188 Vaildation Error: 0.28119999170303345\n",
      "Accuracy: 0.719 Vaildation Error: 0.281000018119812\n",
      "Accuracy: 0.7198 Vaildation Error: 0.2802000045776367\n",
      "Accuracy: 0.7194 Vaildation Error: 0.28060001134872437\n",
      "Accuracy: 0.7206 Vaildation Error: 0.2793999910354614\n",
      "Accuracy: 0.7204 Vaildation Error: 0.27960002422332764\n",
      "Accuracy: 0.7214 Vaildation Error: 0.27859997749328613\n",
      "Accuracy: 0.72 Vaildation Error: 0.2799999713897705\n",
      "Accuracy: 0.7214 Vaildation Error: 0.27859997749328613\n",
      "Accuracy: 0.7226 Vaildation Error: 0.27740001678466797\n",
      "Accuracy: 0.722 Vaildation Error: 0.27799999713897705\n",
      "Accuracy: 0.7224 Vaildation Error: 0.2775999903678894\n",
      "Accuracy: 0.7208 Vaildation Error: 0.27920001745224\n",
      "Accuracy: 0.7218 Vaildation Error: 0.2781999707221985\n",
      "Accuracy: 0.7218 Vaildation Error: 0.2781999707221985\n",
      "Accuracy: 0.7222 Vaildation Error: 0.2778000235557556\n",
      "Accuracy: 0.7216 Vaildation Error: 0.2784000039100647\n",
      "Accuracy: 0.722 Vaildation Error: 0.27799999713897705\n",
      "Accuracy: 0.7206 Vaildation Error: 0.2793999910354614\n",
      "Accuracy: 0.7206 Vaildation Error: 0.2793999910354614\n",
      "Accuracy: 0.7208 Vaildation Error: 0.27920001745224\n",
      "Accuracy: 0.7196 Vaildation Error: 0.28039997816085815\n",
      "Accuracy: 0.7214 Vaildation Error: 0.27859997749328613\n",
      "Accuracy: 0.7204 Vaildation Error: 0.27960002422332764\n",
      "Accuracy: 0.7206 Vaildation Error: 0.2793999910354614\n",
      "Accuracy: 0.7198 Vaildation Error: 0.2802000045776367\n",
      "Accuracy: 0.7216 Vaildation Error: 0.2784000039100647\n",
      "Accuracy: 0.7218 Vaildation Error: 0.2781999707221985\n",
      "Accuracy: 0.7218 Vaildation Error: 0.2781999707221985\n",
      "Accuracy: 0.7224 Vaildation Error: 0.2775999903678894\n",
      "Accuracy: 0.723 Vaildation Error: 0.2770000100135803\n",
      "Accuracy: 0.7228 Vaildation Error: 0.27719998359680176\n",
      "Accuracy: 0.7234 Vaildation Error: 0.2766000032424927\n",
      "Accuracy: 0.723 Vaildation Error: 0.2770000100135803\n",
      "Accuracy: 0.7218 Vaildation Error: 0.2781999707221985\n",
      "Accuracy: 0.7214 Vaildation Error: 0.27859997749328613\n",
      "Accuracy: 0.7208 Vaildation Error: 0.27920001745224\n",
      "Accuracy: 0.7208 Vaildation Error: 0.27920001745224\n",
      "Accuracy: 0.7216 Vaildation Error: 0.2784000039100647\n",
      "Accuracy: 0.7218 Vaildation Error: 0.2781999707221985\n",
      "Accuracy: 0.7224 Vaildation Error: 0.2775999903678894\n",
      "Accuracy: 0.7234 Vaildation Error: 0.2766000032424927\n",
      "Accuracy: 0.7234 Vaildation Error: 0.2766000032424927\n",
      "Accuracy: 0.7242 Vaildation Error: 0.2757999897003174\n",
      "Accuracy: 0.7228 Vaildation Error: 0.27719998359680176\n",
      "Accuracy: 0.7226 Vaildation Error: 0.27740001678466797\n",
      "Accuracy: 0.7226 Vaildation Error: 0.27740001678466797\n",
      "Accuracy: 0.7226 Vaildation Error: 0.27740001678466797\n",
      "Accuracy: 0.7228 Vaildation Error: 0.27719998359680176\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-cbe514283a11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0mfeed_dict_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict_data\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# feed into data and start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                     \u001b[0mbatch_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    with tf.variable_scope(\"mlp_model\"):\n",
    "        x = tf.placeholder(\"float\", [None, 784])   # x is batch input\n",
    "        y = tf.placeholder(\"float\", [None, 10])   # y is output for 10 classification\n",
    "\n",
    "        output = inference(x)   # get the inference result\n",
    "        cost = loss(output=output, y=y)   # get the loss\n",
    "        global_step = tf.Variable(0, name=\"global_step\", trainable=False)   # training step\n",
    "        train_opt = training(cost=cost, global_step=global_step)   # training body\n",
    "        eval_opt_val = evaluate(output=output, y=y, name=\"valid\")   # evaluation result\n",
    "        eval_opt_test = evaluate(output=output, y=y, name=\"test\")   # evaluation result\n",
    "\n",
    "        init_var = tf.global_variables_initializer()\n",
    "        summary_opt = tf.summary.merge_all()   # merge summary in each epoch\n",
    "        saver = tf.train.Saver()   # for saving checkpoints\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            # write the summary \n",
    "            summary_writer = tf.summary.FileWriter(\"/Users/jiankaiwang/Desktop/devops/tmp/basic_tf/logistic_logs_nn\", graph=sess.graph)\n",
    "            sess.run(init_var)   # initialize all variables\n",
    "\n",
    "            for epoch in range(training_epochs):\n",
    "                avg_cost = 0.\n",
    "                total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "                for idx in range(total_batch):\n",
    "                    batch_x, batch_y = mnist.train.next_batch(batch_size=batch_size)   # get the batch data\n",
    "\n",
    "                    feed_dict_data = {x: batch_x, y: batch_y}\n",
    "                    sess.run(train_opt, feed_dict=feed_dict_data)   # feed into data and start training\n",
    "\n",
    "                    batch_cost = sess.run(cost, feed_dict=feed_dict_data)\n",
    "                    avg_cost += batch_cost / total_batch   # calculate the average loss\n",
    "\n",
    "                    if epoch % display_step == 0:\n",
    "                        # record log\n",
    "\n",
    "                        feed_dict_val_data = {x: mnist.validation.images, y: mnist.validation.labels}\n",
    "                        acc = sess.run(eval_opt_val, feed_dict=feed_dict_val_data)   # calculate the accuracy\n",
    "\n",
    "                        print(\"Accuracy:\", acc, \"Vaildation Error:\", (1-acc))\n",
    "                        tf.summary.scalar(\"validation_accuracy\", acc)  \n",
    "\n",
    "                        summary_str = sess.run(summary_opt, feed_dict=feed_dict_data)\n",
    "                        summary_writer.add_summary(summary_str, sess.run(global_step))   # write out the summary\n",
    "\n",
    "                        saver.save(sess, \\\n",
    "                                   \"/Users/jiankaiwang/Desktop/devops/tmp/basic_tf/model-checkpoint\", \\\n",
    "                                  global_step=global_step)\n",
    "\n",
    "            print(\"Training finishing.\")\n",
    "\n",
    "            feed_dict_test_data = {x: mnist.test.images, y: mnist.test.labels}\n",
    "            acc = sess.run(eval_opt_test, feed_dict=feed_dict_test_data)   # test result\n",
    "            print(\"Test Accuracy:\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
