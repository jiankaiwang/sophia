{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python3.5/dist-packages (2.2.4)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.5/dist-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.5/dist-packages (from keras) (2.8.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.5/dist-packages (from keras) (1.0.6)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.5/dist-packages (from keras) (1.11.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.5/dist-packages (from keras) (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.5/dist-packages (from keras) (1.14.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.5/dist-packages (from keras) (3.13)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras version: 2.2.4\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(\"keras version: {}\".format(keras.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_WORDS=1000 # only use top 1000 words\n",
    "INDEX_FROM=3   # word index offset\n",
    "\n",
    "if os.path.exists('/notebooks/data'):\n",
    "    k_train, k_test = keras.datasets.imdb.load_data(path='/notebooks/data/imdb/imdb.npz', num_words=NUM_WORDS, index_from=INDEX_FROM)\n",
    "elif os.path.exists('/Volumes/Data'):\n",
    "    k_train, k_test = keras.datasets.imdb.load_data(path='/Volumes/Data/imdb/imdb.npz', num_words=NUM_WORDS, index_from=INDEX_FROM)\n",
    "else:\n",
    "    raise IOError(\"no such path\")\n",
    "    \n",
    "k_train_x, k_train_y = k_train\n",
    "k_test_x, k_test_y = k_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show origin text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START> this film was just brilliant casting <UNK> <UNK> story direction <UNK> really <UNK> the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same <UNK> <UNK> as myself so i loved the fact there was a real <UNK> with this film the <UNK> <UNK> throughout the film were great it was just brilliant so much that i <UNK> the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the <UNK> <UNK> was amazing really <UNK> at the end it was so sad and you know what they say if you <UNK> at a film it must have been good and this definitely was also <UNK> to the two little <UNK> that played the <UNK> of <UNK> and paul they were just brilliant children are often left out of the <UNK> <UNK> i think because the stars that play them all <UNK> up are such a big <UNK> for the whole film but these children are amazing and should be <UNK> for what they have done don't you think the whole story was so <UNK> because it was true and was <UNK> life after all that was <UNK> with us all\n"
     ]
    }
   ],
   "source": [
    "word_to_id = keras.datasets.imdb.get_word_index()\n",
    "word_to_id = {k:(v+INDEX_FROM) for k,v in word_to_id.items()}\n",
    "word_to_id[\"<PAD>\"] = 0\n",
    "word_to_id[\"<START>\"] = 1\n",
    "word_to_id[\"<UNK>\"] = 2\n",
    "\n",
    "id_to_word = {value:key for key,value in word_to_id.items()}\n",
    "print(' '.join(id_to_word[id] for id in k_train_x[0] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data count: 25000\n",
      "[1, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "print(\"train data count: {}\".format(len(k_train_x)))\n",
    "print(k_train_x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# expand sequence to length of 500 with value = 0 if the sequence length <= 500\n",
    "# truncated sequence to length of 500 if the sequence length > 500\n",
    "k_train_x_p = keras.preprocessing.sequence.pad_sequences(k_train_x, maxlen=500, value=0., padding=\"post\")\n",
    "k_test_x_p = keras.preprocessing.sequence.pad_sequences(k_test_x, maxlen=500, value=0., padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,  14,  22,  16,  43, 530, 973,   2,   2,  65, 458,   2,  66,\n",
       "         2,   4, 173,  36, 256,   5,  25, 100,  43, 838, 112,  50, 670,\n",
       "         2,   9,  35, 480, 284,   5, 150,   4, 172, 112, 167,   2, 336,\n",
       "       385,  39,   4, 172,   2,   2,  17, 546,  38,  13, 447,   4, 192,\n",
       "        50,  16,   6, 147,   2,  19,  14,  22,   4,   2,   2, 469,   4,\n",
       "        22,  71,  87,  12,  16,  43, 530,  38,  76,  15,  13,   2,   4,\n",
       "        22,  17, 515,  17,  12,  16, 626,  18,   2,   5,  62, 386,  12,\n",
       "         8, 316,   8, 106,   5,   4,   2,   2,  16, 480,  66,   2,  33,\n",
       "         4, 130,  12,  16,  38, 619,   5,  25, 124,  51,  36, 135,  48,\n",
       "        25,   2,  33,   6,  22,  12, 215,  28,  77,  52,   5,  14, 407,\n",
       "        16,  82,   2,   8,   4, 107, 117,   2,  15, 256,   4,   2,   7,\n",
       "         2,   5, 723,  36,  71,  43, 530, 476,  26, 400, 317,  46,   7,\n",
       "         4,   2,   2,  13, 104,  88,   4, 381,  15, 297,  98,  32,   2,\n",
       "        56,  26, 141,   6, 194,   2,  18,   4, 226,  22,  21, 134, 476,\n",
       "        26, 480,   5, 144,  30,   2,  18,  51,  36,  28, 224,  92,  25,\n",
       "       104,   4, 226,  65,  16,  38,   2,  88,  12,  16, 283,   5,  16,\n",
       "         2, 113, 103,  32,  15,  16,   2,  19, 178,  32,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a simple example\n",
    "k_train_x_p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_train_x_p_c = keras.utils.to_categorical(k_train_y, num_classes=2, dtype='int')\n",
    "k_test_x_p_c = keras.utils.to_categorical(k_test_y, num_classes=2, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_train_x_p_c[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tflearn in /usr/local/lib/python3.5/dist-packages (0.3.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.5/dist-packages (from tflearn) (1.11.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.5/dist-packages (from tflearn) (1.14.5)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.5/dist-packages (from tflearn) (5.2.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tflearn             0.3.2                 \n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "\n",
    "!pip list | grep 'tflearn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tflearn.data_utils import to_categorical, pad_sequences\n",
    "from tflearn.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n_word=30000, most common used 300000 word\n",
    "if os.path.exists('/notebooks/data'):\n",
    "    t_train, t_test, _ = imdb.load_data('/notebooks/data/imdb/imdb.pkl', n_words=1000, valid_portion=0.)\n",
    "elif os.path.exists('/Volumes/Data'):\n",
    "    t_train, t_test, _ = imdb.load_data('/Volumes/Data/imdb/imdb.pkl', n_words=1000, valid_portion=0.)\n",
    "else:\n",
    "    raise IOError(\"no such path\")\n",
    "\n",
    "# trainX, testX: the sequence\n",
    "# trainY, testY: the emotion label (positive/negative, 1/0)\n",
    "t_train_x, t_train_y = t_train\n",
    "t_test_x, t_test_y = t_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data count: 25000\n",
      "[6, 1, 1, 1, 29, 1, 28, 44, 6, 1, 7, 55, 947, 938, 854, 1, 1, 1, 7, 1, 7, 721, 170, 47, 712, 8, 815, 15, 31, 6, 1, 1, 61, 1, 170, 608, 31, 6, 51, 1, 1, 4, 51, 59, 43, 183, 10, 6, 1, 64, 1, 85, 245, 1, 31, 712, 3, 6, 322, 5, 494, 1, 1, 202, 256, 3, 5, 52, 335, 3, 6, 1, 1, 1, 44, 64, 85, 2, 1, 7, 2, 1, 1, 34, 56, 1, 324, 15, 4, 12, 13, 9, 11, 12, 13, 9, 11, 31, 2, 1, 3, 17, 76, 10, 6, 1, 1, 595, 747, 4, 61, 1, 14, 8, 1, 20, 1, 3, 26, 17, 10, 6, 1, 3, 5, 3, 15, 61, 770, 3, 45, 1, 8, 2, 1, 533, 4, 1, 7, 59, 181, 14, 6, 1, 27, 3, 263, 3, 106, 2, 1, 3, 26, 102, 125, 1, 7, 122, 63, 30, 150, 159, 733, 55, 60, 12, 13, 9, 11, 12, 13, 9, 11, 1, 3, 17, 10, 6, 1, 803, 55, 1, 5, 1, 5, 2, 1, 1, 1, 23, 106, 1, 5, 1, 372, 4, 261, 2, 27, 145, 1, 24, 41, 2, 1, 23, 275, 709, 18, 81, 37, 229, 8, 539, 47, 300, 49, 345, 1, 4, 12, 13, 9, 11, 12, 13, 9, 11, 1, 1, 10, 33, 2, 75, 296, 152, 17, 27, 10, 134, 1, 22, 322, 4, 2, 330, 323, 3, 5, 68, 2, 1, 7, 2, 1, 35, 979, 211, 8, 112, 2, 1, 941, 5, 1, 129, 235, 1, 4, 57, 14, 82, 33, 23, 2, 1, 1, 7, 1, 1, 1, 3, 30, 248, 117, 30, 82, 164, 6, 1, 435, 4, 12, 13, 9, 11, 12, 13, 9, 11, 17, 10, 6, 366, 7, 18, 67, 330, 1, 7, 1, 1, 16, 49, 8, 683, 1, 1, 3, 5, 3, 168, 33, 3, 15, 69, 661, 3, 2, 134, 14, 10, 452, 6, 237, 79, 23, 1, 926, 15, 1, 27, 5, 330, 323, 4, 2, 1, 131, 3, 167, 1, 1, 44, 106, 1, 15, 1, 53, 1, 673, 7, 345, 1, 3, 429, 15, 854, 3, 5, 68, 1, 3, 10, 305, 1, 704, 8, 3, 5, 93, 1, 2, 611, 7, 105, 1, 467, 4, 1, 93, 38, 585, 926, 15, 2, 986, 1, 7, 2, 27, 74, 320, 8, 37, 1, 1, 7, 345, 1, 20, 216, 220, 1, 55, 1, 170, 316, 3, 168, 43, 213, 183, 538, 689, 44, 2, 29, 1, 1, 28, 1, 1, 5, 2, 588, 7, 114, 257, 7, 1, 1, 4, 153, 16, 98, 33, 399, 8, 1, 3, 2, 588, 7, 1, 1, 1, 15, 17, 27, 21, 2, 39, 678, 459, 16, 80, 24, 14, 4, 12, 13, 9, 11, 12, 13, 9, 11, 61, 93, 254, 79, 17, 27, 340, 8, 1, 6, 1, 7, 202, 3, 1, 1, 1, 15, 39, 7, 36, 101, 1, 565, 4, 485, 3, 1, 20, 251, 10, 75, 883, 3, 5, 42, 226, 1, 351, 29, 277, 42, 2, 1, 7, 2, 27, 28, 4, 1, 1, 3, 168, 197, 333, 15, 94, 122, 3, 1, 36, 233, 22, 89, 4, 1, 1, 3, 1, 1, 3, 5, 2, 492, 1, 2, 1, 35, 2, 1, 171, 15, 17, 1, 3, 168, 31, 2, 239, 2, 120, 171, 1, 15, 2, 1, 98, 6, 62, 308, 4, 2, 710, 24, 2, 1, 365, 3, 16, 117, 3, 35, 22, 88, 2, 1, 7, 2, 172, 5, 2, 1, 3, 22, 245, 4, 168, 43, 452, 204, 105, 7, 2, 27, 197, 222, 4]\n"
     ]
    }
   ],
   "source": [
    "print(\"train data count: {}\".format(len(t_train_x)))\n",
    "print(t_train[0][23000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# expand sequence to length of 500 with value = 0 if the sequence length <= 500\n",
    "# truncated sequence to length of 500 if the sequence length > 500\n",
    "t_train_x_p = pad_sequences(t_train_x, maxlen=500, value=0.)\n",
    "t_test_x_p = pad_sequences(t_test_x, maxlen=500, value=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6,   1,   1,   1,  29,   1,  28,  44,   6,   1,   7,  55, 947,\n",
       "       938, 854,   1,   1,   1,   7,   1,   7, 721, 170,  47, 712,   8,\n",
       "       815,  15,  31,   6,   1,   1,  61,   1, 170, 608,  31,   6,  51,\n",
       "         1,   1,   4,  51,  59,  43, 183,  10,   6,   1,  64,   1,  85,\n",
       "       245,   1,  31, 712,   3,   6, 322,   5, 494,   1,   1, 202, 256,\n",
       "         3,   5,  52, 335,   3,   6,   1,   1,   1,  44,  64,  85,   2,\n",
       "         1,   7,   2,   1,   1,  34,  56,   1, 324,  15,   4,  12,  13,\n",
       "         9,  11,  12,  13,   9,  11,  31,   2,   1,   3,  17,  76,  10,\n",
       "         6,   1,   1, 595, 747,   4,  61,   1,  14,   8,   1,  20,   1,\n",
       "         3,  26,  17,  10,   6,   1,   3,   5,   3,  15,  61, 770,   3,\n",
       "        45,   1,   8,   2,   1, 533,   4,   1,   7,  59, 181,  14,   6,\n",
       "         1,  27,   3, 263,   3, 106,   2,   1,   3,  26, 102, 125,   1,\n",
       "         7, 122,  63,  30, 150, 159, 733,  55,  60,  12,  13,   9,  11,\n",
       "        12,  13,   9,  11,   1,   3,  17,  10,   6,   1, 803,  55,   1,\n",
       "         5,   1,   5,   2,   1,   1,   1,  23, 106,   1,   5,   1, 372,\n",
       "         4, 261,   2,  27, 145,   1,  24,  41,   2,   1,  23, 275, 709,\n",
       "        18,  81,  37, 229,   8, 539,  47, 300,  49, 345,   1,   4,  12,\n",
       "        13,   9,  11,  12,  13,   9,  11,   1,   1,  10,  33,   2,  75,\n",
       "       296, 152,  17,  27,  10, 134,   1,  22, 322,   4,   2, 330, 323,\n",
       "         3,   5,  68,   2,   1,   7,   2,   1,  35, 979, 211,   8, 112,\n",
       "         2,   1, 941,   5,   1, 129, 235,   1,   4,  57,  14,  82,  33,\n",
       "        23,   2,   1,   1,   7,   1,   1,   1,   3,  30, 248, 117,  30,\n",
       "        82, 164,   6,   1, 435,   4,  12,  13,   9,  11,  12,  13,   9,\n",
       "        11,  17,  10,   6, 366,   7,  18,  67, 330,   1,   7,   1,   1,\n",
       "        16,  49,   8, 683,   1,   1,   3,   5,   3, 168,  33,   3,  15,\n",
       "        69, 661,   3,   2, 134,  14,  10, 452,   6, 237,  79,  23,   1,\n",
       "       926,  15,   1,  27,   5, 330, 323,   4,   2,   1, 131,   3, 167,\n",
       "         1,   1,  44, 106,   1,  15,   1,  53,   1, 673,   7, 345,   1,\n",
       "         3, 429,  15, 854,   3,   5,  68,   1,   3,  10, 305,   1, 704,\n",
       "         8,   3,   5,  93,   1,   2, 611,   7, 105,   1, 467,   4,   1,\n",
       "        93,  38, 585, 926,  15,   2, 986,   1,   7,   2,  27,  74, 320,\n",
       "         8,  37,   1,   1,   7, 345,   1,  20, 216, 220,   1,  55,   1,\n",
       "       170, 316,   3, 168,  43, 213, 183, 538, 689,  44,   2,  29,   1,\n",
       "         1,  28,   1,   1,   5,   2, 588,   7, 114, 257,   7,   1,   1,\n",
       "         4, 153,  16,  98,  33, 399,   8,   1,   3,   2, 588,   7,   1,\n",
       "         1,   1,  15,  17,  27,  21,   2,  39, 678, 459,  16,  80,  24,\n",
       "        14,   4,  12,  13,   9,  11,  12,  13,   9,  11,  61,  93, 254,\n",
       "        79,  17,  27, 340,   8,   1,   6,   1,   7, 202,   3,   1,   1,\n",
       "         1,  15,  39,   7,  36, 101], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a simple example\n",
    "t_train_x_p[23000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change label to one-hot encoding\n",
    "t_train_y_c = to_categorical(t_train_y, nb_classes=2)\n",
    "t_test_y_c = to_categorical(t_test_y, nb_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(t_train_y_c[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data loading method\n",
    "class IMDBDataset():\n",
    "    def __init__(self, X, Y):\n",
    "        self.data_count = len(X)\n",
    "        self.input = X\n",
    "        self.label = Y\n",
    "        self.ptr = 0\n",
    "        \n",
    "    def minibatch(self, size):\n",
    "        ret = None\n",
    "        \n",
    "        if self.ptr + size < self.data_count:\n",
    "            ret = self.input[self.ptr:(self.ptr + size)], self.label[self.ptr:(self.ptr + size)]\n",
    "        else:\n",
    "            ret = np.concatenate((self.input[self.ptr:], self.input[:size-len(self.input[self.ptr:])])), \\\n",
    "                  np.concatenate((self.label[self.ptr:], self.label[:size-len(self.label[self.ptr:])]))\n",
    "        \n",
    "        self.ptr = (self.ptr + size) % (self.data_count)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
