{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TF2Data_Text.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"klpru-nAvBrQ","colab_type":"text"},"source":["This tutorial guides you on how to load text files via the `tf.data.TextLineDataset` APIs. TextLineDataset is created to load the text file in that each example is the line. In this example, you are going to build a model to classify the different translators.\n","\n","Datasets are: (They have already been preprocessed.)\n","* William Cowper — [text](https://storage.googleapis.com/download.tensorflow.org/data/illiad/cowper.txt)\n","* Edward, Earl of Derby — [text](https://storage.googleapis.com/download.tensorflow.org/data/illiad/derby.txt)\n","* Samuel Butler — [text](https://storage.googleapis.com/download.tensorflow.org/data/illiad/butler.txt)\n","\n","Reference: \n","  * Load Text: https://www.tensorflow.org/tutorials/load_data/text"]},{"cell_type":"code","metadata":{"id":"iNL9C2tWJ7Ti","colab_type":"code","colab":{}},"source":["!pip install -q tf-nightly"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6nTfO-7lKCFb","colab_type":"code","outputId":"76205467-1745-451d-e19b-447ff8213f4c","executionInfo":{"status":"ok","timestamp":1578455780896,"user_tz":-480,"elapsed":7540,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["import tensorflow as tf\n","import tensorflow_datasets as tfds\n","import os\n","import numpy as np\n","\n","print(\"Tensorflow Version: {}\".format(tf.__version__))\n","print(\"Eager Mode: {}\".format(tf.executing_eagerly()))\n","print(\"GPU {} available\".format(\"is\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"not\"))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Tensorflow Version: 2.1.0-dev20200107\n","Eager Mode: True\n","GPU is available\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ROnZIX8awgk8","colab_type":"text"},"source":["# Data Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"1qVzWAy_w5jZ","colab_type":"text"},"source":["## Downloading Datasets"]},{"cell_type":"code","metadata":{"id":"UZMa_EBjKasV","colab_type":"code","colab":{}},"source":["DIRECTORY_URL = 'https://storage.googleapis.com/download.tensorflow.org/data/illiad/'\n","FILE_NAMES = ['cowper.txt', 'derby.txt', 'butler.txt']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dKob95L9wjY_","colab_type":"code","colab":{}},"source":["for name in FILE_NAMES:\n","  text_file = tf.keras.utils.get_file(name, DIRECTORY_URL + name)\n","dirname = os.path.dirname(text_file)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6RlvDWBtwy2S","colab_type":"code","outputId":"ecfac5f6-d9cf-4aa9-d8eb-195e531b690f","executionInfo":{"status":"ok","timestamp":1578455784179,"user_tz":-480,"elapsed":10761,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!ls {dirname}"],"execution_count":5,"outputs":[{"output_type":"stream","text":["butler.txt  cowper.txt\tderby.txt\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MpwPQ-B_w8r9","colab_type":"text"},"source":["## Load the Datasets"]},{"cell_type":"code","metadata":{"id":"9GG7f675w0zX","colab_type":"code","colab":{}},"source":["def labeler(example, index):\n","  return example, tf.cast(index, tf.int32)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zqg-b2ELxcUA","colab_type":"code","colab":{}},"source":["labeled_data_sets = []\n","\n","for i, filename in enumerate(FILE_NAMES):\n","  lines_dataset = tf.data.TextLineDataset(os.path.join(dirname, filename))\n","  labeled_dataset = lines_dataset.map(lambda eg: labeler(eg, i))\n","  labeled_data_sets.append(labeled_dataset)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ScFKOetPyQx-","colab_type":"code","outputId":"ad8d20f5-a0c8-40cb-93b7-bdccf795753e","executionInfo":{"status":"ok","timestamp":1578455784590,"user_tz":-480,"elapsed":11123,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["labeled_data_sets"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<MapDataset shapes: ((), ()), types: (tf.string, tf.int32)>,\n"," <MapDataset shapes: ((), ()), types: (tf.string, tf.int32)>,\n"," <MapDataset shapes: ((), ()), types: (tf.string, tf.int32)>]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"3oPL6545ynaw","colab_type":"text"},"source":["Before you start a training task, you have to combine three text datasets into a bigger one."]},{"cell_type":"code","metadata":{"id":"WNEOjQu7zRBC","colab_type":"code","colab":{}},"source":["BUFFER_SIZE = 50000\n","BATCH_SIZE = 64\n","TAKE_SIZE = 5000"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q7GPcYZOyR6B","colab_type":"code","colab":{}},"source":["all_labeled_data = labeled_data_sets[0]\n","for i in range(1, len(labeled_data_sets)):\n","  all_labeled_data = all_labeled_data.concatenate(labeled_data_sets[i])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zKRcK076zI6O","colab_type":"code","colab":{}},"source":["all_labeled_data = all_labeled_data.shuffle(BUFFER_SIZE, \n","                                            reshuffle_each_iteration=False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UQO30BP8zaJa","colab_type":"text"},"source":["Let's take a look at the combined labeded data."]},{"cell_type":"code","metadata":{"id":"cUNFUcbTzZs6","colab_type":"code","outputId":"42c56504-f32e-4bda-88a2-73285f9dfb3d","executionInfo":{"status":"ok","timestamp":1578455786024,"user_tz":-480,"elapsed":12511,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["for d in all_labeled_data.take(5):\n","  print(d)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["(<tf.Tensor: shape=(), dtype=string, numpy=b'Shouldst not to evil lead the sons of Greece.'>, <tf.Tensor: shape=(), dtype=int32, numpy=1>)\n","(<tf.Tensor: shape=(), dtype=string, numpy=b'To whom thus Hector of the glancing helm,'>, <tf.Tensor: shape=(), dtype=int32, numpy=1>)\n","(<tf.Tensor: shape=(), dtype=string, numpy=b'The warrior ranks, so long he bids thee pause'>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n","(<tf.Tensor: shape=(), dtype=string, numpy=b'\"Be men, my friends,\" he cried, \"and respect one another\\'s good'>, <tf.Tensor: shape=(), dtype=int32, numpy=2>)\n","(<tf.Tensor: shape=(), dtype=string, numpy=b\"In Antron, and in Pteleon's grass-clad meads;\">, <tf.Tensor: shape=(), dtype=int32, numpy=1>)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SAoEXRxK1lhG","colab_type":"text"},"source":["# Encode Text as Numbers"]},{"cell_type":"markdown","metadata":{"id":"bO-K-1n_3bFR","colab_type":"text"},"source":["Before you go further, you have to do one more transformation to the text. Machine Learning or deep learning is using numeric data, however, the text or the word is not a numeric value. You have to transform the text into numbers. In this example, the line dataset is composed of multiple lines, each line also accompanies a label representing the translator. Basically you might think about how to transform the line into a number. In practical, you are going to break down the string into several words and to try to transform a word into a numeric value."]},{"cell_type":"markdown","metadata":{"id":"1Ab5og8z3c4o","colab_type":"text"},"source":["## Building Vocabularies"]},{"cell_type":"markdown","metadata":{"id":"CQpEZrdH4oyQ","colab_type":"text"},"source":["Building vocabularies is to tokenize the text into a collection of individual unique words. There are several steps to follow.\n","* Iterate over all the line example.\n","* Use `tfds.featrures.text.Tokenize` to split the text line into tokens.\n","* Collect the tokens and remove the duplicates.\n","* Get the size of the tokens for later use."]},{"cell_type":"code","metadata":{"id":"IoUuTPJxzi0r","colab_type":"code","outputId":"196a6bd8-f939-4dfd-e1d2-19db6c90622b","executionInfo":{"status":"ok","timestamp":1578455795347,"user_tz":-480,"elapsed":21822,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["tokenizer = tfds.features.text.Tokenizer()\n","\n","vocabulary_set = set()\n","for text_tensor, _ in all_labeled_data:  # _ is the label\n","  tokens = tokenizer.tokenize(text_tensor.numpy())\n","  vocabulary_set.update(tokens)\n","\n","vocab_size = len(vocabulary_set)\n","vocab_size"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["17178"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"wcm631Y-6NKJ","colab_type":"text"},"source":["## Encode Examples\n","\n","After you get a set of tokens, next you need an encoder to encode the token into a numeric value. \n","\n","Send the vocabulary set into `tfds.features.text.TokenTextEncoder` to create a encoder. This encoder helps you to transform a string of the text into a list of integers."]},{"cell_type":"code","metadata":{"id":"pqG3OIIq5f9Y","colab_type":"code","colab":{}},"source":["encoder = tfds.features.text.TokenTextEncoder(vocabulary_set)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xEznCqWV-dmS","colab_type":"text"},"source":["You can try the encoder by passing a string of the text to it."]},{"cell_type":"code","metadata":{"id":"J4ggSGY4-c9Y","colab_type":"code","outputId":"8eb6ef0f-cee6-4eaa-b491-c4c92356ba08","executionInfo":{"status":"ok","timestamp":1578455796877,"user_tz":-480,"elapsed":23327,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["example_text = next(iter(all_labeled_data))[0].numpy()\n","example_text"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["b'Shouldst not to evil lead the sons of Greece.'"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"hGUOAiH7-q_2","colab_type":"code","outputId":"6313cd3b-4b03-4712-b556-2ac75a72a2df","executionInfo":{"status":"ok","timestamp":1578455796878,"user_tz":-480,"elapsed":23315,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["encoded_example = encoder.encode(example_text)\n","print(encoded_example)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["[4180, 12498, 3435, 15171, 2424, 16678, 4564, 1538, 13556]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oWEU7fbQ-_SQ","colab_type":"text"},"source":["You can also decode the encoded list of integers."]},{"cell_type":"code","metadata":{"id":"HxEUCBj4-37G","colab_type":"code","outputId":"3fb2fba6-fee2-415b-b4db-ca0e6770f08a","executionInfo":{"status":"ok","timestamp":1578455796879,"user_tz":-480,"elapsed":23297,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["encoder.decode(encoded_example)"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Shouldst not to evil lead the sons of Greece'"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"mNZ71xf4_TcK","colab_type":"text"},"source":["To merge such operations into a part of the model, you can wrap them via `tf.py_function` as a Tensorflow op and pass the result to the dataset's `map` function."]},{"cell_type":"code","metadata":{"id":"xMkSb3uw--Qm","colab_type":"code","colab":{}},"source":["def encode(text_tensor, label):\n","  encoded_text = encoder.encode(text_tensor.numpy())\n","  return encoded_text, label"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AXcN4tWAAO_1","colab_type":"code","colab":{}},"source":["def encode_map_fn(text, label):\n","  return tf.py_function(encode, inp=[text, label], Tout=(tf.int32, tf.int32))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YTMq040UA-dG","colab_type":"code","outputId":"821bbfbc-8216-4b04-ac56-4432ff4ab19e","executionInfo":{"status":"ok","timestamp":1578455796886,"user_tz":-480,"elapsed":23264,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["all_encoded_data = all_labeled_data.map(encode_map_fn)\n","all_encoded_data"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<MapDataset shapes: (<unknown>, <unknown>), types: (tf.int32, tf.int32)>"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"u_ckobErBPuY","colab_type":"text"},"source":["# Split the Dataset into Train and Test Batches\n","\n","Next, you are going to split the dataset into training and test datasets. The easy way is to access the dataset using the `tf.data.Dataset.take()` and `tf.data.Dataset.skip()` APIs.\n","\n","Typically, the examples inside of a batch are required to be in the same size and the same length. However, the text encoder doesn't guarantee the fixed length of the encoded integer length. Here you can solve the length issue via using the `tf.data.Dataset.padded_batch()` API to pad the examples to the same sizes."]},{"cell_type":"code","metadata":{"id":"bbuSYMJRBLJO","colab_type":"code","colab":{}},"source":["train_data = all_encoded_data.skip(TAKE_SIZE).shuffle(BUFFER_SIZE)\n","train_data = train_data.padded_batch(BATCH_SIZE, padded_shapes=([-1], []))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G3bndyb4I6ON","colab_type":"code","colab":{}},"source":["test_data = all_encoded_data.take(TAKE_SIZE)\n","test_data = test_data.padded_batch(BATCH_SIZE, padded_shapes=([-1], []))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SKORvFazJGP2","colab_type":"code","colab":{}},"source":["sample_text, sample_labels = next(iter(test_data))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q5pe20ukJUxB","colab_type":"code","outputId":"293a7e76-3cc7-4436-b6c5-1b9cb457347e","executionInfo":{"status":"ok","timestamp":1578455798513,"user_tz":-480,"elapsed":24836,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["sample_text[0], sample_labels[0], sample_text.numpy().shape"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<tf.Tensor: shape=(16,), dtype=int32, numpy=\n"," array([ 4180, 12498,  3435, 15171,  2424, 16678,  4564,  1538, 13556,\n","            0,     0,     0,     0,     0,     0,     0], dtype=int32)>,\n"," <tf.Tensor: shape=(), dtype=int32, numpy=1>,\n"," (64, 16))"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"YVfN5fxWJto8","colab_type":"text"},"source":["We have to increase 1 to the vocabulary size because you have introduced a new token (zero for padding)."]},{"cell_type":"code","metadata":{"id":"Ncs0R7SPJmri","colab_type":"code","colab":{}},"source":["vocab_size += 1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vrzpAeliJ_Q0","colab_type":"text"},"source":["# Building the Model"]},{"cell_type":"code","metadata":{"id":"6Lq0A_QWLJmf","colab_type":"code","colab":{}},"source":["def simple_model(inputs):\n","  embed = tf.keras.layers.Embedding(vocab_size, 64)(inputs)\n","\n","  # return_state: True\n","  # [combined_hidden_state, fwd_h_state, fwd_c_state, bck_h_state, bck_c_state]\n","  fwd = tf.keras.layers.LSTM(units=32, return_state=True, name=\"fw\")\n","  bck = tf.keras.layers.LSTM(units=32, go_backwards=True, return_state=True, name=\"bk\")\n","  bd = tf.keras.layers.Bidirectional(fwd, backward_layer=bck)(embed)\n","\n","  x = tf.keras.layers.Dense(32, activation='elu')(bd[0])\n","  x = tf.keras.layers.Dense(32, activation='elu')(x)\n","  y = tf.keras.layers.Dense(3, activation='softmax')(x)\n","  return y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hIKqbcWUJ-Ay","colab_type":"code","colab":{}},"source":["def build_model(inputs):\n","  # inputs: [None, None] (batch_size, padded_size), e.g. (64, 16)\n","\n","  # The first layer is to convert a list of integer representation \n","  # to the dense vector embeddings.\n","  # embed: [None, None, 64], (batch_size, padded_size, embedding_vector)\n","  embed = tf.keras.layers.Embedding(vocab_size, 64)(inputs)\n","\n","  # The next layer is a RNN layer with the Long Short-Term Memory, which lets the model \n","  # learn the word in their context with other words. \n","  # A bidirectional mechanism is designed to learn the datapoints \n","  # in the relationship with ones that came after them or before them.\n","  # [None, None, 64*2] (batch_size, padded_size, output_dim)\n","  fwd = tf.keras.layers.LSTM(units=64, return_sequences=True)\n","  bck = tf.keras.layers.LSTM(units=64, go_backwards=True, return_sequences=True)\n","  x = tf.keras.layers.Bidirectional(fwd, backward_layer=bck)(embed)\n","\n","  # add a TimeDistributed layer\n","  # [None, None, 64*2] -> [None, None, 64]\n","  x = tf.keras.layers.TimeDistributed(\n","        tf.keras.layers.Dense(64), input_shape=(None, 128)\n","      )(x)\n","\n","  # automatically generate a backward LSTM layer\n","  # x: [None, 32*2]  \n","  x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=32, return_sequences=False))(x)\n","\n","  x = tf.keras.layers.Dense(units=64, activation='elu')(x)\n","  x = tf.keras.layers.Dense(units=64, activation='elu')(x)\n","\n","  # The final layer is the categorical result.\n","  y = tf.keras.layers.Dense(units=3, activation='softmax')(x)\n","  return y"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RoSyt2pFTkXx","colab_type":"text"},"source":["While you are going to build an input whose time point is variant, you can assign its shape with `(None,)` or `[None]`."]},{"cell_type":"code","metadata":{"id":"HfLwRffHUbq2","colab_type":"code","colab":{}},"source":["def build_compile_model():\n","  inputs = tf.keras.layers.Input(shape=(None,))  # variant length of time points\n","  outputs = build_model(inputs)\n","  #outputs = simple_model(inputs)\n","  model = tf.keras.Model(inputs, outputs)\n","\n","  model.compile(loss='sparse_categorical_crossentropy', \n","                optimizer='adam', \n","                metrics=[\"accuracy\"])\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kW9Lte8NU-9d","colab_type":"text"},"source":["# Train the Model"]},{"cell_type":"code","metadata":{"id":"Q6jmQaM1U9HN","colab_type":"code","colab":{}},"source":["model = build_compile_model()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cMN1hYiqVDib","colab_type":"code","outputId":"37cadd41-9bc4-4da9-f022-786d952ce101","executionInfo":{"status":"ok","timestamp":1578455800358,"user_tz":-480,"elapsed":26596,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}},"colab":{"base_uri":"https://localhost:8080/","height":425}},"source":["model.summary()"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, None)]            0         \n","_________________________________________________________________\n","embedding (Embedding)        (None, None, 64)          1099456   \n","_________________________________________________________________\n","bidirectional (Bidirectional (None, None, 128)         66048     \n","_________________________________________________________________\n","time_distributed (TimeDistri (None, None, 64)          8256      \n","_________________________________________________________________\n","bidirectional_1 (Bidirection (None, 64)                24832     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 64)                4160      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 64)                4160      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 3)                 195       \n","=================================================================\n","Total params: 1,207,107\n","Trainable params: 1,207,107\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FesZKko1DcAJ","colab_type":"code","colab":{}},"source":["!rm -rf ./log ./log.zip\n","tfb = tf.keras.callbacks.TensorBoard('./log', write_graph=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uE6xX92bW294","colab_type":"code","outputId":"ed1c1647-ec11-4746-97be-88aa33b5dd96","executionInfo":{"status":"ok","timestamp":1578455888824,"user_tz":-480,"elapsed":115023,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["model.fit(train_data, epochs=2, validation_data=test_data, callbacks=[tfb])"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Epoch 1/2\n","697/697 [==============================] - 47s 68ms/step - loss: 0.5004 - accuracy: 0.7577 - val_loss: 0.3965 - val_accuracy: 0.8170\n","Epoch 2/2\n","697/697 [==============================] - 38s 55ms/step - loss: 0.2912 - accuracy: 0.8735 - val_loss: 0.3611 - val_accuracy: 0.8378\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f8870050860>"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"iwl9pSAkXCuO","colab_type":"code","outputId":"d9bc6ffc-18fc-49f5-a364-b60171ab43e7","executionInfo":{"status":"ok","timestamp":1578455892330,"user_tz":-480,"elapsed":118513,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["loss, acc = model.evaluate(test_data, verbose=2)\n","print(\"Loss: {}, Acc: {}\".format(loss, acc))"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Loss: 0.3610934236004383, Acc: 0.8378000259399414\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n3gwdK_xXHaS","colab_type":"code","outputId":"9c4f2848-8660-4d91-a129-defbf734a244","executionInfo":{"status":"ok","timestamp":1578455892331,"user_tz":-480,"elapsed":118499,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["model.inputs, model.input_shape"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([<tf.Tensor 'input_1:0' shape=(None, None) dtype=float32>], (None, None))"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"iD_rGaYyWAhp","colab_type":"code","outputId":"672a8aac-f769-48bb-8ce7-9ce496f3fe73","executionInfo":{"status":"ok","timestamp":1578455892332,"user_tz":-480,"elapsed":118488,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}},"colab":{"base_uri":"https://localhost:8080/","height":374}},"source":["for w in model.weights:\n","  print(w.name, w.numpy().shape)"],"execution_count":35,"outputs":[{"output_type":"stream","text":["embedding/embeddings:0 (17179, 64)\n","bidirectional/forward_lstm/kernel:0 (64, 256)\n","bidirectional/forward_lstm/recurrent_kernel:0 (64, 256)\n","bidirectional/forward_lstm/bias:0 (256,)\n","bidirectional/backward_lstm_1/kernel:0 (64, 256)\n","bidirectional/backward_lstm_1/recurrent_kernel:0 (64, 256)\n","bidirectional/backward_lstm_1/bias:0 (256,)\n","time_distributed/kernel:0 (128, 64)\n","time_distributed/bias:0 (64,)\n","bidirectional_1/forward_lstm_2/kernel:0 (64, 128)\n","bidirectional_1/forward_lstm_2/recurrent_kernel:0 (32, 128)\n","bidirectional_1/forward_lstm_2/bias:0 (128,)\n","bidirectional_1/backward_lstm_2/kernel:0 (64, 128)\n","bidirectional_1/backward_lstm_2/recurrent_kernel:0 (32, 128)\n","bidirectional_1/backward_lstm_2/bias:0 (128,)\n","dense_1/kernel:0 (64, 64)\n","dense_1/bias:0 (64,)\n","dense_2/kernel:0 (64, 64)\n","dense_2/bias:0 (64,)\n","dense_3/kernel:0 (64, 3)\n","dense_3/bias:0 (3,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iQmBdPttXqua","colab_type":"text"},"source":["# Prediction"]},{"cell_type":"code","metadata":{"id":"S5KQZ7XsYL6o","colab_type":"code","colab":{}},"source":["pred_data = next(iter(test_data))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a1tqX70fYPmA","colab_type":"code","outputId":"967b06ac-1bae-4d4f-8c52-0da99fefb8d6","executionInfo":{"status":"ok","timestamp":1578455894355,"user_tz":-480,"elapsed":120400,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["pred_data[1][:10]"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(10,), dtype=int32, numpy=array([1, 1, 0, 2, 1, 0, 1, 1, 0, 0], dtype=int32)>"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"lHWXahlbZc5S","colab_type":"code","outputId":"e4a40bed-ac92-4b07-9802-cdee590466ec","executionInfo":{"status":"ok","timestamp":1578455894982,"user_tz":-480,"elapsed":121017,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["res = model.predict(pred_data[0][:10])\n","res, np.argmax(res, axis=-1)"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([[1.9283679e-01, 8.0536532e-01, 1.7978031e-03],\n","        [4.2089685e-03, 9.9565923e-01, 1.3192077e-04],\n","        [6.7608112e-01, 3.2349932e-01, 4.1960593e-04],\n","        [1.5656850e-03, 6.1565783e-02, 9.3686849e-01],\n","        [6.2814735e-02, 9.3648571e-01, 6.9956860e-04],\n","        [6.7881286e-01, 3.2110366e-01, 8.3420586e-05],\n","        [9.2930514e-03, 9.8990750e-01, 7.9939817e-04],\n","        [1.7776463e-02, 9.8162490e-01, 5.9868390e-04],\n","        [9.7273493e-01, 2.7182616e-02, 8.2438797e-05],\n","        [9.1961706e-01, 7.8422263e-02, 1.9606927e-03]], dtype=float32),\n"," array([1, 1, 0, 2, 1, 0, 1, 1, 0, 0]))"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"oXCJCzxSb-7h","colab_type":"code","outputId":"77156d75-1fc2-4af4-eaf3-6c734b96bf0b","executionInfo":{"status":"ok","timestamp":1578455894985,"user_tz":-480,"elapsed":121006,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["for_pd = pred_data[0][0].numpy()\n","for_pd, for_pd.shape"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([ 4180, 12498,  3435, 15171,  2424, 16678,  4564,  1538, 13556,\n","            0,     0,     0,     0,     0,     0,     0], dtype=int32), (16,))"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"iKE6jEVepFPr","colab_type":"code","outputId":"b5fc47d7-6b08-4ddd-9d10-1badbfe533bd","executionInfo":{"status":"ok","timestamp":1578455894985,"user_tz":-480,"elapsed":120995,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["model.predict(np.expand_dims(for_pd, axis=0))"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.19283688, 0.8053653 , 0.0017978 ]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"CZ5xgLTLpVOJ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}