{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `tflite_convert`: Starting from `TensorFlow 1.9`, the command-line tool tflite_convert is installed as part of the Python package. All of the examples below use tflite_convert for simplicity.\n",
    "    * Example: `tflite_convert --output_file=...`\n",
    "    \n",
    "* `bazel`: In order to run the latest version of the TensorFlow Lite Converter either install the nightly build using pip or clone the TensorFlow repository and use bazel.\n",
    "    * Example: `bazel run //tensorflow/contrib/lite/python:tflite_convert -- --output_file=...`\n",
    "    \n",
    "* `Python API`: Tensroflow version < 1.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert a TensorFlow GraphDef\n",
    "\n",
    "Make sure the frozen model file `.pb` is exported from [freeze_graph.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "# you can download the example model \n",
    "curl https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_0.50_128_frozen.tgz \\\n",
    "  | tar xzv -C /tmp \n",
    "  \n",
    "# convert the model to tflite\n",
    "tflite_convert \\\n",
    "    --output_file=/tmp/foo.tflite \\\n",
    "    --graph_def_file=/tmp/mobilenet_v1_0.50_128/frozen_graph.pb \\\n",
    "    --input_arrays=input \\\n",
    "    --output_arrays=MobilenetV1/Predictions/Reshape_1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert from SavedModel\n",
    "\n",
    "`SaveModel` is the checkpoint-based way to conserve the model. Usually it is the folder conversing a checkpoint, and lots of `.ckpt` or `ckpt-{epoch}` style filename of files.\n",
    "\n",
    "The values for `--input_arrays` and `--output_arrays` are an aggregated, alphabetized list of the inputs and outputs in the SignatureDefs within the `MetaGraphDef` specified by `--saved_model_tag_set`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "tflite_convert \\\n",
    "    --output_file=/tmp/foo.tflite \\\n",
    "    --saved_model_dir=/tmp/saved_model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conver from `tf.keras` model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "tflite_convert \\\n",
    "    --output_file=/tmp/foo.tflite \\\n",
    "    --keras_model_file=/tmp/keras_model.h5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TensorFlow Lite Converter is compatible with fixed point quantization models. (refer to webpage: https://www.tensorflow.org/performance/quantization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UINT8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "tflite_convert \\\n",
    "    --output_file=/tmp/foo.tflite \\\n",
    "    --graph_def_file=/tmp/some_quantized_graph.pb \\\n",
    "    --inference_type=QUANTIZED_UINT8 \\\n",
    "    --input_arrays=input \\\n",
    "    --output_arrays=MobilenetV1/Predictions/Reshape_1 \\\n",
    "    --mean_values=128 \\\n",
    "    --std_dev_values=127\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy-quantization\n",
    "\n",
    "\"Dummy-quantization\" will produce lower accuracy but will emulate the performance of a correctly quantized model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "curl https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_0.50_128_frozen.tgz \\\n",
    "    | tar xzv -C /tmp\n",
    "tflite_convert \\\n",
    "    --output_file=/tmp/foo.cc \\\n",
    "    --graph_def_file=/tmp/mobilenet_v1_0.50_128/frozen_graph.pb \\\n",
    "    --inference_type=QUANTIZED_UINT8 \\\n",
    "    --input_arrays=input \\\n",
    "    --output_arrays=MobilenetV1/Predictions/Reshape_1 \\\n",
    "    --default_ranges_min=0 \\\n",
    "    --default_ranges_max=6 \\\n",
    "    --mean_values=128 \\\n",
    "    --std_dev_values=127\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Input/Output Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Input Arrays\n",
    "\n",
    "Note the `input_shape` is `colon-separated` list, the `input_array` is `comma-separated` list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "curl https://storage.googleapis.com/download.tensorflow.org/models/inception_v1_2016_08_28_frozen.pb.tar.gz \\\n",
    "  | tar xzv -C /tmp\n",
    "tflite_convert \\\n",
    "    --graph_def_file=/tmp/inception_v1_2016_08_28_frozen.pb \\\n",
    "    --output_file=/tmp/foo.tflite \\\n",
    "    --input_shapes=1,28,28,96:1,28,28,16:1,28,28,192:1,28,28,64 \\\n",
    "    --input_arrays=InceptionV1/InceptionV1/Mixed_3b/Branch_1/Conv2d_0a_1x1/Relu,InceptionV1/InceptionV1/Mixed_3b/Branch_2/Conv2d_0a_1x1/Relu,InceptionV1/InceptionV1/Mixed_3b/Branch_3/MaxPool_0a_3x3/MaxPool,InceptionV1/InceptionV1/Mixed_3b/Branch_0/Conv2d_0a_1x1/Relu \\\n",
    "    --output_arrays=InceptionV1/Logits/Predictions/Reshape_1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Output Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "curl https://storage.googleapis.com/download.tensorflow.org/models/inception_v1_2016_08_28_frozen.pb.tar.gz \\\n",
    "  | tar xzv -C /tmp\n",
    "tflite_convert \\\n",
    "  --graph_def_file=/tmp/inception_v1_2016_08_28_frozen.pb \\\n",
    "  --output_file=/tmp/foo.tflite \\\n",
    "  --input_arrays=input \\\n",
    "  --output_arrays=InceptionV1/InceptionV1/Mixed_3b/Branch_1/Conv2d_0a_1x1/Relu,InceptionV1/InceptionV1/Mixed_3b/Branch_2/Conv2d_0a_1x1/Relu\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying subgraphs\n",
    "\n",
    "Any array in the input file can be specified as an input or output array in order to extract subgraphs out of an input graph file. The TensorFlow Lite Converter discards the parts of the graph outside of the specific subgraph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "curl https://storage.googleapis.com/download.tensorflow.org/models/inception_v1_2016_08_28_frozen.pb.tar.gz \\\n",
    "  | tar xzv -C /tmp\n",
    "tflite_convert \\\n",
    "  --graph_def_file=/tmp/inception_v1_2016_08_28_frozen.pb \\\n",
    "  --output_file=/tmp/foo.pb \\\n",
    "  --input_shapes=1,28,28,96:1,28,28,16:1,28,28,192:1,28,28,64 \\\n",
    "  --input_arrays=InceptionV1/InceptionV1/Mixed_3b/Branch_1/Conv2d_0a_1x1/Relu,InceptionV1/InceptionV1/Mixed_3b/Branch_2/Conv2d_0a_1x1/Relu,InceptionV1/InceptionV1/Mixed_3b/Branch_3/MaxPool_0a_3x3/MaxPool,InceptionV1/InceptionV1/Mixed_3b/Branch_0/Conv2d_0a_1x1/Relu \\\n",
    "  --output_arrays=InceptionV1/InceptionV1/Mixed_3b/concat_v2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can convert or export the graph visualization and please refer to official document link https://www.tensorflow.org/lite/convert/cmdline_examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
