{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TensorflowLite_API.ipynb","version":"0.3.2","provenance":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.4"},"kernelspec":{"display_name":"Python [default]","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"-83zG6gkIFYv","colab_type":"text"},"source":["# Overview"]},{"cell_type":"markdown","metadata":{"id":"luMC3pGWIFYw","colab_type":"text"},"source":["![Tensorflow Lite](https://www.tensorflow.org/lite/images/convert/workflow.svg)"]},{"cell_type":"markdown","metadata":{"id":"6uXb0vbiIFYw","colab_type":"text"},"source":["# API Level"]},{"cell_type":"markdown","metadata":{"id":"XQKh_HXZIFYx","colab_type":"text"},"source":["**Basic Requirement: tensorflow version >= 1.9.0**\n","\n","* `tf.contrib.lite.TFLiteConverter`: convert tensorflow models to tensor flow lite\n","    * `TFLiteConverter` provides class methods based on the original format of the model.\n","    * `TFLiteConverter.from_session()` is available for GraphDefs.\n","    * `TFLiteConverter.from_saved_model()` is available for SavedModels.\n","    * `TFLiteConverter.from_keras_model_file()` is available for `tf.Keras` files.\n","* `tf.contrib.lite.Interpreter`: calling Python interpreter"]},{"cell_type":"markdown","metadata":{"id":"JNRPCttUIFYy","colab_type":"text"},"source":["# Converting Example"]},{"cell_type":"markdown","metadata":{"id":"5EaCKBnVIFYy","colab_type":"text"},"source":["## Exporting a GraphDef from tf.Session\n","\n","Convert a Tensorflow GraphDef into a Tensorflow Lite Flatbuffer from a `tf.Session` object."]},{"cell_type":"code","metadata":{"id":"9BEqX0QcIFYz","colab_type":"code","colab":{},"outputId":"9aa32b16-f6d1-4942-b053-a2cba7ac2e46"},"source":["# if you encounter module 'tensorflow.contrib.lite.python.lite' has no attribute 'TFLiteConverter'\n","!pip install tf_nightly"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tf_nightly in /anaconda3/lib/python3.6/site-packages (1.13.0.dev20181101)\n","Requirement already satisfied: tb-nightly<1.14.0a0,>=1.13.0a0 in /anaconda3/lib/python3.6/site-packages (from tf_nightly) (1.13.0a20181101)\n","Requirement already satisfied: protobuf>=3.6.1 in /anaconda3/lib/python3.6/site-packages (from tf_nightly) (3.6.1)\n","Requirement already satisfied: termcolor>=1.1.0 in /anaconda3/lib/python3.6/site-packages (from tf_nightly) (1.1.0)\n","Requirement already satisfied: absl-py>=0.1.6 in /anaconda3/lib/python3.6/site-packages (from tf_nightly) (0.5.0)\n","Requirement already satisfied: wheel>=0.26 in /anaconda3/lib/python3.6/site-packages (from tf_nightly) (0.32.0)\n","Requirement already satisfied: numpy>=1.13.3 in /anaconda3/lib/python3.6/site-packages (from tf_nightly) (1.14.3)\n","Requirement already satisfied: gast>=0.2.0 in /anaconda3/lib/python3.6/site-packages (from tf_nightly) (0.2.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /anaconda3/lib/python3.6/site-packages (from tf_nightly) (1.15.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /anaconda3/lib/python3.6/site-packages (from tf_nightly) (1.0.6)\n","Requirement already satisfied: tensorflow-estimator>=1.10.0 in /anaconda3/lib/python3.6/site-packages (from tf_nightly) (1.10.12)\n","Requirement already satisfied: six>=1.10.0 in /anaconda3/lib/python3.6/site-packages (from tf_nightly) (1.11.0)\n","Requirement already satisfied: astor>=0.6.0 in /anaconda3/lib/python3.6/site-packages (from tf_nightly) (0.7.1)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /anaconda3/lib/python3.6/site-packages (from tf_nightly) (1.0.5)\n","Requirement already satisfied: markdown>=2.6.8 in /anaconda3/lib/python3.6/site-packages (from tb-nightly<1.14.0a0,>=1.13.0a0->tf_nightly) (3.0.1)\n","Requirement already satisfied: werkzeug>=0.11.10 in /anaconda3/lib/python3.6/site-packages (from tb-nightly<1.14.0a0,>=1.13.0a0->tf_nightly) (0.14.1)\n","Requirement already satisfied: setuptools in /anaconda3/lib/python3.6/site-packages (from protobuf>=3.6.1->tf_nightly) (39.1.0)\n","Requirement already satisfied: h5py in /anaconda3/lib/python3.6/site-packages (from keras-applications>=1.0.6->tf_nightly) (2.7.1)\n","Requirement already satisfied: mock>=2.0.0 in /anaconda3/lib/python3.6/site-packages (from tensorflow-estimator>=1.10.0->tf_nightly) (2.0.0)\n","Requirement already satisfied: pbr>=0.11 in /anaconda3/lib/python3.6/site-packages (from mock>=2.0.0->tensorflow-estimator>=1.10.0->tf_nightly) (5.1.0)\n","\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n","You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RKEpARA0IFY6","colab_type":"code","colab":{},"outputId":"efbf89ff-158c-435b-9047-b6f140555deb"},"source":["import tensorflow as tf\n","\n","def sessionExport():\n","    img = tf.placeholder(name=\"img\", dtype=tf.float32, shape=(1, 64, 64, 3))\n","    var = tf.get_variable(\"weights\", dtype=tf.float32, shape=(1, 64, 64, 3))\n","    val = img + var\n","    out = tf.identity(val, name=\"out\")\n","\n","    with tf.Session() as sess:\n","        sess.run(tf.global_variables_initializer())\n","        converter = tf.contrib.lite.TFLiteConverter.from_session(sess, [img], [out])\n","        tflite_model = converter.convert()\n","        open(\"converted_model.tflite\", \"wb\").write(tflite_model)\n","        \n","#sessionExport()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n","  from ._conv import register_converters as _register_converters\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Znb0t_m5IFY9","colab_type":"text"},"source":["## Exporting a GraphDef from file\n","\n","Convert a Tensorflow GraphDef stored in a file (`.pb` or `.pbtxt`) into Tensorflow Lite FlatBuffer.\n","\n","You can download a frozen example model from \n","https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_1.0_224_frozen.tgz\n","\n","if you prepare the your own model, please make sure using [freeze_graph.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py) to freeze the model."]},{"cell_type":"code","metadata":{"id":"CkwyMr0JIFY-","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","\n","def frozenExport():\n","    graph_def_file = \"./mobilenet_v1_1.0_224/frozen_graph.pb\"\n","    input_arrays = [\"input\"]\n","    output_arrays = [\"MobilenetV1/Predictions/Softmax\"]\n","\n","    converter = tf.contrib.lite.TFLiteConverter.from_frozen_graph(graph_def_file, input_arrays, output_arrays)\n","    tflite_model = converter.convert()\n","    open(\"converted_model.tflite\", \"wb\").write(tflite_model)\n","    \n","#frozenExport()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2lexCJ-eIFZB","colab_type":"text"},"source":["## Exporting a SavedModel"]},{"cell_type":"markdown","metadata":{"id":"Qy8MPTV8IFZB","colab_type":"text"},"source":["`SaveModel` is the checkpoint-based way to conserve the model. Usually it is the folder conversing a checkpoint, and lots of `.ckpt` or `ckpt-{epoch}` style filename of files.\n","\n","For more complex SavedModels, the optional parameters that can be passed into `TFLiteConverter.from_saved_model()` are `input_arrays`, `input_shapes`, `output_arrays`, `tag_set` and `signature_key`. Details of each parameter are available by running `help(tf.contrib.lite.TFLiteConverter)`."]},{"cell_type":"code","metadata":{"id":"HAw_c0aaIFZC","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","\n","def ckptExport():\n","    converter = tf.contrib.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n","    tflite_model = converter.convert()\n","    open(\"converted_model.tflite\", \"wb\").write(tflite_model)\n","\n","#ckptExport()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ftGWp93jIFZE","colab_type":"text"},"source":["## Export a tf.keras file"]},{"cell_type":"code","metadata":{"id":"Ik-0Czu1IFZF","colab_type":"code","colab":{},"outputId":"e4ab87bd-4ea4-426e-bed7-e4c58806a2b8"},"source":["# make sure you have installed h5py\n","!pip install h5py"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: h5py in /anaconda3/lib/python3.6/site-packages (2.7.1)\n","Requirement already satisfied: numpy>=1.7 in /anaconda3/lib/python3.6/site-packages (from h5py) (1.14.3)\n","Requirement already satisfied: six in /anaconda3/lib/python3.6/site-packages (from h5py) (1.11.0)\n","\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n","You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O8Apth9VIFZI","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","\n","def h5Export():\n","    converter = tf.contrib.lite.TFLiteConverter.from_keras_model_file(\"keras_model.h5\")\n","    tflite_model = converter.convert()\n","    open(\"converted_model.tflite\", \"wb\").write(tflite_model)\n","    \n","#h5Export()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SkWmpgV4IFZK","colab_type":"text"},"source":["## Export a tf.keras network\n","\n","You have to export the `.h5` file first and then convert it into tensorflow lite."]},{"cell_type":"code","metadata":{"id":"XfbtcTXkIFZL","colab_type":"code","colab":{}},"source":["import numpy as np\n","import tensorflow as tf\n","\n","def kerasExport():\n","    # Generate tf.keras model.\n","    model = tf.keras.models.Sequential()\n","    model.add(tf.keras.layers.Dense(2, input_shape=(3,)))\n","    model.add(tf.keras.layers.RepeatVector(3))\n","    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(3)))\n","    model.compile(loss=tf.keras.losses.MSE,\n","                  optimizer=tf.keras.optimizers.RMSprop(lr=0.0001),\n","                  metrics=[tf.keras.metrics.categorical_accuracy],\n","                  sample_weight_mode='temporal')\n","\n","    x = np.random.random((1, 3))\n","    y = np.random.random((1, 3, 3))\n","    model.train_on_batch(x, y)\n","    model.predict(x)\n","\n","    # Save tf.keras model in HDF5 format.\n","    keras_file = \"keras_model.h5\"\n","    tf.keras.models.save_model(model, keras_file)\n","\n","    # Convert to TensorFlow Lite model.\n","    converter = tf.contrib.lite.TFLiteConverter.from_keras_model_file(keras_file)\n","    tflite_model = converter.convert()\n","    open(\"converted_model.tflite\", \"wb\").write(tflite_model)\n","\n","#kerasExport()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fNQT9PScIFZO","colab_type":"text"},"source":["# Adcanced Converting"]},{"cell_type":"markdown","metadata":{"id":"6xYFqhVEIFZP","colab_type":"text"},"source":["## Quantized GraphDef"]},{"cell_type":"code","metadata":{"id":"FI0G-5rgIFZQ","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","\n","def quantExport():\n","    img = tf.placeholder(name=\"img\", dtype=tf.float32, shape=(1, 64, 64, 3))\n","    const = tf.constant([1., 2., 3.]) + tf.constant([1., 4., 4.])\n","    val = img + const\n","    out = tf.fake_quant_with_min_max_args(val, min=0., max=1., name=\"output\")\n","\n","    with tf.Session() as sess:\n","        converter = tf.contrib.lite.TFLiteConverter.from_session(sess, [img], [out])\n","        # you have to transform int into QUANTIZED_UINT8 before exporting\n","        converter.inference_type = tf.contrib.lite.constants.QUANTIZED_UINT8\n","        input_arrays = converter.get_input_arrays()\n","        converter.quantized_input_stats = {input_arrays[0] : (0., 1.)}  # mean, std_dev\n","        tflite_model = converter.convert()\n","        open(\"converted_model.tflite\", \"wb\").write(tflite_model)\n","        \n","#quantExport()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vrcqUGIwIFZT","colab_type":"text"},"source":["# Tensorflow Lite Python Interpreter\n","\n","## Load and use a `.tflite` model"]},{"cell_type":"code","metadata":{"id":"zrjruxs7IFZT","colab_type":"code","colab":{},"outputId":"382dd212-6c1f-419b-8e0d-0c9056b5d45c"},"source":["import numpy as np\n","import os\n","import tensorflow as tf\n","\n","def tfLitePyInterpreter(tflitefile):\n","    # Load TFLite model and allocate tensors.\n","    interpreter = tf.contrib.lite.Interpreter(model_path=tflitefile)\n","    interpreter.allocate_tensors()\n","\n","    # Get input and output tensors.\n","    input_details = interpreter.get_input_details()\n","    output_details = interpreter.get_output_details()\n","\n","    # Test model on random input data.\n","    input_shape = input_details[0]['shape']\n","    input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n","    interpreter.set_tensor(input_details[0]['index'], input_data)\n","    print(input_shape)\n","    print(output_details[0]['shape'])\n","\n","    interpreter.invoke()\n","    output_data = interpreter.get_tensor(output_details[0]['index'])\n","    print(np.argmax(output_data, 1))\n","    \n","tflitefile = os.path.join(\"/Users/jiankaiwang/Google_Drive_Devops_Sync/sophia/tmp/converted_model.tflite\")\n","assert os.path.exists(tflitefile), \"no such tflite file\"\n","tfLitePyInterpreter(tflitefile)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[  1 224 224   3]\n","[   1 1001]\n","[311]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q_qtcEFnIFZX","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}