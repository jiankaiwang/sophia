{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"TensorflowServing_ImageExample.ipynb","provenance":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"e7nDQJwEd-Ug","colab_type":"text"},"source":["# Tensorflow Serving for Image Recognition"]},{"cell_type":"code","metadata":{"id":"oCFmbDZrd-Uj","colab_type":"code","colab":{},"outputId":"ae5234ab-83ec-428f-d09d-6745eeb104c9"},"source":["import tensorflow as tf\n","import tensorflow_model_analysis as tfma\n","import os\n","import cv2\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import base64\n","\n","print(\"TF Version: {}\".format(tf.__version__))\n","print(\"Numpy Version: {}\".format(np.__version__))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TF Version: 1.14.0\n","Numpy Version: 1.17.3\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XGrs5UIZd-Un","colab_type":"text"},"source":["## Data Preparation"]},{"cell_type":"code","metadata":{"id":"Rr5wcHhXd-Uo","colab_type":"code","colab":{}},"source":["from tensorflow.examples.tutorials.mnist import input_data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OexJTDCBd-Us","colab_type":"code","colab":{},"outputId":"c64274c9-959b-43c6-f5d7-b277f54e9d39"},"source":["if os.path.exists(\"/Users/jiankaiwang/devops/tmp/MNIST_data/\"):\n","  mnist = input_data.read_data_sets(\"/Users/jiankaiwang/devops/tmp/MNIST_data/\", one_hot=True)\n","else:\n","  mnist = input_data.read_data_sets(\"/tmp/MNIST_data/\", one_hot=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-4-bc4a15cc9771>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n","WARNING:tensorflow:From /Users/jiankaiwang/devops/pyenv/tfx/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please write your own downloading logic.\n","WARNING:tensorflow:From /Users/jiankaiwang/devops/pyenv/tfx/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","Extracting /Users/jiankaiwang/devops/tmp/MNIST_data/train-images-idx3-ubyte.gz\n","WARNING:tensorflow:From /Users/jiankaiwang/devops/pyenv/tfx/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","Extracting /Users/jiankaiwang/devops/tmp/MNIST_data/train-labels-idx1-ubyte.gz\n","WARNING:tensorflow:From /Users/jiankaiwang/devops/pyenv/tfx/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.one_hot on tensors.\n","Extracting /Users/jiankaiwang/devops/tmp/MNIST_data/t10k-images-idx3-ubyte.gz\n","Extracting /Users/jiankaiwang/devops/tmp/MNIST_data/t10k-labels-idx1-ubyte.gz\n","WARNING:tensorflow:From /Users/jiankaiwang/devops/pyenv/tfx/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PjJANoced-Uv","colab_type":"code","colab":{}},"source":["def _bytes_feature(value):\n","  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n","  if isinstance(value, type(tf.constant(0))):\n","    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n","  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n","\n","def _float_feature(value):\n","  \"\"\"Returns a float_list from a float / double.\"\"\"\n","  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n","\n","def _int64_feature(value):\n","  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n","  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5EMoHST5d-Uy","colab_type":"code","colab":{}},"source":["def create_tf_example(imgInByte, labelInByte):\n","    tf_example = tf.train.Example(features=tf.train.Features(feature={\\\n","    'image': _bytes_feature(imgInByte) \\\n","    , 'label': _bytes_feature(labelInByte) \\\n","    }))\n","    return tf_example"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mGtJkPj3d-U1","colab_type":"code","colab":{}},"source":["def Base64Converter(byte_string):\n","    _byteStr = base64.b64encode(byte_string)\n","    return _byteStr[:-2].replace(b\"+\", b\"-\").replace(b\"/\", b\"_\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lchiGUVSd-U3","colab_type":"code","colab":{}},"source":["with tf.python_io.TFRecordWriter(\"/Users/jiankaiwang/Desktop/mnist_test.tfrecord\") as writer:\n","    for i in range(mnist.test.num_examples):\n","        writer.write(\n","            create_tf_example(\n","                Base64Converter(mnist.test.images[i].astype(\"float32\").tobytes()),  # [None, 784]\n","                Base64Converter(mnist.test.labels[i].astype(\"float32\").tobytes())   # [None, 10]\n","            ).SerializeToString()\n","        )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8LZBCgZld-U5","colab_type":"code","colab":{}},"source":["def writeTFRecords(obj):\n","    obj.write(\n","        create_tf_example(\n","            Base64Converter(mnist.test.images[i].astype(\"float32\").tobytes()),  # [None, 784]\n","            Base64Converter(mnist.test.labels[i].astype(\"float32\").tobytes())   # [None, 10]\n","        ).SerializeToString()\n","    )\n","\n","with tf.python_io.TFRecordWriter(\"/Users/jiankaiwang/Desktop/mnist_test_1.tfrecord\") as writer1:\n","    with tf.python_io.TFRecordWriter(\"/Users/jiankaiwang/Desktop/mnist_test_2.tfrecord\") as writer2:\n","        for i in range(mnist.test.num_examples):\n","            if i % 2 == 0:\n","                writeTFRecords(writer1)\n","            else:\n","                writeTFRecords(writer2)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qAFADh_Gd-U7","colab_type":"text"},"source":["## Model Generation"]},{"cell_type":"markdown","metadata":{"id":"8OnynJoHd-U9","colab_type":"text"},"source":["### Quick Test between np.tobytes() and tf.decode_raw()"]},{"cell_type":"code","metadata":{"id":"3Xh4gj52d-U-","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z8AjKyaBd-VA","colab_type":"code","colab":{},"outputId":"6f9bba5c-e963-4f70-9fe1-e6649c2b2727"},"source":["_img = mnist.test.images[0]\n","img = np.reshape(_img, [28,28])\n","plt.imshow(img)\n","img_ = img.tobytes()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"1CRXDe39d-VE","colab_type":"code","colab":{},"outputId":"3a9cb6e7-bcf2-4de1-91d0-042d546fa36f"},"source":["tf.reset_default_graph()\n","with tf.Graph().as_default():\n","    img_p = tf.io.decode_raw(img_, tf.float32)\n","    with tf.Session() as sess:\n","        decode_img = sess.run(img_p)\n","        decode_img = np.reshape(decode_img, [28,28])\n","\n","plt.imshow(decode_img)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x14307fdd8>"]},"metadata":{"tags":[]},"execution_count":10},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"TrEYtuWud-VH","colab_type":"text"},"source":["### Quick Test between np.tobytes() and tf.decode_base64()"]},{"cell_type":"code","metadata":{"id":"3WtD_EUZd-VI","colab_type":"code","colab":{},"outputId":"b2b20cd9-7d3a-4cfb-8d26-0bca39143976"},"source":["img_b64_es = base64.b64encode(mnist.test.images[0].astype(\"float32\").tobytes())\n","img_b64_ds = base64.b64decode(img_b64_es)\n","img_d = np.frombuffer(img_b64_ds, dtype=\"float32\")\n","img_d_shape = img_d.reshape([28, 28])\n","plt.imshow(img_d_shape, cmap=\"gray\")"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x13d5c5668>"]},"metadata":{"tags":[]},"execution_count":11},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"x_2eCpeWd-VK","colab_type":"code","colab":{},"outputId":"4de5665e-7153-4b09-ee5b-bbccc0c9dbd7"},"source":["tf.reset_default_graph()\n","\n","with tf.Graph().as_default():\n","    img = tf.placeholder(tf.string)\n","    b64s = tf.io.encode_base64(img)\n","    encoded_image = tf.io.decode_base64(b64s)\n","    with tf.Session() as sess:\n","        sess.run(tf.global_variables_initializer())\n","        b64s_di, b64s_e = sess.run([encoded_image, b64s], \n","                                   feed_dict={img: mnist.test.images[0].astype(\"float32\").tobytes()})\n","        print(len(b64s_e))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["4182\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nmsLKg82d-VO","colab_type":"code","colab":{},"outputId":"4690051d-5df6-4553-a61f-9a114f4274b5"},"source":["print(len(img_b64_es))\n","img_b64_es[:-2].replace(b\"+\",b\"-\").replace(b\"/\",b\"_\") == b64s_e"],"execution_count":0,"outputs":[{"output_type":"stream","text":["4184\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"QidEmc3Vd-VR","colab_type":"text"},"source":["Input may or may not have padding at the end. See EncodeBase64 for padding. Web-safe means that input must use - and _ instead of + and /. \n","\n","Tensorflow encoding is different from base64 in web-safe base64 url. Two steps make both of them are the same.\n","* Trim final 2 bytes.\n","* Replace byte '+' with '-' and byte '/' with '_'."]},{"cell_type":"markdown","metadata":{"id":"yBz5oefZd-VT","colab_type":"text"},"source":["Saving byte string in numpy.array issue, trimimg zeros at the end of byte string."]},{"cell_type":"code","metadata":{"id":"0czQFdfbd-VT","colab_type":"code","colab":{},"outputId":"9487048a-dd85-46c6-c686-cf01d407b8ec"},"source":["_train_images = []\n","_bytes_array = []\n","\n","for i in range(mnist.train.num_examples):\n","    byte_data = mnist.train.images[i].astype(\"float32\").tobytes()\n","    byte_string = Base64Converter(byte_data)  # convert to base64 encoded string\n","    _train_images.append(byte_string)\n","    _bytes_array.append(len(byte_string))\n","\n","# dtype='O' (big O) means python object\n","train_images = np.array(_train_images, dtype='O')\n","train_images = train_images.reshape([-1,1])\n","print(train_images.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(55000, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SuxMg-zYd-VW","colab_type":"code","colab":{},"outputId":"441dde44-4b46-452b-d3bf-00464ce98e43"},"source":["tf.reset_default_graph()\n","with tf.Graph().as_default():\n","    b64s_input = tf.placeholder(tf.string, shape=[None,1])\n","    raw_input = tf.io.decode_base64(b64s_input)  # to byte\n","    decode = tf.io.decode_raw(raw_input, tf.float32)\n","    with tf.Session() as sess:\n","        img_ = sess.run(decode, feed_dict={b64s_input: train_images[9:11]})\n","        print(img_.shape)\n","\n","print(_bytes_array[:10])\n","print(len(_train_images[0]), len(_train_images[1]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(2, 1, 784)\n","[4182, 4182, 4182, 4182, 4182, 4182, 4182, 4182, 4182, 4182]\n","4182 4182\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XlAfgS7Td-VY","colab_type":"code","colab":{},"outputId":"b2868026-58de-49a8-8e47-4f10b5375055"},"source":["_train_labels = []\n","\n","for i in range(mnist.train.num_examples):\n","    byte_data = mnist.train.labels[i].astype(\"float32\").tobytes()\n","    label_byte = Base64Converter(byte_data)\n","    _train_labels.append(label_byte)\n","    \n","train_labels = np.array(_train_labels, dtype=\"O\")\n","train_labels = train_labels.reshape([-1, 1])\n","train_labels.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(55000, 1)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"BphGDLc5d-Vb","colab_type":"text"},"source":["### Customized Models"]},{"cell_type":"code","metadata":{"id":"TMiVETqHd-Vb","colab_type":"code","colab":{}},"source":["def layer(input, weight_shape, bias_shape):\n","    weight_std = (2.0 / weight_shape[0]) ** 0.5\n","    w_init = tf.random_normal_initializer(stddev=weight_std)\n","    b_init = tf.constant_initializer(value=0)\n","    W = tf.get_variable(name=\"W\", shape=weight_shape, initializer=w_init)\n","    b = tf.get_variable(name=\"b\", shape=bias_shape, initializer=b_init)\n","    return tf.nn.relu(tf.matmul(input, W) + b)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tynDpO_4d-Vg","colab_type":"code","colab":{}},"source":["def evaluate(output, y):\n","  compare = tf.equal(tf.argmax(output, axis=1), tf.argmax(y, axis=1))\n","  compare_to_float = tf.cast(compare, tf.float32)\n","  accuracy, updated_op = tf.metrics.mean(compare_to_float)\n","  return accuracy, updated_op"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VfG1jqhnd-Vj","colab_type":"code","colab":{}},"source":["def model_fn(features, labels, mode, params):\n","    \n","    # image input transformation from base64 encoded string to byte string and then to float32\n","    _input = tf.io.decode_base64(features[\"image\"])\n","    _input = tf.io.decode_raw(_input, tf.float32)\n","    new_input = tf.squeeze(_input, axis=1) # [None, 1, 784] => [None, 784]\n","    \n","    if mode in [tf.estimator.ModeKeys.TRAIN, tf.estimator.ModeKeys.EVAL]:\n","        # The labels are only used in TRAIN and EVAL modess.\n","        # label input transform from string to float32\n","        labels = tf.io.decode_base64(labels)\n","        labels = tf.io.decode_raw(labels, tf.float32) \n","        labels = tf.squeeze(labels, axis=1) # [None, 1, 10] => [None, 1]\n","    \n","    # build a mlp model\n","    with tf.variable_scope(\"hidden1\"):\n","        hidden1 = layer(new_input, [784, 1024], [1024])\n","    with tf.variable_scope(\"hidden2\"):\n","        hidden2 = layer(hidden1, [1024, 512], [512])\n","    with tf.variable_scope(\"output\"):\n","        output = layer(hidden2, [512, 10], [10])\n","    \n","    # define the result\n","    result = tf.identity(output, name=\"class\")\n","    prob = tf.nn.softmax(result, name=\"prob\")\n","    predict_dict = {\"output\": output, \"prob\": prob}\n","    if mode == tf.estimator.ModeKeys.PREDICT:\n","        return tf.estimator.EstimatorSpec(\n","            mode=mode,\n","            predictions=predict_dict)\n","    \n","    # define loss function\n","    cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=output, labels=labels)\n","    loss = tf.reduce_mean(cross_entropy)\n","    \n","    # define optimizer\n","    optimizer = tf.train.GradientDescentOptimizer(learning_rate=params[\"learning_rate\"])\n","    train_opt = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n","    \n","    # metrics\n","    eval_metric_ops = {\n","        #\"accuracy\": tf.metrics.accuracy(labels, output)\n","        \"accuracy\": evaluate(output, labels)\n","    }\n","    \n","    # return an estimator spec\n","    return tf.estimator.EstimatorSpec(\n","        mode=mode,\n","        loss=loss,\n","        train_op=train_opt,\n","        eval_metric_ops=eval_metric_ops)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z9E6hcV-d-Vm","colab_type":"code","colab":{}},"source":["batch_size = 128\n","epochs = mnist.train.num_examples // batch_size\n","\n","model_params = {\"learning_rate\": 1e-4}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XsMRpBhxd-Vo","colab_type":"code","colab":{},"outputId":"c047710a-273b-4d83-f4e3-996cb189f0f0"},"source":["nn = tf.estimator.Estimator(model_fn=model_fn, params=model_params)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Using default config.\n","WARNING:tensorflow:Using temporary folder as model directory: /var/folders/4b/wh1nthj1563b1gl58ydgwnfw0000gp/T/tmpugbau_ba\n","INFO:tensorflow:Using config: {'_model_dir': '/var/folders/4b/wh1nthj1563b1gl58ydgwnfw0000gp/T/tmpugbau_ba', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x13d5f2048>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"nlERECx2d-Vq","colab_type":"code","colab":{},"outputId":"b10c6fdf-0351-428f-f02c-b80666122698"},"source":["train_input_fn = tf.estimator.inputs.numpy_input_fn(\n","    x={\"image\": train_images},\n","    y=train_labels,\n","    num_epochs=epochs,\n","    shuffle=True, \n","    batch_size=batch_size)\n","\n","# Train\n","nn.train(input_fn=train_input_fn, steps=200)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /Users/jiankaiwang/devops/pyenv/tfx/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","WARNING:tensorflow:From /Users/jiankaiwang/devops/pyenv/tfx/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","To construct input pipelines, use the `tf.data` module.\n","WARNING:tensorflow:From /Users/jiankaiwang/devops/pyenv/tfx/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","To construct input pipelines, use the `tf.data` module.\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","WARNING:tensorflow:From /Users/jiankaiwang/devops/pyenv/tfx/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","WARNING:tensorflow:From /Users/jiankaiwang/devops/pyenv/tfx/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","To construct input pipelines, use the `tf.data` module.\n","INFO:tensorflow:Saving checkpoints for 0 into /var/folders/4b/wh1nthj1563b1gl58ydgwnfw0000gp/T/tmpugbau_ba/model.ckpt.\n","INFO:tensorflow:loss = 2.3351197, step = 1\n","INFO:tensorflow:global_step/sec: 78.5751\n","INFO:tensorflow:loss = 2.2912858, step = 101 (1.274 sec)\n","INFO:tensorflow:Saving checkpoints for 200 into /var/folders/4b/wh1nthj1563b1gl58ydgwnfw0000gp/T/tmpugbau_ba/model.ckpt.\n","INFO:tensorflow:Loss for final step: 2.2937706.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow_estimator.python.estimator.estimator.Estimator at 0x13d5f2b00>"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"bGBIFlPUd-Vu","colab_type":"text"},"source":["### Evaluating Model"]},{"cell_type":"code","metadata":{"id":"21X1WqeMd-Vv","colab_type":"code","colab":{},"outputId":"bc608d8a-b118-4ab2-aa1f-442afcde5199"},"source":["# image transformation from float32 to byte string\n","_test_images = []\n","\n","for i in range(mnist.test.num_examples):\n","    byte_data = mnist.test.images[i].astype(\"float32\").tobytes()\n","    byte_data = Base64Converter(byte_data)\n","    byte_string = np.array(byte_data).tostring()\n","    _test_images.append(byte_string)\n","\n","test_images = np.array(_test_images, dtype='O')\n","test_images = test_images.reshape([-1, 1])\n","print(test_images.shape)\n","\n","# label transformation from float32 to byte string\n","_test_labels = []\n","\n","for i in range(mnist.test.num_examples):\n","    label_byte = mnist.test.labels[i].astype(\"float32\").tobytes()\n","    label_byte = Base64Converter(label_byte)\n","    _test_labels.append(label_byte)\n","    \n","test_labels = np.array(_test_labels, dtype=\"O\")\n","test_labels = test_labels.reshape([-1, 1])\n","print(test_labels.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(10000, 1)\n","(10000, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kdGEiAcpd-Vx","colab_type":"code","colab":{},"outputId":"a89f74dd-c9d0-44a2-cc7c-5e11941a377b"},"source":["# Score accuracy\n","test_input_fn = tf.estimator.inputs.numpy_input_fn(\n","    x={\"image\": test_images},\n","    y=test_labels,\n","    num_epochs=1,\n","    shuffle=False)\n","\n","ev = nn.evaluate(input_fn=test_input_fn)\n","print(\"Loss: %s\" % ev[\"loss\"])\n","print(\"Accuracy: %s\" % ev[\"accuracy\"])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2019-12-04T18:05:21Z\n","INFO:tensorflow:Graph was finalized.\n","WARNING:tensorflow:From /Users/jiankaiwang/devops/pyenv/tfx/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","INFO:tensorflow:Restoring parameters from /var/folders/4b/wh1nthj1563b1gl58ydgwnfw0000gp/T/tmpugbau_ba/model.ckpt-200\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Finished evaluation at 2019-12-04-18:05:21\n","INFO:tensorflow:Saving dict for global step 200: accuracy = 0.1373, global_step = 200, loss = 2.2944782\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 200: /var/folders/4b/wh1nthj1563b1gl58ydgwnfw0000gp/T/tmpugbau_ba/model.ckpt-200\n","Loss: 2.2944782\n","Accuracy: 0.1373\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PcsbAwl5d-V0","colab_type":"text"},"source":["## Prediction"]},{"cell_type":"code","metadata":{"id":"Zlle2EyYd-V0","colab_type":"code","colab":{},"outputId":"47f72748-e679-47eb-a0bf-99f8f4b32a61"},"source":["used_index = 0\n","pred_data = mnist.test.images[used_index].astype('float32').tobytes()\n","pred_data = Base64Converter(pred_data)\n","pred_data = np.array(pred_data, dtype=\"O\").reshape([-1, 1])\n","\n","plt.imshow(mnist.test.images[used_index].reshape(28, 28))\n","\n","# Print out predictions\n","predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n","    x={\"image\": pred_data},\n","    num_epochs=1,\n","    shuffle=False)\n","\n","import struct\n","predictions = nn.predict(input_fn=predict_input_fn)\n","for _, p in enumerate(predictions):\n","    pred_class = np.argmax(p[\"prob\"])\n","    prob = p[\"prob\"][pred_class]\n","    print(\"Prediction (pred %s: %s): %s\" % (pred_class, prob, p[\"prob\"]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /var/folders/4b/wh1nthj1563b1gl58ydgwnfw0000gp/T/tmpugbau_ba/model.ckpt-200\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","Prediction (pred 2: 0.13284893): [0.09364577 0.09191748 0.13284893 0.09191748 0.09191748 0.09191748\n"," 0.09191748 0.09191748 0.09191748 0.13008298]\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"4-k4SxZTd-V2","colab_type":"text"},"source":["## Model Export"]},{"cell_type":"code","metadata":{"id":"5RsC5mWtd-V3","colab_type":"code","colab":{},"outputId":"caea9c28-c9b9-4aeb-b4f9-733b07f04845"},"source":["def serving_input_receiver_fn():\n","    \"\"\"Serving input_fn that builds features from placeholders\"\"\"\n","    serialized_tf_example = tf.placeholder(dtype=tf.string, shape=[None, 1])\n","    receiver_tensors = {'image': serialized_tf_example}\n","    return tf.estimator.export.ServingInputReceiver(receiver_tensors, serialized_tf_example)\n","\n","serving_input_receiver_fn()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ServingInputReceiver(features={'image': <tf.Tensor 'Placeholder_2:0' shape=(?, 1) dtype=string>}, receiver_tensors={'input': <tf.Tensor 'Placeholder_2:0' shape=(?, 1) dtype=string>}, receiver_tensors_alternatives=None)"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"9yBEHZsxd-V6","colab_type":"code","colab":{},"outputId":"a6a458bf-5cae-41ce-c454-2ee872161bdb"},"source":["if os.path.exists(\"/Users/jiankaiwang/Desktop/TFE_SavedModel/\"):\n","    exported_name = nn.export_saved_model(\"/Users/jiankaiwang/Desktop/TFE_SavedModel/\", serving_input_receiver_fn)\n","else:\n","    exported_name = nn.export_saved_model(\"/tmp/TFE_SavedModel/\", serving_input_receiver_fn)\n","    \n","outmodel = exported_name.decode(\"UTF-8\")\n","print(outmodel)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","WARNING:tensorflow:From /Users/jiankaiwang/devops/pyenv/tfx/lib/python3.7/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n","INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n","INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n","INFO:tensorflow:Signatures INCLUDED in export for Train: None\n","INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n","INFO:tensorflow:Restoring parameters from /var/folders/4b/wh1nthj1563b1gl58ydgwnfw0000gp/T/tmpugbau_ba/model.ckpt-200\n","INFO:tensorflow:Assets added to graph.\n","INFO:tensorflow:No assets to write.\n","INFO:tensorflow:SavedModel written to: /Users/jiankaiwang/Desktop/TFE_SavedModel/temp-b'1575454152'/saved_model.pb\n","/Users/jiankaiwang/Desktop/TFE_SavedModel/1575454152\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"N4u_8EX9d-V9","colab_type":"code","colab":{},"outputId":"7d6d2859-b5fa-430e-8bf3-ee739f3cf60d"},"source":["!saved_model_cli show --dir /Users/jiankaiwang/Desktop/TFE_SavedModel/1575454152 --tag_set serve --signature_def serving_default"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/Users/jiankaiwang/devops/pyenv/tfx/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/Users/jiankaiwang/devops/pyenv/tfx/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/Users/jiankaiwang/devops/pyenv/tfx/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/Users/jiankaiwang/devops/pyenv/tfx/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/Users/jiankaiwang/devops/pyenv/tfx/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/Users/jiankaiwang/devops/pyenv/tfx/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","/Users/jiankaiwang/devops/pyenv/tfx/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/Users/jiankaiwang/devops/pyenv/tfx/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/Users/jiankaiwang/devops/pyenv/tfx/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/Users/jiankaiwang/devops/pyenv/tfx/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/Users/jiankaiwang/devops/pyenv/tfx/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/Users/jiankaiwang/devops/pyenv/tfx/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","The given SavedModel SignatureDef contains the following input(s):\n","  inputs['input'] tensor_info:\n","      dtype: DT_STRING\n","      shape: (-1, 1)\n","      name: Placeholder:0\n","The given SavedModel SignatureDef contains the following output(s):\n","  outputs['output'] tensor_info:\n","      dtype: DT_FLOAT\n","      shape: (-1, 10)\n","      name: output/Relu:0\n","  outputs['prob'] tensor_info:\n","      dtype: DT_FLOAT\n","      shape: (-1, 10)\n","      name: prob:0\n","Method name is: tensorflow/serving/predict\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pVa6bN4fd-WC","colab_type":"text"},"source":["## Restful API requests for Prediction"]},{"cell_type":"code","metadata":{"id":"Ng_iLs0Gd-WC","colab_type":"code","colab":{}},"source":["import json\n","import requests\n","import os\n","import tensorflow as tf\n","from tensorflow.examples.tutorials.mnist import input_data\n","import base64\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LZf3AGwud-WE","colab_type":"code","colab":{},"outputId":"b7dcd98d-251c-42d5-9546-45a0716cb5fa"},"source":["if os.path.exists(\"/Users/jiankaiwang/devops/tmp/MNIST_data/\"):\n","  mnist = input_data.read_data_sets(\"/Users/jiankaiwang/devops/tmp/MNIST_data/\", one_hot=True)\n","else:\n","  mnist = input_data.read_data_sets(\"/tmp/MNIST_data/\", one_hot=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Extracting /Users/jiankaiwang/devops/tmp/MNIST_data/train-images-idx3-ubyte.gz\n","Extracting /Users/jiankaiwang/devops/tmp/MNIST_data/train-labels-idx1-ubyte.gz\n","Extracting /Users/jiankaiwang/devops/tmp/MNIST_data/t10k-images-idx3-ubyte.gz\n","Extracting /Users/jiankaiwang/devops/tmp/MNIST_data/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0nzPa9nLd-WH","colab_type":"code","colab":{}},"source":["def Base64Converter(byte_string):\n","    _byteStr = base64.b64encode(byte_string)\n","    return _byteStr[:-2].replace(b\"+\", b\"-\").replace(b\"/\", b\"_\")\n","\n","def Base64ConverterOri(byte_string):\n","    _byteStr = base64.b64encode(byte_string)\n","    return _byteStr"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"azWqQ64Sd-WI","colab_type":"code","colab":{},"outputId":"a7d30537-782e-4ac9-a371-88de4128aa84"},"source":["use_idx = 0\n","\n","# must be inputs (vector) or instances (list)\n","b64eUTF8Ori = Base64Converter(mnist.test.images[use_idx].tobytes()).decode('UTF-8')\n","my_data = {\"instances\": []}\n","my_data[\"instances\"].append([b64eUTF8Ori])\n","\n","plt.imshow(mnist.test.images[use_idx].reshape(28, 28), cmap='gray')\n","plt.show()\n","\n","print(\"Label: {}\".format(np.argmax(mnist.test.labels[use_idx])))\n","#print(\"Sent data: {}\".format(my_data))"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["Label: 7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9pTpnZV_d-WN","colab_type":"code","colab":{},"outputId":"f89cbe9e-b4d5-4995-8052-1f58e32b0db2"},"source":["\"\"\"\n","# or you can use the default base64 converter in tensorflow\n","def ImgBase64(byteData):\n","  tf.reset_default_graph()\n","  with tf.Graph().as_default():\n","    inputs = tf.placeholder(tf.string)\n","    base64Encode = tf.io.encode_base64(inputs)\n","    with tf.Session() as sess:\n","      outputs = sess.run(base64Encode, feed_dict={inputs: byteData})\n","    return outputs\n","\n","b64e = ImgBase64(mnist.test.images[0].tobytes())\n","b64eUTF8 = b64e.decode(\"UTF-8\")\n","\n","my_data = {\"instances\": []}\n","my_data[\"instances\"].append([b64eUTF8])\n","\"\"\""],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n# or you can use the default base64 converter in tensorflow\\ndef ImgBase64(byteData):\\n  tf.reset_default_graph()\\n  with tf.Graph().as_default():\\n    inputs = tf.placeholder(tf.string)\\n    base64Encode = tf.io.encode_base64(inputs)\\n    with tf.Session() as sess:\\n      outputs = sess.run(base64Encode, feed_dict={inputs: byteData})\\n    return outputs\\n\\nb64e = ImgBase64(mnist.test.images[0].tobytes())\\nb64eUTF8 = b64e.decode(\"UTF-8\")\\n\\nmy_data = {\"instances\": []}\\nmy_data[\"instances\"].append([b64eUTF8])\\n'"]},"metadata":{"tags":[]},"execution_count":61}]},{"cell_type":"markdown","metadata":{"id":"0BcGPlKxd-WQ","colab_type":"text"},"source":["Use the default base64 converter in tensorflow."]},{"cell_type":"code","metadata":{"id":"3l4UCXdmd-WR","colab_type":"code","colab":{},"outputId":"043fb35d-8e61-49e8-8221-a7b2a6e23cbf"},"source":["serving_url = \"http://localhost:8501/v1/models/TFE_SavedModel:predict\"\n","\n","r = requests.post(serving_url,\n","                  data=json.dumps(my_data),\n","                  headers={'Content-Type': 'application/octet-stream'})\n","print(r.status_code, r.content)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["200 b'{\\n    \"predictions\": [\\n        {\\n            \"output\": [0.0186281614, 0.0, 0.368321508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.347281367],\\n            \"prob\": [0.0936457738, 0.0919174775, 0.132848933, 0.0919174775, 0.0919174775, 0.0919174775, 0.0919174775, 0.0919174775, 0.0919174775, 0.13008298]\\n        }\\n    ]\\n}'\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"t-9bUYfVd-WU","colab_type":"text"},"source":["## Read the tfrecords"]},{"cell_type":"code","metadata":{"id":"FfKw93Vjd-WV","colab_type":"code","colab":{}},"source":["def read_and_decode(filename_queue):\n","    # create a tfrecord object\n","    reader = tf.TFRecordReader()\n","    _, serialized_example = reader.read(filename_queue)\n","    \n","    # decode the example\n","    features = tf.parse_single_example(serialized_example,\\\n","                features={'image':tf.FixedLenFeature([], tf.string)\\\n","                          , 'label':tf.FixedLenFeature([], tf.string)})\n","    \n","    label = tf.io.decode_base64(features[\"label\"])\n","    label = tf.io.decode_raw(label, tf.float32)\n","    \n","    # it must decode byteslist from string type to uint8 type\n","    image = tf.io.decode_base64(features[\"image\"])\n","    image = tf.io.decode_raw(image, tf.float32)\n","    return image, label"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tboYSPd6d-WX","colab_type":"code","colab":{},"outputId":"79079081-b5cc-4bd0-fa41-b6b10ba62850"},"source":["tf.reset_default_graph()\n","\n","with tf.name_scope('input'):\n","    # return a QueueRunner object and FIFOQueue object inside in\n","    filename_queue = tf.train.string_input_producer(\n","        [\"/Users/jiankaiwang/Desktop/mnist_test.tfrecord\"], \n","        num_epochs=None)\n","    \n","    image, label = read_and_decode(filename_queue)\n","    \n","    with tf.Session() as sess:\n","\n","        # because one epoch variable is built inside string_input_produer (image_raw)\n","        # and the variable is belonging to tf.GraphKeys.LOCAL_VARIABLES\n","        # tf.local_variables_initializer() is necessary\n","        init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n","        sess.run(init_op)\n","\n","        coord=tf.train.Coordinator()\n","        threads= tf.train.start_queue_runners(coord=coord)\n","        \n","        for i in range(0, 3, 1):\n","            img, lbl = sess.run([image, label])\n","            print(lbl)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-102-a37869a9f60d>:7: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-102-a37869a9f60d>:7: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /Users/jiankaiwang/devops/pyenv/tfx/lib/python3.7/site-packages/tensorflow/python/training/input.py:278: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /Users/jiankaiwang/devops/pyenv/tfx/lib/python3.7/site-packages/tensorflow/python/training/input.py:278: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /Users/jiankaiwang/devops/pyenv/tfx/lib/python3.7/site-packages/tensorflow/python/training/input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /Users/jiankaiwang/devops/pyenv/tfx/lib/python3.7/site-packages/tensorflow/python/training/input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-101-32dea344fc89>:3: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-101-32dea344fc89>:3: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n"],"name":"stderr"},{"output_type":"stream","text":["[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n","[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n","INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Enqueue operation was cancelled\n","\t [[{{node input/input_producer/input_producer_EnqueueMany}}]]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Enqueue operation was cancelled\n","\t [[{{node input/input_producer/input_producer_EnqueueMany}}]]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"khDigbvwd-WZ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}