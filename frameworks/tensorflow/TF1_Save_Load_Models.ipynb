{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --no-cache-dir -q opencv-python requests tensorflow_hub matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 97
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5141,
     "status": "ok",
     "timestamp": 1584674501475,
     "user": {
      "displayName": "çŽ‹DevOps",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgXVAgB9A4OE1KXeAfp5b-xUS2OSsbqSRVEe_UETw=s64",
      "userId": "04300517850278510646"
     },
     "user_tz": -480
    },
    "id": "4OURqUQBkg8J",
    "outputId": "aa36e831-c7fa-430e-a23f-245fd2f1cc12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 1.15.2\n",
      "Tensorflow.Keras Version: 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_hub as hub\n",
    "import shutil\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Tensorflow Version: {}\".format(tf.__version__))\n",
    "print(\"Tensorflow.Keras Version: {}\".format(keras.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W9T1cMhw9Kxr"
   },
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OhI7GFNe9Kxt"
   },
   "outputs": [],
   "source": [
    "def preprocess_image(img_path):\n",
    "  img = cv2.imread(img_path)\n",
    "  img = img[:,:,::-1]\n",
    "  img = cv2.resize(img, (224,224))\n",
    "  plt.imshow(img)\n",
    "  plt.show()\n",
    "  _img = img / 255.0\n",
    "  return _img, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sO6i_gEz9Kx2"
   },
   "outputs": [],
   "source": [
    "#cls_img_path = \"/Users/jiankaiwang/devops/VOCdevkit/VOC2008/JPEGImages/2007_000648.jpg\"\n",
    "cls_img_path = \"/Users/jiankaiwang/devops/VOCdevkit/VOC2008/JPEGImages/2007_000033.jpg\"\n",
    "assert os.path.exists(cls_img_path), \"Image was not found.\"\n",
    "img, img_ori = preprocess_image(cls_img_path)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img_ori = np.expand_dims(img_ori, axis=0)\n",
    "assert img.shape == (1,224,224,3), \"Image shape was not allowed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uun47OPv9Kx6"
   },
   "outputs": [],
   "source": [
    "label_raw_data = requests.get(\"https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt\")\n",
    "labels = []\n",
    "_tmp_word = \"\"\n",
    "for word in label_raw_data.content.decode('utf-8'):\n",
    "  if word not in [\"\\n\", \"\\r\\n\"]:\n",
    "    _tmp_word += word\n",
    "  else:\n",
    "    labels.append(_tmp_word)    \n",
    "    _tmp_word = \"\"\n",
    "print(len(labels), labels[0], labels[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N3QuJ1rQ9Kx9"
   },
   "source": [
    "# SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L011DBO72iNv"
   },
   "outputs": [],
   "source": [
    "saved_model_path = \"/Users/jiankaiwang/devops/tfhub/imagene_mobilenet_v2_140_224_classification\"\n",
    "assert os.path.exists(saved_model_path), \"Saved model path was not found.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XrQ5R23x9KyA"
   },
   "source": [
    "## Using tf.saved_model APIs (SavedModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GlvYKaXx9KyB"
   },
   "source": [
    "### Customized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sUHMtCaP9KyC"
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/MNIST_data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fQkrirsF9KyF"
   },
   "outputs": [],
   "source": [
    "full_training = True\n",
    "learning_rate = 1e-2\n",
    "training_epochs = 2 if full_training else 1\n",
    "batch_size = 64 if full_training else 32\n",
    "display_step = 1\n",
    "log_path = os.path.join(\"/\",\"tmp\",\"tensorboard_log\",\"mnist_example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x2yy6sXi9KyH"
   },
   "outputs": [],
   "source": [
    "def conv2d(input, weight_shape, bias_shape):\n",
    "  in_count = weight_shape[0] * weight_shape[1] * weight_shape[2]\n",
    "  weight_init = tf.random_normal_initializer(stddev=(2/in_count)**0.5)\n",
    "  bias_init = tf.constant_initializer(value=0)\n",
    "  weight = tf.get_variable(\"W\", weight_shape, initializer=weight_init)\n",
    "  bias = tf.get_variable(\"b\", bias_shape, initializer=bias_init)\n",
    "  conv = tf.nn.conv2d(input, weight, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "  return tf.nn.relu(tf.nn.bias_add(conv, bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R3ytHogL9KyL"
   },
   "outputs": [],
   "source": [
    "def pool2d(input, k=2):\n",
    "  return tf.nn.max_pool(value=input, ksize=[1,k,k,1], strides=[1,k,k,1], padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O1fKhKDq9KyO"
   },
   "outputs": [],
   "source": [
    "def dense(input, weight_shape, bias_shape, name):\n",
    "  in_count = weight_shape[0] * weight_shape[1]\n",
    "  weight_init = tf.random_normal_initializer(stddev=(2/in_count)**0.5)\n",
    "  bias_init = tf.constant_initializer(value=0)\n",
    "  weight = tf.get_variable(\"W\", weight_shape, initializer=weight_init)\n",
    "  bias = tf.get_variable(\"b\", bias_shape, initializer=bias_init)\n",
    "  logits = tf.matmul(input, weight)\n",
    "  return tf.nn.relu(tf.nn.bias_add(logits, bias), name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j1fcqB_X9KyR"
   },
   "outputs": [],
   "source": [
    "def inference(input, keep_prob=0.5):\n",
    "  x = tf.reshape(input, [-1, 28, 28, 1])\n",
    "\n",
    "  with tf.variable_scope(\"hidden_1\"):\n",
    "    conv_1 = conv2d(x, [3, 3, 1, 32], [32])         # 28 x 28 x 32\n",
    "    pool_1 = pool2d(conv_1, 2)                      # 14 x 14 x 32\n",
    "\n",
    "  with tf.variable_scope(\"hidden_2\"):\n",
    "    conv_2 = conv2d(pool_1, [3, 3, 32, 64], [64])   # 14 x 14 x 64\n",
    "    pool_2 = pool2d(conv_2, 2)                      # 7 x 7 x 64\n",
    "\n",
    "  with tf.variable_scope(\"fc\"):\n",
    "    pool_2_flat = tf.reshape(pool_2, [-1, 7 * 7 * 64])\n",
    "    fc_1 = dense(pool_2_flat, [7 * 7 * 64, 1024], [1024], name=\"fc\")\n",
    "\n",
    "    # dropout\n",
    "    fc_1_dropout = tf.nn.dropout(fc_1, keep_prob=keep_prob)\n",
    "\n",
    "  with tf.variable_scope(\"output\"):\n",
    "    output = dense(fc_1_dropout, [1024, 10], [10], name=\"logits\")\n",
    "\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2qHs71QN9KyU"
   },
   "outputs": [],
   "source": [
    "def loss(output, y):\n",
    "  \"\"\"\n",
    "  output: the logits value from inference\n",
    "  y: the labeling data\n",
    "  \"\"\"\n",
    "  cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=output, labels=y)\n",
    "  loss = tf.reduce_mean(cross_entropy)\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dNacRsQ-9KyW"
   },
   "outputs": [],
   "source": [
    "def training(loss, global_step):\n",
    "  \"\"\"\n",
    "  loss: the loss value\n",
    "  global_step: the global training step index\n",
    "  \"\"\"\n",
    "  tf.summary.scalar(\"loss\", loss)\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "  grads = tf.gradients(loss, tf.trainable_variables())\n",
    "  grads = list(zip(grads, tf.trainable_variables()))\n",
    "  apply_grads = optimizer.apply_gradients(grads_and_vars=grads, global_step=global_step)\n",
    "  return grads, apply_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2icHsGSb9KyY"
   },
   "outputs": [],
   "source": [
    "def evaluate(output, y):\n",
    "  \"\"\"\n",
    "  output: the logits value from inference\n",
    "  y: the labeling data\n",
    "  \"\"\"\n",
    "  compare = tf.equal(tf.argmax(output, axis=1), tf.argmax(y, axis=1))\n",
    "  accuracy = tf.reduce_mean(tf.cast(compare, tf.float32))\n",
    "  tf.summary.scalar(\"eval\", accuracy)\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {saved_model_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "glGNiTU39Kyd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Accuracy: 0.93, Vaildation Error: 0.07\n",
      "Epoch: 2, Accuracy: 0.95, Vaildation Error: 0.05\n",
      "Training finishing.\n",
      "Test Accuracy: 0.95\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /Users/jiankaiwang/devops/tmp/tf_saved_model_apis/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "saved_model_path = \"/Users/jiankaiwang/devops/tmp/tf_saved_model_apis\"\n",
    "if os.path.exists(saved_model_path):\n",
    "  shutil.rmtree(saved_model_path)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "  with tf.variable_scope(\"cnn\"):\n",
    "    x = tf.placeholder(\"float\", [None, 784], name=\"images\")\n",
    "    y = tf.placeholder(\"float\", [None, 10], name=\"label\")\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "    output = inference(x, keep_prob=keep_prob) \n",
    "    loss_val = loss(output=output, y=y)\n",
    "    global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "    train_grads, train_opt = training(loss=loss_val, global_step=global_step)   # training body\n",
    "    eval_opt = evaluate(output=output, y=y)   # evaluation result\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "      sess.run(tf.global_variables_initializer())   # initialize all variables\n",
    "\n",
    "      for epoch in range(training_epochs):\n",
    "        avg_loss = 0.\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "        for idx in range(total_batch):\n",
    "          batch_x, batch_y = mnist.train.next_batch(batch_size=batch_size)   # get the batch data\n",
    "\n",
    "          feed_dict_data = {x: batch_x, y: batch_y, keep_prob: 0.5}\n",
    "          grads, _ = sess.run([train_grads, train_opt], feed_dict=feed_dict_data)   # run training\n",
    "\n",
    "          batch_loss = sess.run(loss_val, feed_dict=feed_dict_data)\n",
    "          avg_loss += batch_loss / total_batch   # calculate the average loss\n",
    "\n",
    "        if epoch % display_step == 0:\n",
    "          feed_dict_val_data = {x: mnist.validation.images, y: mnist.validation.labels, keep_prob: 1.0}\n",
    "          acc = sess.run(eval_opt, feed_dict=feed_dict_val_data)   # calculate the accuracy\n",
    "          print(\"Epoch: {}, Accuracy: {:.2f}, Vaildation Error: {:.2f}\".format(epoch+1, acc, 1-acc))\n",
    "\n",
    "      print(\"Training finishing.\")\n",
    "\n",
    "      feed_dict_test_data = {x: mnist.test.images, y: mnist.test.labels, keep_prob: 1.0}\n",
    "      acc = sess.run(eval_opt, feed_dict=feed_dict_test_data)\n",
    "      print(\"Test Accuracy: {:.2f}\".format(acc))\n",
    "\n",
    "      tf.saved_model.simple_save(sess, saved_model_path, inputs={\"image\":x, \"rate\": keep_prob}, outputs={\"output\": output})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F70hv0bH9Kyf",
    "outputId": "02aaca2a-312b-4be4-bd59-31f066d024ec",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/jiankaiwang/devops/tmp/tf_saved_model_apis/variables/variables\n",
      "cnn/images\n",
      "cnn/label\n",
      "cnn/Placeholder\n",
      "cnn/Reshape/shape\n",
      "cnn/Reshape\n",
      "cnn/hidden_1/W/Initializer/random_normal/shape\n",
      "cnn/hidden_1/W/Initializer/random_normal/mean\n",
      "cnn/hidden_1/W/Initializer/random_normal/stddev\n",
      "cnn/hidden_1/W/Initializer/random_normal/RandomStandardNormal\n",
      "cnn/hidden_1/W/Initializer/random_normal/mul\n",
      "Label: 0\n",
      "Inference result: 0\n",
      "[[12.604624   0.         3.8232436  0.6547819  0.         3.2755642\n",
      "   3.911615   1.3226465  1.1137877  2.6310313]]\n"
     ]
    }
   ],
   "source": [
    "saved_model_path = \"/Users/jiankaiwang/devops/tmp/tf_saved_model_apis\"\n",
    "assert os.path.exists(saved_model_path), \"The model folder was not found.\"\n",
    "\n",
    "tf.Graph()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "  tf.saved_model.load(sess, ['serve'], saved_model_path)\n",
    "\n",
    "  # show all operations\n",
    "  all_ops = graph.get_operations()\n",
    "  for ops in all_ops[:10]:\n",
    "    if ops.name[:8] != \"cnn/save\": print(ops.name)\n",
    "\n",
    "  inputs = graph.get_tensor_by_name(\"cnn/images:0\")\n",
    "  outputs = graph.get_tensor_by_name(\"cnn/output/logits:0\")\n",
    "  keep_prob = graph.get_tensor_by_name(\"cnn/Placeholder:0\")\n",
    "\n",
    "  val_idx = 3\n",
    "  inference_result = sess.run(outputs, feed_dict={\n",
    "    inputs: mnist.test.images[val_idx:(val_idx+1)],\n",
    "    keep_prob: 1.0})\n",
    "  print(\"Label: {}\".format(np.argmax(mnist.test.labels[val_idx])))\n",
    "  print(\"Inference result: {}\".format(np.argmax(inference_result[0])))\n",
    "  print(inference_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z8VML_ma9Kyi"
   },
   "source": [
    "## Using Models from tf.hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JClypGok9Kyk"
   },
   "outputs": [],
   "source": [
    "saved_model_path = \"/Users/jiankaiwang/devops/tfhub/imagene_mobilenet_v2_140_224_classification\"\n",
    "assert os.path.exists(saved_model_path), \"Saved model path was not found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V7H3g_0S9Kym"
   },
   "outputs": [],
   "source": [
    "!saved_model_cli show --dir /Users/jiankaiwang/devops/tfhub/imagene_mobilenet_v2_140_224_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z0wZSgO-9Kyo"
   },
   "outputs": [],
   "source": [
    "from tensorflow_hub import registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a4xoOJhO9Kyv"
   },
   "outputs": [],
   "source": [
    "def resolve(handle):\n",
    "  \"\"\"Resolves a module handle into a path.\n",
    "   Resolves a module handle into a path by downloading and caching in\n",
    "   location specified by TF_HUB_CACHE_DIR if needed.\n",
    "  Args:\n",
    "    handle: (string) the Module handle to resolve.\n",
    "  Returns:\n",
    "    A string representing the Module path.\n",
    "  \"\"\"\n",
    "  return registry.resolver(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bDsDgaX39Kyz"
   },
   "outputs": [],
   "source": [
    "saved_model_path = \"/Users/jiankaiwang/devops/tfhub/imagene_mobilenet_v2_140_224_classification\"\n",
    "assert os.path.exists(saved_model_path), \"Saved model path was not found.\"\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Graph().as_default() as graph:\n",
    "  module_handle = resolve(saved_model_path)\n",
    "  loaded = tf.saved_model.load_v2(module_handle, tags=['train'])   \n",
    "  all_ops = graph.get_operations()\n",
    "  f = loaded.signatures[\"image_classification\"]\n",
    "\n",
    "  with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    res = sess.run(f(images=tf.convert_to_tensor(img, dtype=tf.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hBo9sVv19Ky4",
    "outputId": "ee677c61-5044-4896-8b10-bb6fa597d8e9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "saved_model_path = \"/Users/jiankaiwang/devops/tfhub/imagene_mobilenet_v2_140_224_classification\"\n",
    "assert os.path.exists(saved_model_path), \"Saved model path was not found.\"\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Graph().as_default() as graph:\n",
    "  with tf.Session(graph=graph) as sess:\n",
    "    loaded = tf.saved_model.load(sess, [], saved_model_path)   \n",
    "\n",
    "    all_ops = graph.get_operations()\n",
    "    #for ops in all_ops:\n",
    "    #    print(ops.name) \n",
    "\n",
    "    inputs = graph.get_tensor_by_name(\"hub_input/images:0\")\n",
    "    outputs = graph.get_tensor_by_name(\"MobilenetV2/Logits/output:0\")\n",
    "\n",
    "    res = sess.run(outputs, feed_dict={inputs: img})\n",
    "    res_idx = np.argmax(res[0])\n",
    "    print(\"Result : {}, Prob: {}\".format(labels[res_idx], res[0][res_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u4ZaxXxr9Ky7"
   },
   "source": [
    "# Using tf.hub APIs (SavedModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fZ3wpTYh9Ky8"
   },
   "outputs": [],
   "source": [
    "saved_model_path = \"/Users/jiankaiwang/devops/tfhub/imagene_mobilenet_v2_140_224_classification\"\n",
    "assert os.path.exists(saved_model_path), \"Saved model path was not found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xz6DK5VS9Ky_"
   },
   "outputs": [],
   "source": [
    "with tf.Graph().as_default():  \n",
    "  classifier = hub.Module(saved_model_path)\n",
    "  height, width = hub.get_expected_image_size(classifier)\n",
    "  #tf.logging.info(\"Suggested height {}, width {}\".format(height, width))\n",
    "  \n",
    "  images = tf.placeholder(tf.float32, shape=(1, height, width, 3))  \n",
    "  logits = classifier(images)\n",
    "\n",
    "  with tf.Session() as sess:\n",
    "    collects = tf.group(tf.global_variables_initializer(), \n",
    "                        tf.tables_initializer())\n",
    "    sess.run(collects)\n",
    "    \n",
    "    cls_res, = sess.run([logits], feed_dict={images: img})\n",
    "    cls_res = cls_res[0]\n",
    "    cls_res_idx = np.argmax(cls_res)\n",
    "    print(\"Classification result: {}, prob: {}\".format(labels[cls_res_idx], cls_res[cls_res_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8MDFgF4l9KzB"
   },
   "source": [
    "# Frozen Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TmgwQelr9KzB"
   },
   "outputs": [],
   "source": [
    "frozen_model_path = \"/Users/jiankaiwang/devops/Auxiliary_Operations/vc_cicd/tmp/new01_retrain_dev/mbv2_0.75_128/retrained_graph.pb\"\n",
    "assert os.path.exists(frozen_model_path), \"Frozen model was not found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "96sj1Y3X9KzI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "TF1_Save_Load_Models.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
