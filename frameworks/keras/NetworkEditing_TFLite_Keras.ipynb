{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras version: 2.1.6\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, MaxPooling2D, Conv2D, BatchNormalization\n",
    "from keras.models import save_model, load_model\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from collections import OrderedDict\n",
    "\n",
    "print(\"Keras version: {}\".format(keras.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python 3.5.4 :: Anaconda custom (64-bit)\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data(path=os.path.join('.','keras_mnist'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "nb_epoch = 1\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "pool_size = (2,2)\n",
    "kernel_size = (3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (sample_num, row, col, channel)\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255.\n",
    "x_test /= 255.\n",
    "\n",
    "# one-hot encoding\n",
    "# e.g. array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
    "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# first convolutional layer\n",
    "model.add(Conv2D(32, (kernel_size[0], kernel_size[1]), padding='valid', input_shape=input_shape))\n",
    "model.add(BatchNormalization(momentum=0.99, epsilon=0.001))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# second convolutional layer\n",
    "model.add(Conv2D(32, (kernel_size[0], kernel_size[1])))\n",
    "model.add(BatchNormalization(momentum=0.99, epsilon=0.001))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# max pooling layer\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "# flatten\n",
    "model.add(Flatten())\n",
    "\n",
    "# First Dense layer (FC 1)\n",
    "model.add(Dense(128))\n",
    "model.add(BatchNormalization(momentum=0.99, epsilon=0.001))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Second Dense Layer (FC 2)\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 601,578\n",
      "Trainable params: 601,194\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define loss function, optimizer, and metrics\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def np_expert_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    y_true: [batch_size, nb_classes]\n",
    "    y_pred: [batch_size, nb_classes]\n",
    "    \"\"\"\n",
    "    if y_true.ndim == 1:\n",
    "        y_true = y_true.reshape(1, y_true.size)\n",
    "        y_pred = y_pred.reshape(1, y_pred.size)\n",
    "        \n",
    "    if y_true.size == y_pred.size:\n",
    "        y_true_idx = y_true.argmax(axis=1)\n",
    "    \n",
    "    batch_size = y_true.shape[0]\n",
    "    return -np.sum(np.log(y_pred[np.arange(batch_size), y_true_idx] + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def default_expert_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    (Tensor, not numpy array) y_true: [batch_size, nb_classes]\n",
    "    (Tensor, not numpy array) y_pred: [batch_size, nb_classes]\n",
    "    \"\"\"\n",
    "    \n",
    "    y_res = keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "    \n",
    "    return y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_squared_error(y_true, y_pred):\n",
    "    y_res = K.mean(K.square(y_pred - y_true), axis=-1)\n",
    "    print(K.shape(y_res))\n",
    "    return y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expert_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    (Tensor, not numpy array) y_true: [batch_size, nb_classes]\n",
    "    (Tensor, not numpy array) y_pred: [batch_size, nb_classes]\n",
    "    \"\"\"\n",
    "    if K.ndim(y_true) == 1:\n",
    "        y_true = K.reshape(y_true, [1, K.shape(y_true)[0]], dtype=\"float32\")\n",
    "        y_pred = K.reshape(y_pred, [1, K.shape(y_pred)[0]], dtype=\"float32\")\n",
    "    \n",
    "    b_size = K.cast(K.shape(y_pred)[0], dtype=\"float32\")\n",
    "    y_res = -K.sum(y_true * K.log(y_pred + 1e-7)) / b_size   # return \n",
    "    return y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correct_ratio(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    return: (1) can be a tensor list, (2) can be a tensor scalar\n",
    "    \"\"\"\n",
    "    true_list = K.argmax(y_true)\n",
    "    pred_list = K.argmax(y_pred)\n",
    "    correct = K.cast(K.equal(true_list, pred_list), \"float32\")\n",
    "    mean_correct = K.mean(correct)\n",
    "    return mean_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.compile(loss=expert_loss, optimizer='adadelta', metrics=['acc', correct_ratio])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['acc'], weighted_metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelpath = os.path.join('.','keras_model','mlp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the model if it exists\n",
    "if os.path.isfile(modelpath):\n",
    "    model = load_model(modelpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tbCallBack = keras.callbacks.TensorBoard(log_dir=os.path.join('.','keras_model','graph'), \\\n",
    "                                         histogram_freq=0, \\\n",
    "                                         write_graph=True, \\\n",
    "                                         write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:2862: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 249s 4ms/step - loss: 0.1069 - acc: 0.9713 - weighted_acc: 0.9713 - val_loss: 0.0537 - val_acc: 0.9831 - val_weighted_acc: 0.9831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f21cf6cd278>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the model\n",
    "model.fit(x_train, y_train, \\\n",
    "          batch_size=batch_size, \\\n",
    "          epochs=nb_epoch, \\\n",
    "          verbose=1, \\\n",
    "          validation_data=(x_test, y_test), \\\n",
    "          shuffle=True, \\\n",
    "         callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.05368674308508634.\n",
      "Test Accuracy: 0.9831.\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test Score: {}.'.format(score[0]))\n",
    "print('Test Accuracy: {}.'.format(score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_test[0:2])\n",
    "print(np.argmax(pred, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model(model, modelpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced: Specific Layer Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv2d_1_input_1:0\", shape=(?, 28, 28, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "inp = model.input                                           # input placeholder\n",
    "print(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : Tensor(\"conv2d_1_1/BiasAdd:0\", shape=(?, 26, 26, 32), dtype=float32)\n",
      "1 : Tensor(\"batch_normalization_1_1/cond/Merge:0\", shape=(?, 26, 26, 32), dtype=float32)\n",
      "2 : Tensor(\"activation_1_1/Relu:0\", shape=(?, 26, 26, 32), dtype=float32)\n",
      "3 : Tensor(\"conv2d_2_1/BiasAdd:0\", shape=(?, 24, 24, 32), dtype=float32)\n",
      "4 : Tensor(\"batch_normalization_2_1/cond/Merge:0\", shape=(?, 24, 24, 32), dtype=float32)\n",
      "5 : Tensor(\"activation_2_1/Relu:0\", shape=(?, 24, 24, 32), dtype=float32)\n",
      "6 : Tensor(\"max_pooling2d_1_1/MaxPool:0\", shape=(?, 12, 12, 32), dtype=float32)\n",
      "7 : Tensor(\"flatten_1_1/Reshape:0\", shape=(?, ?), dtype=float32)\n",
      "8 : Tensor(\"dense_1_1/BiasAdd:0\", shape=(?, 128), dtype=float32)\n",
      "9 : Tensor(\"batch_normalization_3_1/cond/Merge:0\", shape=(?, 128), dtype=float32)\n",
      "10 : Tensor(\"activation_3_1/Relu:0\", shape=(?, 128), dtype=float32)\n",
      "11 : Tensor(\"dense_2_1/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "12 : Tensor(\"activation_4_1/Softmax:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "outputs = [layer.output for layer in model.layers]          # all layer outputs\n",
    "\n",
    "for out in range(len(outputs)): \n",
    "    print(out, \":\", outputs[out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp: the placeholder image\n",
    "# outputs[-1]: the latest layer\n",
    "functons = K.function([inp], [outputs[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_partial_res, = functons([x_test[0].reshape(1, 28, 28, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFfCAYAAACfj30KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCGkRijAhhLQIRZgQQlqEIkwIIS3y/wFYJOCHHvLvRQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c0e8b1e160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_img = np.minimum(x_test[0] * 255., 255.).reshape((28,28))  # reshape to (28, 28) for plt.imshow()\n",
    "test_img = test_img.astype(\"uint8\")\n",
    "plt.imshow(test_img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(keras_partial_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer Editing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Origin Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 601,578\n",
      "Trainable params: 601,194\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer Insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_layer(edit_model):\n",
    "    layers = [l for l in edit_model.layers]\n",
    "    for l in range(len(layers)): \n",
    "        print(l, \":\", layers[l].input, \"->\", layers[l].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : Tensor(\"conv2d_1_input_1:0\", shape=(?, 28, 28, 1), dtype=float32) -> Tensor(\"conv2d_1_1/BiasAdd:0\", shape=(?, 26, 26, 32), dtype=float32)\n",
      "1 : Tensor(\"conv2d_1_1/BiasAdd:0\", shape=(?, 26, 26, 32), dtype=float32) -> Tensor(\"batch_normalization_1_1/cond/Merge:0\", shape=(?, 26, 26, 32), dtype=float32)\n",
      "2 : Tensor(\"batch_normalization_1_1/cond/Merge:0\", shape=(?, 26, 26, 32), dtype=float32) -> Tensor(\"activation_1_1/Relu:0\", shape=(?, 26, 26, 32), dtype=float32)\n",
      "3 : Tensor(\"activation_1_1/Relu:0\", shape=(?, 26, 26, 32), dtype=float32) -> Tensor(\"conv2d_2_1/BiasAdd:0\", shape=(?, 24, 24, 32), dtype=float32)\n",
      "4 : Tensor(\"conv2d_2_1/BiasAdd:0\", shape=(?, 24, 24, 32), dtype=float32) -> Tensor(\"batch_normalization_2_1/cond/Merge:0\", shape=(?, 24, 24, 32), dtype=float32)\n",
      "5 : Tensor(\"batch_normalization_2_1/cond/Merge:0\", shape=(?, 24, 24, 32), dtype=float32) -> Tensor(\"activation_2_1/Relu:0\", shape=(?, 24, 24, 32), dtype=float32)\n",
      "6 : Tensor(\"activation_2_1/Relu:0\", shape=(?, 24, 24, 32), dtype=float32) -> Tensor(\"max_pooling2d_1_1/MaxPool:0\", shape=(?, 12, 12, 32), dtype=float32)\n",
      "7 : Tensor(\"max_pooling2d_1_1/MaxPool:0\", shape=(?, 12, 12, 32), dtype=float32) -> Tensor(\"flatten_1_1/Reshape:0\", shape=(?, ?), dtype=float32)\n",
      "8 : Tensor(\"flatten_1_1/Reshape:0\", shape=(?, ?), dtype=float32) -> Tensor(\"dense_1_1/BiasAdd:0\", shape=(?, 128), dtype=float32)\n",
      "9 : Tensor(\"dense_1_1/BiasAdd:0\", shape=(?, 128), dtype=float32) -> Tensor(\"batch_normalization_3_1/cond/Merge:0\", shape=(?, 128), dtype=float32)\n",
      "10 : Tensor(\"batch_normalization_3_1/cond/Merge:0\", shape=(?, 128), dtype=float32) -> Tensor(\"activation_3_1/Relu:0\", shape=(?, 128), dtype=float32)\n",
      "11 : Tensor(\"activation_3_1/Relu:0\", shape=(?, 128), dtype=float32) -> Tensor(\"dense_2_1/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "12 : Tensor(\"dense_2_1/BiasAdd:0\", shape=(?, 10), dtype=float32) -> Tensor(\"activation_4_1/Softmax:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "show_layer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_layer(edit_model, layer_id, new_layer):\n",
    "    \"\"\"\n",
    "    layer_id: start from input with 0\n",
    "    \"\"\"\n",
    "    layers = [l for l in edit_model.layers]\n",
    "    \n",
    "    #for l in layers: print(l.input, l.output)\n",
    "    \n",
    "    x = layers[0].output\n",
    "    for i in range(1, len(layers)):\n",
    "        if i == layer_id:\n",
    "            for layer_idx in new_layer:\n",
    "                x = layer_idx(x)\n",
    "        x = layers[i](x)\n",
    "        \n",
    "    new_model = Model(input=layers[0].input, outputs=x)\n",
    "    \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:16: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ac..., inputs=Tensor(\"co...)`\n"
     ]
    }
   ],
   "source": [
    "inserted_model = insert_layer(model, 11, [Dense(128), BatchNormalization(), Activation('relu')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1_input (InputLayer)  (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 618,602\n",
      "Trainable params: 617,962\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inserted_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_intermediate_single_layer_in_keras(edit_model, layer_id, new_layer):\n",
    "    layers = [l for l in edit_model.layers]\n",
    "\n",
    "    x = layers[0].output\n",
    "    for i in range(1, len(layers)):\n",
    "        if i == layer_id:\n",
    "            x = new_layer(x)\n",
    "        else:\n",
    "            x = layers[i](x)\n",
    "\n",
    "    new_model = Model(input=layers[0].input, output=x)\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_intermediate_multiple_layer_in_keras(edit_model, layer_dict):\n",
    "    layers = [l for l in edit_model.layers]\n",
    "    \n",
    "    layer_id = list(layer_dict.keys())\n",
    "\n",
    "    x = layers[0].output\n",
    "    for i in range(1, len(layers)):\n",
    "        if i in layer_id:\n",
    "            x = layer_dict[i](x)\n",
    "        else:\n",
    "            x = layers[i](x)\n",
    "\n",
    "    new_model = Model(input=layers[0].input, output=x)\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ac..., inputs=Tensor(\"co...)`\n"
     ]
    }
   ],
   "source": [
    "replaced_layer = OrderedDict()\n",
    "replaced_layer[11] = Dense(2)\n",
    "replaced_layer[12] = Activation('softmax')\n",
    "replaced_model = replace_intermediate_multiple_layer_in_keras(model, replaced_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1_input (InputLayer)  (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 600,546\n",
      "Trainable params: 600,162\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "replaced_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export from .h5 to .tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-nightly\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/34/c5d7ccc5f0c77e14613331d5886cb14b20f354fbf02cb17c6db97148d350/tf_nightly-1.13.0.dev20181120-cp35-cp35m-manylinux1_x86_64.whl (90.9MB)\n",
      "\u001b[K    100% |################################| 90.9MB 175kB/s ta 0:00:011 2% |                                | 2.6MB 2.0MB/s eta 0:00:46    3% |                                | 2.7MB 2.5MB/s eta 0:00:36    3% |#                               | 3.2MB 4.7MB/s eta 0:00:19    4% |#                               | 3.9MB 1.7MB/s eta 0:00:50    11% |###                             | 10.1MB 5.1MB/s eta 0:00:16    11% |###                             | 10.5MB 9.5MB/s eta 0:00:09    21% |#######                         | 20.0MB 5.5MB/s eta 0:00:13    23% |#######                         | 21.2MB 7.4MB/s eta 0:00:10    23% |#######                         | 21.4MB 4.3MB/s eta 0:00:17    24% |#######                         | 22.5MB 1.6MB/s eta 0:00:43    26% |########                        | 24.0MB 7.3MB/s eta 0:00:10    26% |########                        | 24.4MB 3.7MB/s eta 0:00:18    27% |########                        | 25.1MB 4.8MB/s eta 0:00:14    29% |#########                       | 26.5MB 2.9MB/s eta 0:00:23    30% |#########                       | 27.8MB 9.8MB/s eta 0:00:07    30% |#########                       | 28.0MB 3.3MB/s eta 0:00:20    34% |###########                     | 31.6MB 7.6MB/s eta 0:00:08    35% |###########                     | 32.6MB 5.5MB/s eta 0:00:11    39% |############                    | 36.1MB 987kB/s eta 0:00:56    46% |##############                  | 42.5MB 2.2MB/s eta 0:00:23    47% |###############                 | 42.8MB 8.4MB/s eta 0:00:06    49% |###############                 | 44.7MB 6.6MB/s eta 0:00:08    50% |################                | 45.8MB 2.6MB/s eta 0:00:18    53% |#################               | 48.3MB 2.0MB/s eta 0:00:22    55% |#################               | 50.6MB 3.5MB/s eta 0:00:12    55% |#################               | 50.9MB 4.1MB/s eta 0:00:10    58% |##################              | 52.8MB 1.8MB/s eta 0:00:21    61% |###################             | 55.8MB 3.8MB/s eta 0:00:10    62% |####################            | 57.1MB 3.8MB/s eta 0:00:09    63% |####################            | 58.1MB 10.4MB/s eta 0:00:04    64% |####################            | 58.8MB 5.7MB/s eta 0:00:06    66% |#####################           | 60.0MB 5.2MB/s eta 0:00:06    66% |#####################           | 60.4MB 5.2MB/s eta 0:00:06    66% |#####################           | 60.6MB 6.3MB/s eta 0:00:05    68% |#####################           | 61.9MB 6.0MB/s eta 0:00:05    68% |######################          | 62.5MB 8.6MB/s eta 0:00:04    69% |######################          | 63.2MB 1.6MB/s eta 0:00:18    71% |######################          | 65.0MB 2.0MB/s eta 0:00:13    72% |#######################         | 66.3MB 8.1MB/s eta 0:00:04    73% |#######################         | 66.8MB 12.3MB/s eta 0:00:02    73% |#######################         | 66.9MB 1.8MB/s eta 0:00:14    75% |########################        | 68.5MB 1.9MB/s eta 0:00:13    77% |########################        | 70.3MB 2.3MB/s eta 0:00:09    79% |#########################       | 72.7MB 2.2MB/s eta 0:00:09    82% |##########################      | 75.0MB 5.6MB/s eta 0:00:03    82% |##########################      | 75.1MB 1.9MB/s eta 0:00:09    84% |###########################     | 76.8MB 8.9MB/s eta 0:00:02    86% |###########################     | 78.5MB 2.9MB/s eta 0:00:05    87% |###########################     | 79.5MB 4.2MB/s eta 0:00:03    89% |############################    | 81.1MB 315kB/s eta 0:00:32    89% |############################    | 81.2MB 2.4MB/s eta 0:00:04    89% |############################    | 81.6MB 2.2MB/s eta 0:00:05    90% |############################    | 82.2MB 7.4MB/s eta 0:00:02    91% |#############################   | 83.0MB 12.5MB/s eta 0:00:01    92% |#############################   | 84.0MB 8.4MB/s eta 0:00:01    93% |#############################   | 84.6MB 4.0MB/s eta 0:00:02    95% |##############################  | 86.9MB 5.8MB/s eta 0:00:01    99% |############################### | 90.7MB 1.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tb-nightly<1.14.0a0,>=1.13.0a0 (from tf-nightly)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/a8/b67446ac3356911de7717265e0093fada79ecbe2637436874f305eb849aa/tb_nightly-1.13.0a20181119-py3-none-any.whl (3.2MB)\n",
      "\u001b[K    100% |################################| 3.2MB 1.2MB/s ta 0:00:01    29% |#########                       | 942kB 2.2MB/s eta 0:00:02    86% |###########################     | 2.7MB 1.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.5/dist-packages (from tf-nightly) (1.15.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.5/dist-packages (from tf-nightly) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.5/dist-packages (from tf-nightly) (0.5.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.5/dist-packages (from tf-nightly) (1.11.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.5/dist-packages (from tf-nightly) (0.7.1)\n",
      "Collecting tf-estimator-nightly (from tf-nightly)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/d3/8897e230eb9f048ef9dec207cd463754f920fa79b2c113b11603885186a2/tf_estimator_nightly-1.12.0.dev20181120-py2.py3-none-any.whl (294kB)\n",
      "\u001b[K    100% |################################| 296kB 1.2MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.5/dist-packages (from tf-nightly) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.5/dist-packages (from tf-nightly) (0.31.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.5/dist-packages (from tf-nightly) (3.6.1)\n",
      "Collecting keras-preprocessing>=1.0.5 (from tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/fc/94/74e0fa783d3fc07e41715973435dd051ca89c550881b3454233c39c73e69/Keras_Preprocessing-1.0.5-py2.py3-none-any.whl\n",
      "Collecting keras-applications>=1.0.6 (from tf-nightly)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c4/2ff40221029f7098d58f8d7fb99b97e8100f3293f9856f0fb5834bef100b/Keras_Applications-1.0.6-py2.py3-none-any.whl (44kB)\n",
      "\u001b[K    100% |################################| 51kB 2.9MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.5/dist-packages (from tf-nightly) (1.15.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.5/dist-packages (from tb-nightly<1.14.0a0,>=1.13.0a0->tf-nightly) (0.14.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.5/dist-packages (from tb-nightly<1.14.0a0,>=1.13.0a0->tf-nightly) (3.0)\n",
      "Collecting mock>=2.0.0 (from tf-estimator-nightly->tf-nightly)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/35/f187bdf23be87092bd0f1200d43d23076cee4d0dec109f195173fd3ebc79/mock-2.0.0-py2.py3-none-any.whl (56kB)\n",
      "\u001b[K    100% |################################| 61kB 2.0MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.5/dist-packages (from protobuf>=3.6.1->tf-nightly) (39.1.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.5/dist-packages (from keras-applications>=1.0.6->tf-nightly) (2.8.0)\n",
      "Collecting pbr>=0.11 (from mock>=2.0.0->tf-estimator-nightly->tf-nightly)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/04/fddc1c2dd75b256eda4d360024692231a2c19a0c61ad7f4a162407c1ab58/pbr-5.1.1-py2.py3-none-any.whl (106kB)\n",
      "\u001b[K    100% |################################| 112kB 2.4MB/s ta 0:00:01\n",
      "\u001b[31mkeras 2.2.2 has requirement keras-applications==1.0.4, but you'll have keras-applications 1.0.6 which is incompatible.\u001b[0m\n",
      "\u001b[31mkeras 2.2.2 has requirement keras-preprocessing==1.0.2, but you'll have keras-preprocessing 1.0.5 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tb-nightly, pbr, mock, tf-estimator-nightly, keras-preprocessing, keras-applications, tf-nightly\n",
      "  Found existing installation: Keras-Preprocessing 1.0.3\n",
      "    Uninstalling Keras-Preprocessing-1.0.3:\n",
      "      Successfully uninstalled Keras-Preprocessing-1.0.3\n",
      "  Found existing installation: Keras-Applications 1.0.5\n",
      "    Uninstalling Keras-Applications-1.0.5:\n",
      "      Successfully uninstalled Keras-Applications-1.0.5\n",
      "Successfully installed keras-applications-1.0.6 keras-preprocessing-1.0.5 mock-2.0.0 pbr-5.1.1 tb-nightly-1.13.0a20181119 tf-estimator-nightly-1.12.0.dev20181120 tf-nightly-1.13.0.dev20181120\n",
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 1.13.0-dev20181120\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Tensorflow version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tflite_path = os.path.join('.','keras_model','mlp.tflite')\n",
    "assert os.path.exists(modelpath), \".h5 file is not found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-23-df30169a2d9d>:1: TocoConverter.from_keras_model_file (from tensorflow.lite.python.lite) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `lite.TFLiteConverter.from_keras_model_file` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/lite/python/lite.py:592: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.convert_variables_to_constants\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.extract_sub_graph\n",
      "INFO:tensorflow:Froze 20 variables.\n",
      "INFO:tensorflow:Converted 20 variables to const ops.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2405224"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.contrib.lite.TocoConverter.from_keras_model_file(modelpath)\n",
    "tflite_model = converter.convert()\n",
    "open(tflite_path, \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
