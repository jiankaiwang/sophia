{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNTK\n",
    "\n",
    "* *Author: JianKai Wang (https://sophia.ddns.net)*\n",
    "* *Date: 2018/04/18*\n",
    "\n",
    "Microsoft Cognitive Toolkit (CNTK) 是一套分散式深度學習的開源工具組。可透過 CNTK 簡易建立如 feed-forward DNNs, convolutional neural networks (CNNs) 或 Recurrent neural networks (RNN)，且已內建包含如 stochastic gradient descent (SGD, backpropagation) 等最佳化的工具。CNTK 描述神經網路為一系列有圖向性的計算過程。此外，CNTK 亦可自動調用 NVIDIA GPU 來加速深度學習，是深度學習領域中領先的框架之一。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "* Official WebSite: https://docs.microsoft.com/en-us/cognitive-toolkit/\n",
    "* CNTK on Github: https://github.com/Microsoft/CNTK\n",
    "* CNTK Tutorial: https://cntk.ai/pythondocs/gettingstarted.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NVidia Installation\n",
    "\n",
    "CNTK 可以自動調用 NVIDIA 顯示卡 (GPU) 來加速深度學習，底下是必要安裝組件。GPU 可用於加速深度學習，不僅是減少訓練時間，在測試與佈署產品時都能有效提升效率，但並非為深度學習所必備，相關內容已有相當多的資源可以參考，但最有趣的還是一影片可以讓你了解 CPU 與 GPU 在圖像上的計算差異，參考網址 https://www.youtube.com/watch?v=-P28LKWTzrI 。\n",
    "\n",
    "### 安裝組件\n",
    "\n",
    "1. 於 NVIDIA 官網 (http://www.nvidia.com.tw/Download/index.aspx) 下載目前最新的驅動程式。\n",
    "2. 下載並安裝 CUDA SDK (https://developer.nvidia.com/cuda-downloads)，CUDA 為 NVIDIA 提供的 SDK 可對顯示卡進行程式設計。\n",
    "3. 下載並安裝 cuDNN (https://developer.nvidia.com/rdp/cudnn-archive)，cuDNN 為一使用 CUDA 的深度神經網路函式庫。\n",
    "4. 設置底下環境變數\n",
    "\n",
    "```shell\n",
    "# windows example\n",
    "setx PATH \"C:\\Program Files\\NVIDIA Corporation\\NVSMI;%PATH%\"\n",
    "setx PATH \"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\bin;%PATH%\"\n",
    "setx PATH \"C:\\local\\cudnn-9.0-v7.0\\cuda\\bin;%PATH%\"\n",
    "```\n",
    "\n",
    "### 限制\n",
    "\n",
    "* 顯卡限制: 需要注意 CNTK 有最低支援的顯示卡要求，需要 compute capability >= 3.0 的顯卡，可以至官網 https://developer.nvidia.com/cuda-gpus 查詢 (此限制與其他深度學習框架，如 tensorflow 相同)。\n",
    "\n",
    "* 開發環境限制: 若使用 Visual Studio 進行開發，需要注意 Visual Studio 2017 支援 CUDA 9 以上 (CUDA 8.x 都不支援)，而 CUDA 9.x 以上不支援 Visual Studio 2015 含以下。底下所有的內容皆會以 python (anaconda IDE) 或 GO (visual studio code) 等來進行。\n",
    "\n",
    "## 安裝 MKL\n",
    "\n",
    "1. 參考 windows (https://docs.microsoft.com/en-us/cognitive-toolkit/setup-mkl-on-windows) 或 linux (https://docs.microsoft.com/en-us/cognitive-toolkit/setup-mkl-on-linux) 相關安裝。\n",
    "2. 須注意要設置環境變數。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安裝環境\n",
    "\n",
    "### 安裝 Anaconda\n",
    "\n",
    "Anaconda 為基於 Python 用於資料科學、機器學習等領域使用的 IDE，不僅提供如 jupyter notebook 線上互動開發環境、spyder 大量程式碼開發等環境，更已包含許多常用的工具 (如 pip) 與函式庫 (numpy, scipy) 等，相當適合想要進入人工智慧、資料科學等領域的人使用。可以至網頁 https://www.anaconda.com/download/ 下載安裝。\n",
    "\n",
    "建議安裝 python 3.5 以上的環境，此環境可以與其他深度學習框架併用，如 tensorflow 等。可以透過底下方式檢驗是否已安裝 anaconda，\n",
    "\n",
    "```shell\n",
    "# 於 CLI 下，輸入 python 或 pip --version 等\n",
    "# 應出現如 Python 3.5.4 |Anaconda custom (64-bit) 或 pip 9.0.2 等資訊\n",
    "$ python\n",
    "$ pip --version\n",
    "```\n",
    "\n",
    "### 安裝 CNTK\n",
    "\n",
    "可以參考網頁 https://docs.microsoft.com/en-us/cognitive-toolkit/Setup-CNTK-on-your-machine ，並根據機器類型來選擇安裝方法，須注意的是目前 CNTK 僅接受 amd64 架構安裝，並不支援如 ARM 等系列處理器 (包含如 Raspberry Pi 或 Jetson tx2 等開發版)。\n",
    "\n",
    "安裝時需要注意，有分成 CPU 與 GPU 兩類，需視機器硬體配置來決定，而若安裝 GPU 則之後可以透過 `try_set_default_device(cnd.cpu())` 函式來切換使用 CPU 進行深度學習。\n",
    "\n",
    "```shell\n",
    "# download CPU-Only version\n",
    "$ wget https://cntk.ai/PythonWheel/CPU-Only/cntk-2.4-cp35-cp35m-win_amd64.whl\n",
    "$ pip install cntk-2.4-cp35-cp35m-win_amd64.whl\n",
    "\n",
    "# download GPU version\n",
    "$ wget https://cntk.ai/PythonWheel/GPU/cntk-2.4-cp35-cp35m-win_amd64.whl\n",
    "$ pip install cntk-2.4-cp35-cp35m-win_amd64.whl\n",
    "```\n",
    "\n",
    "### 安裝其他必要套件\n",
    "\n",
    "* 安裝其他 CNTK 使用套件，如 OpenCV 等\n",
    "\n",
    "```shell\n",
    "conda install -c menpo opencv3 \n",
    "pip install opencv-python easydict pyyaml\n",
    "```\n",
    "\n",
    "* [optional] 重新安裝 pillow\n",
    "\n",
    "在使用時可能出現 `can not import Image from PIL` 的訊息，可以透過重新安裝 pillow 來解決問題。\n",
    "\n",
    "```shell\n",
    "# conda install pillow=5.0.0\n",
    "conda uninstall pillow\n",
    "pip install pillow\n",
    "```\n",
    "\n",
    "* 下載 CNTK Sample\n",
    "\n",
    "於目前路徑下載 CNTK Sample，此 sample 中包含如 Tutorials、Examples、Manual 或 PretrainedModels 等，是相當有用的資源。\n",
    "\n",
    "```shell\n",
    "$ cd ~\n",
    "$ python -m cntk.sample_installer\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNTK 快速導覽\n",
    "\n",
    "### Check CNTK version\n",
    "\n",
    "可以透過底下函式來確認 CNTK 是否已經安裝完成。可以透過 `try_set_default_device(cnd.cpu())` 或 `try_set_default_device(cnd.gpu(0))` 等函式來切換訓練使用的資源為 CPU 或 GPU。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify the cntk verion\n",
    "import cntk\n",
    "print(cntk.__version__)\n",
    "\n",
    "# check CPU/GPU device info\n",
    "cntk.logging.set_trace_level(2)\n",
    "cntk.all_devices() \n",
    "\n",
    "# set default devive\n",
    "import cntk.device as cnd\n",
    "# set the default device to CPU\n",
    "cnd.try_set_default_device(cnd.cpu())\n",
    "# set the default device to GPU\n",
    "#cnd.try_set_default_device(cnd.gpu(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Toy 範例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 資料準備\n",
    "\n",
    "```shell\n",
    "# make sure you have already downloaded the samples\n",
    "$ python -m cntk.sample_installer\n",
    "\n",
    "# under Examples/Image/Detection/FastRCNN\n",
    "# the Grocery datasets would be downloaded under Examples/Image/DataSets/Grocery\n",
    "# the default net AlexNet model would be downloaded under PretrainedModels/\n",
    "$ python install_data_and_model.py\n",
    "```\n",
    "\n",
    "* 修改 CNTK 執行組態\n",
    "\n",
    "```shell\n",
    "# # under Examples/Image/Detection/FasterRCNN\n",
    "# visualize the prediction and labels\n",
    "$ vim FasterRCNN_config.py\n",
    "```\n",
    "\n",
    "```python\n",
    "# set the flag\n",
    "__C.VISUALIZE_RESULTS = True\n",
    "\n",
    "# edit the run_faster_rcnn.py to use CPU only\n",
    "if __name__ == '__main__':\n",
    "    cfg = get_configuration()\n",
    "    prepare(cfg, False)\n",
    "    #cntk.device.try_set_default_device(cntk.device.gpu(cfg.GPU_ID))\n",
    "    cntk.device.try_set_default_device(cntk.device.cpu())\n",
    "```\n",
    "\n",
    "* 執行 Faster-RCNN 模型\n",
    "\n",
    "```shell\n",
    "# to train and evaluate Faster R-CNN model\n",
    "$ python run_faster_rcnn.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple CNTK Flow\n",
    "\n",
    "底下為一簡單範例說明 CNTK 的深度學習流程。建立 2 全連結層深度神經網路 (2-layer fully connected deep neural network)，每層內含有 50 隱藏維度。有 2 個輸入變數，輸入資料與標籤。模型為兩個 Dense layer ，並建立每一層所需權重、偏差值與激活函式。`ce` 為 `cross entropy` 用來定義模型的 loss function，`pe` 為用來計算分類錯誤的函式。模型使用標準 SGD 來進行最佳化，而其學習速率為 0.125。\n",
    "\n",
    "模型建立後，進行循環性訓練 (training loop)，共 1024 次 (epochs, `num_minibatches_to_train`)。在每一次循環的訓練中，取得 `features` 與 `labels` 資料，並呼叫 `train_minibatch` 函式來映射目前使用的小訓練資料集 (minibatch) 的輸入資料與標籤。之後使用函式 `print_training_progress` 來每經 20 循環顯示 loss 及 error 結果。\n",
    "\n",
    "當訓練完畢，可以透過 `trainer` 物件來測試神經網路。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " average      since    average      since      examples\n",
      "    loss       last     metric       last              \n",
      " ------------------------------------------------------\n",
      "Learning rate per minibatch: 0.125\n",
      "      1.8        1.8       0.56       0.56            25\n",
      "     1.03      0.639      0.373       0.28            75\n",
      "    0.815      0.655       0.36       0.35           175\n",
      "     0.68      0.562      0.344       0.33           375\n",
      "    0.589      0.503      0.259       0.18           775\n",
      "    0.502      0.417      0.192      0.128          1575\n",
      "    0.414      0.327      0.144     0.0956          3175\n",
      "    0.341      0.268      0.116     0.0894          6375\n",
      "    0.285      0.229     0.0968     0.0772         12775\n",
      "     0.25      0.216     0.0875     0.0782         25575\n",
      " error rate on an unseen minibatch: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.24999519041273743, 0.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import cntk as C\n",
    "from cntk.learners import sgd\n",
    "from cntk.logging import ProgressPrinter\n",
    "from cntk.layers import Dense, Sequential\n",
    "\n",
    "def generate_random_data(sample_size, feature_dim, num_classes):\n",
    "     # Create synthetic data using NumPy.\n",
    "     Y = np.random.randint(size=(sample_size, 1), low=0, high=num_classes)\n",
    "\n",
    "     # Make sure that the data is separable\n",
    "     X = (np.random.randn(sample_size, feature_dim) + 3) * (Y + 1)\n",
    "     X = X.astype(np.float32)\n",
    "     # converting class 0 into the vector \"1 0 0\",\n",
    "     # class 1 into vector \"0 1 0\", ...\n",
    "     class_ind = [Y == class_number for class_number in range(num_classes)]\n",
    "     Y = np.asarray(np.hstack(class_ind), dtype=np.float32)\n",
    "     return X, Y\n",
    "\n",
    "def ffnet():\n",
    "    inputs = 2\n",
    "    outputs = 2\n",
    "    layers = 2\n",
    "    hidden_dimension = 50\n",
    "\n",
    "    # input variables denoting the features and label data\n",
    "    features = C.input_variable((inputs), np.float32)\n",
    "    label = C.input_variable((outputs), np.float32)\n",
    "\n",
    "    # Instantiate the feedforward classification model\n",
    "    my_model = Sequential ([\n",
    "                    Dense(hidden_dimension, activation=C.sigmoid),\n",
    "                    Dense(outputs)])\n",
    "    z = my_model(features)\n",
    "\n",
    "    ce = C.cross_entropy_with_softmax(z, label)\n",
    "    pe = C.classification_error(z, label)\n",
    "\n",
    "    # Instantiate the trainer object to drive the model training\n",
    "    lr_per_minibatch = C.learning_parameter_schedule(0.125)\n",
    "    progress_printer = ProgressPrinter(0)\n",
    "    trainer = C.Trainer(z, (ce, pe), [sgd(z.parameters, lr=lr_per_minibatch)], [progress_printer])\n",
    "\n",
    "    # Get minibatches of training data and perform model training\n",
    "    minibatch_size = 25\n",
    "    num_minibatches_to_train = 1024\n",
    "\n",
    "    aggregate_loss = 0.0\n",
    "    for i in range(num_minibatches_to_train):\n",
    "        train_features, labels = generate_random_data(minibatch_size, inputs, outputs)\n",
    "        # Specify the mapping of input variables in the model to actual minibatch data to be trained with\n",
    "        trainer.train_minibatch({features : train_features, label : labels})\n",
    "        sample_count = trainer.previous_minibatch_sample_count\n",
    "        aggregate_loss += trainer.previous_minibatch_loss_average * sample_count\n",
    "\n",
    "    last_avg_error = aggregate_loss / trainer.total_number_of_samples_seen\n",
    "\n",
    "    test_features, test_labels = generate_random_data(minibatch_size, inputs, outputs)\n",
    "    avg_error = trainer.test_minibatch({features : test_features, label : test_labels})\n",
    "    print(' error rate on an unseen minibatch: {}'.format(avg_error))\n",
    "    return last_avg_error, avg_error\n",
    "\n",
    "np.random.seed(98052)\n",
    "ffnet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNTK Architecture\n",
    "\n",
    "![images/cntk_arch.jpg](images/cntk_arch.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
