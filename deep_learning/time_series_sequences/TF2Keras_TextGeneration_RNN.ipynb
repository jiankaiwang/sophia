{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TF2Keras_TextGeneration_RNN.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNeFX7jfDvOr9PUhQkEBMpu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"F3jkExp9jSgv","colab_type":"text"},"source":["This tutorial guides you on how to generate text using a character-based RNN model. This model helps to generate a character one by one and a longer sequence can execute it repeatedly. **However, such a model can't understand the meanings of word, how to spell them as well, and what a role plays in a sentence.**\n","\n","On the contrary, this model is simple to capture the details on the character levels, such as capitalization, the conversation format, etc."]},{"cell_type":"code","metadata":{"id":"D493tYSraQzo","colab_type":"code","colab":{}},"source":["!pip install -q tf-nightly"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XvCaFSIXagLG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"e892c627-6cb3-4a27-d79c-c113d881bf6e","executionInfo":{"status":"ok","timestamp":1581662052786,"user_tz":-480,"elapsed":5143,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}}},"source":["import tensorflow as tf\n","import numpy as np\n","import os\n","import time\n","\n","print(\"Tensorflow Version: {}\".format(tf.__version__))\n","print(\"GPU {} available.\".format(\"is\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"not\"))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Tensorflow Version: 2.2.0-dev20200212\n","GPU is available.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6Lmek1XElHFS","colab_type":"text"},"source":["# Data Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"WxxLFEBAlYuz","colab_type":"text"},"source":["Here we are going to use the dataset of Shakespeare's writing from [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)."]},{"cell_type":"code","metadata":{"id":"zPvyIzcQlYcL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"cdb222c9-a874-45c1-c67f-86ed83434ecb","executionInfo":{"status":"ok","timestamp":1581662052789,"user_tz":-480,"elapsed":5130,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}}},"source":["path_to_file = tf.keras.utils.get_file('shakespeare.txt', \n","                                       'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n","path_to_file"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n","1122304/1115394 [==============================] - 0s 0us/step\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["'/root/.keras/datasets/shakespeare.txt'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"dTOVHBLOlpwV","colab_type":"text"},"source":["## Read the Data"]},{"cell_type":"code","metadata":{"id":"u0qHAh3ma-y0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"4b299f3b-7799-49d7-e36e-d0fe283ad2dd","executionInfo":{"status":"ok","timestamp":1581662052790,"user_tz":-480,"elapsed":5122,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}}},"source":["text = open(path_to_file, 'rb').read().decode('UTF-8')\n","print(\"Length of text: {} characters\".format(len(text)))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Length of text: 1115394 characters\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"V3BVh6OqmBe_","colab_type":"text"},"source":["Let's take a look at first few characters."]},{"cell_type":"code","metadata":{"id":"ktSyTJB-l-Sc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":255},"outputId":"3b411614-3fd0-44cc-e166-728f86aa3d50","executionInfo":{"status":"ok","timestamp":1581662052791,"user_tz":-480,"elapsed":5114,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}}},"source":["print(text[:200])"],"execution_count":5,"outputs":[{"output_type":"stream","text":["First Citizen:\n","Before we proceed any further, hear me speak.\n","\n","All:\n","Speak, speak.\n","\n","First Citizen:\n","You are all resolved rather to die than to famish?\n","\n","All:\n","Resolved. resolved.\n","\n","First Citizen:\n","First, you\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jVQ4pSjBmQZM","colab_type":"text"},"source":["Let's calculate the unique characters."]},{"cell_type":"code","metadata":{"id":"oRB_UM8GmI6K","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"001ac5bc-c1a2-4d66-ad72-075f9581064d","executionInfo":{"status":"ok","timestamp":1581662052792,"user_tz":-480,"elapsed":5019,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}}},"source":["vocab = sorted(set(text))\n","print(\"Unique characters: {}\".format(len(vocab)))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Unique characters: 65\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6-T3OR95n_ex","colab_type":"text"},"source":["## Vectorize the text"]},{"cell_type":"markdown","metadata":{"id":"fdmogeUyoFFX","colab_type":"text"},"source":["Before training, we have to convert the strings to the numerical representation."]},{"cell_type":"code","metadata":{"id":"6f5_1PjymcIa","colab_type":"code","colab":{}},"source":["char2idx = {u:i for i, u in enumerate(vocab)}\n","idx2char = np.array(vocab)\n","\n","# transform the text with integers\n","text_as_int = [char2idx[c] for c in text]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HEW9G2Zto1J4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":357},"outputId":"1be6dff9-5fe8-4d69-855f-185cd0e95bdc","executionInfo":{"status":"ok","timestamp":1581662053226,"user_tz":-480,"elapsed":5426,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}}},"source":["for char, _ in zip(char2idx, range(20)):\n","  print('{:4s}: {:3d}'.format(repr(char), char2idx[char]))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["'\\n':   0\n","' ' :   1\n","'!' :   2\n","'$' :   3\n","'&' :   4\n","\"'\" :   5\n","',' :   6\n","'-' :   7\n","'.' :   8\n","'3' :   9\n","':' :  10\n","';' :  11\n","'?' :  12\n","'A' :  13\n","'B' :  14\n","'C' :  15\n","'D' :  16\n","'E' :  17\n","'F' :  18\n","'G' :  19\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Edfkbl_6pq84","colab_type":"text"},"source":["Show the first few characters with their mapping integers."]},{"cell_type":"code","metadata":{"id":"dlkksC-vpFiF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e5354800-5d1e-4427-c49f-923f937acc18","executionInfo":{"status":"ok","timestamp":1581662053227,"user_tz":-480,"elapsed":5418,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}}},"source":["print(\"{} <---> {}\".format(repr(text[:20]), text_as_int[:20]))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["'First Citizen:\\nBefor' <---> [18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SiqFGNyMqens","colab_type":"text"},"source":["## Prediction"]},{"cell_type":"markdown","metadata":{"id":"8iQWzPWOr4FK","colab_type":"text"},"source":["The purpose of the prediction is to predict the character given an input one. We are going to train a model for the above purpose. The input of the model is a sequence of characters and the prediction is the next character of the same sequence. The attributes of RNNs are memorizing the previously seen data, a stateful concept. The prediction would be what the next character is, given all the characters until this moment."]},{"cell_type":"markdown","metadata":{"id":"Ha9Zb1b7r6ml","colab_type":"text"},"source":["### Training Examples and Targets"]},{"cell_type":"markdown","metadata":{"id":"r4m9TJwWtNRu","colab_type":"text"},"source":["The basic operation idea is to break down the same text into the inputs and outputs. The output is shifted forward one character of the input. For example, if the `sequence_len` is 4 and the sentence is `hello`, the input sequence becomes `hell` and the output (or target) one becomes `ello`."]},{"cell_type":"code","metadata":{"id":"sFaqMds5qJs4","colab_type":"code","colab":{}},"source":["seq_length = 100\n","examples_per_epoch = len(text) // (seq_length + 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wImchot_xFqW","colab_type":"code","colab":{}},"source":["char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zSBsfKE0xKnV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"2893eefc-53b0-47e1-81f8-8a52b46ac2f3","executionInfo":{"status":"ok","timestamp":1581662055918,"user_tz":-480,"elapsed":8077,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}}},"source":["for c in char_dataset.take(10):\n","  print(idx2char[c.numpy()], end=\" \")"],"execution_count":12,"outputs":[{"output_type":"stream","text":["F i r s t   C i t i "],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"itTfTkOLxyh2","colab_type":"text"},"source":["Here we use `batch()` to split the characters to sequences of the desired size."]},{"cell_type":"code","metadata":{"id":"EliGi_EyxR98","colab_type":"code","colab":{}},"source":["sequences = char_dataset.batch(seq_length + 1, drop_remainder=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tuLtrdjlyBuQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"outputId":"c9eaa16b-2de2-4b2c-e407-5f903454ca75","executionInfo":{"status":"ok","timestamp":1581662055921,"user_tz":-480,"elapsed":8059,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}}},"source":["for seq in sequences.take(5):\n","  print(repr(''.join(idx2char[seq.numpy()])))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n","'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n","\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n","\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n","'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LTjzNkR1ybO2","colab_type":"text"},"source":["For each sequence, we need to split it into the training and the target sequence."]},{"cell_type":"code","metadata":{"id":"s7dBFQVByLsn","colab_type":"code","colab":{}},"source":["def split_input_target(data):\n","  inputs = data[:-1]\n","  target = data[1:]\n","  return inputs, target\n","\n","dataset = sequences.map(split_input_target)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ooJlRAP7y3XT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"3025fdd7-51a6-4581-fe80-873fe8aaada2","executionInfo":{"status":"ok","timestamp":1581662055922,"user_tz":-480,"elapsed":8038,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}}},"source":["for input_example, target_example in dataset.take(1):\n","  print(repr(''.join(idx2char[input_example.numpy()])))\n","  print(repr(''.join(idx2char[target_example.numpy()])))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n","'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"a2LChvrP0HdP","colab_type":"text"},"source":["Each index of these sequence vectors represents one time step. For the input character at time 0 is `F` and the target to be predicted is `i`. The RNN model considers the previous step status in addition to the current input character."]},{"cell_type":"code","metadata":{"id":"YdF0q6R-zMat","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"outputId":"b4c551ab-8ef0-46e2-851e-c7c630b32005","executionInfo":{"status":"ok","timestamp":1581662294529,"user_tz":-480,"elapsed":1206,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}}},"source":["for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n","  print(\"Step {}: input {:s}, target {:s}\".format(\n","    i, repr(idx2char[input_idx.numpy()]), repr(idx2char[target_idx.numpy()])))"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Step 0: input 'F', target 'i'\n","Step 1: input 'i', target 'r'\n","Step 2: input 'r', target 's'\n","Step 3: input 's', target 't'\n","Step 4: input 't', target ' '\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oDG07bFia41e","colab_type":"text"},"source":["### Creating Training Batches"]},{"cell_type":"code","metadata":{"id":"Lki0MUIaap9f","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"79551f5a-256c-4e53-fffb-c561515e2477","executionInfo":{"status":"ok","timestamp":1581662521366,"user_tz":-480,"elapsed":1184,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}}},"source":["BATCH_SIZE = 64\n","BUFFER_SIZE = 10000\n","\n","dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n","dataset"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int32, tf.int32)>"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"ER595dAvc95p","colab_type":"text"},"source":["# Build the Model"]},{"cell_type":"code","metadata":{"id":"z9UXqBJ9bsJv","colab_type":"code","colab":{}},"source":["vocab_size = len(vocab)\n","embedding_dim = 256\n","rnn_units = 1024  # for gru cell"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JsKptazhdmWg","colab_type":"code","colab":{}},"source":["def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n","  def _model(inputs):\n","    embed = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim)(inputs)  # [batch_size, None, 256]\n","    # set `return_sequences=True` for predicting the next character\n","    gru = tf.keras.layers.GRU(units=rnn_units, return_sequences=True, stateful=True,\n","                              recurrent_initializer='glorot_uniform')(embed)    # [None, None, 1024]\n","    outputs = tf.keras.layers.Dense(units=vocan_size)(gru)\n","    return outputs\n","\n","  # if the stateful is True, it requires the batch size\n","  inputs = tf.keras.Input(shape=(None, ), batch_size=batch_size)\n","  generator = _model(inputs)\n","  return tf.keras.Model(inputs, generator)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NNTV5ij2fChv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":289},"outputId":"2309627e-eceb-44f5-c0a5-fcf98997d241","executionInfo":{"status":"ok","timestamp":1581664697340,"user_tz":-480,"elapsed":1141,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}}},"source":["model = build_model(vocab_size=vocab_size, embedding_dim=embedding_dim, \n","                    rnn_units=rnn_units, batch_size=BATCH_SIZE)\n","model.summary()"],"execution_count":59,"outputs":[{"output_type":"stream","text":["Model: \"model_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_16 (InputLayer)        [(64, None)]              0         \n","_________________________________________________________________\n","embedding_11 (Embedding)     (64, None, 256)           16640     \n","_________________________________________________________________\n","gru_11 (GRU)                 (64, None, 1024)          3938304   \n","_________________________________________________________________\n","dense_4 (Dense)              (64, None, 65)            66625     \n","=================================================================\n","Total params: 4,021,569\n","Trainable params: 4,021,569\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PlK4LB-NkvpA","colab_type":"text"},"source":["The above model can be translated as the below model architecture.\n","\n","![](https://www.tensorflow.org/tutorials/text/images/text_generation_training.png)\n","\n","Refer to Tensorflow.org (2020)."]},{"cell_type":"markdown","metadata":{"id":"WdmnE_TJlEGI","colab_type":"text"},"source":["# Try the Model"]},{"cell_type":"markdown","metadata":{"id":"ZWu8Pr4-lQJk","colab_type":"text"},"source":["Let's try the model first to check the result."]},{"cell_type":"code","metadata":{"id":"5XXoreK2feOd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"cc099cac-d792-45df-8914-b4150df33418","executionInfo":{"status":"ok","timestamp":1581665150092,"user_tz":-480,"elapsed":7471,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}}},"source":["for input_example_batch, target_example_batch in dataset.take(1):\n","  prediction_example_batch = model(input_example_batch)\n","  print(prediction_example_batch.shape)  # [batch_size, sequence_length, vocab_size]"],"execution_count":60,"outputs":[{"output_type":"stream","text":["(64, 100, 65)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FoKHdkrbmHrG","colab_type":"text"},"source":["To get the actual predictions from the model, we need to sample from the output distribution to get the actual indices."]},{"cell_type":"code","metadata":{"id":"7xuIVajclsbf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"bf07cd39-2fb7-49cc-9421-38d93f0f2291","executionInfo":{"status":"ok","timestamp":1581669799590,"user_tz":-480,"elapsed":1211,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}}},"source":["sampled_indices = tf.random.categorical(logits=prediction_example_batch[0], num_samples=1)\n","sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n","sampled_indices"],"execution_count":147,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([57, 14, 22, 12,  1, 39, 37, 43, 17, 56,  0, 13, 50, 38, 63, 16, 41,\n","       63, 30, 30,  1, 39, 25, 14, 57, 56, 16, 41,  9, 30, 38, 29, 26, 25,\n","        8, 15, 51, 31, 44, 41, 24, 58, 60,  1, 19, 45, 20, 21,  9, 40, 11,\n","       49, 13, 38, 35, 31, 16,  4, 34, 27, 47, 32, 38, 26, 28, 18, 33,  7,\n","       11, 10, 60, 36, 64, 43, 42, 35, 28, 28, 58, 54, 40, 64, 57, 38, 28,\n","       53, 55,  4, 33, 62,  9, 38, 34,  4,  6, 10, 13,  4, 16, 64])"]},"metadata":{"tags":[]},"execution_count":147}]},{"cell_type":"code","metadata":{"id":"L2M0X0Qfm36Q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"510cde32-fe3a-4de6-cadd-ea616fd28da4","executionInfo":{"status":"ok","timestamp":1581665728144,"user_tz":-480,"elapsed":1201,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}}},"source":["print(\"Input: {}\".format(repr(''.join(idx2char[input_example_batch[0].numpy()]))))\n","print(\"Output: {}\".format(repr(''.join(idx2char[sampled_indices]))))"],"execution_count":68,"outputs":[{"output_type":"stream","text":["Input: \";\\nThat did but show thee, of a fool, inconstant\\nAnd damnable ingrateful: nor was't much,\\nThou woulds\"\n","Output: \"JXO3DseismNmL!,zmJArGWoHNvNIaA-DzIrV-iLNvQMU$wqmXp\\npG'GHveLmRoBcCAGZTaWwcHLoZtEcKReBrwrLMO&zP'reFU;V\"\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1LxiqdfQn_VM","colab_type":"text"},"source":["# Train the Model"]},{"cell_type":"markdown","metadata":{"id":"l9HnhqL5qSgr","colab_type":"text"},"source":["Before training, we have to decide how to train the model. To this problem, we can regard it as a classification problem. Given the previous RNN state, and the input this timestamp, predict the class of the next character."]},{"cell_type":"markdown","metadata":{"id":"S1u1lEE1qUqk","colab_type":"text"},"source":["## Attach an Optimizer, and Define a Loss Function"]},{"cell_type":"markdown","metadata":{"id":"E4gxoKmts8ea","colab_type":"text"},"source":["The `tf.keras.losses.sparse_categorical_crossentropy` API works in this case because it is applied across the last dimension of the predictions. For example, the target shape is `[batch_size, sequence_length]` and the prediction shape is `[batch_size, sequence_length, vocab_size]`. This API helps you calculate the loss alongside the last dimension of the predictions."]},{"cell_type":"code","metadata":{"id":"kgSidu2dntA5","colab_type":"code","colab":{}},"source":["def loss(labels, logits):\n","  return tf.reduce_mean(\n","    tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vFYaCItDroCO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"b83b9072-fc84-4c49-ee8a-24f25537c3ba","executionInfo":{"status":"ok","timestamp":1581667597357,"user_tz":-480,"elapsed":944,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}}},"source":["example_batch_loss = loss(target_example_batch, prediction_example_batch)\n","print(\"Prediction Shape: {}\".format(prediction_example_batch.shape))\n","print(\"Scalar Loss: {}\".format(example_batch_loss.numpy().mean()))"],"execution_count":96,"outputs":[{"output_type":"stream","text":["Prediction Shape: (64, 100, 65)\n","Scalar Loss: 4.173928737640381\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jqpiBOlPsyOc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"83721e48-e57a-4a95-ae83-c5c0c239a6a6","executionInfo":{"status":"ok","timestamp":1581667598998,"user_tz":-480,"elapsed":889,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}}},"source":["print(\"Target shapes: {}\".format(target_example_batch.shape))\n","print(\"Prediction shape: {}\".format(prediction_example_batch.shape))"],"execution_count":97,"outputs":[{"output_type":"stream","text":["Target shapes: (64, 100)\n","Prediction shape: (64, 100, 65)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5sc9rpSLs2Mi","colab_type":"code","colab":{}},"source":["def accuracy(labels, logits):\n","  logits = tf.cast(tf.argmax(logits, axis=-1), tf.int32)\n","  labels = tf.cast(labels, tf.int32)\n","  return tf.reduce_mean(tf.keras.metrics.binary_accuracy(labels, logits))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nOYCB2OruSu_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"6a2a1527-cd20-479a-fb3c-07e7ace3c330","executionInfo":{"status":"ok","timestamp":1581667676432,"user_tz":-480,"elapsed":601,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}}},"source":["accuracy(target_example_batch, prediction_example_batch)"],"execution_count":102,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(), dtype=float32, numpy=0.15562502>"]},"metadata":{"tags":[]},"execution_count":102}]},{"cell_type":"code","metadata":{"id":"NhEsAG9dvOCe","colab_type":"code","colab":{}},"source":["model.compile(loss=loss, optimizer=tf.keras.optimizers.Adam(), metrics=[accuracy])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"46NrECzsv5Ti","colab_type":"text"},"source":["## Configure the Checkpoints"]},{"cell_type":"code","metadata":{"id":"C3Wn2rMsvqyI","colab_type":"code","colab":{}},"source":["ckpt_dir = \"./train_ckpt\"\n","ckpt_prefix = os.path.join(ckpt_dir, 'ckpt_{epoch}')\n","\n","ckpt_callbacks = tf.keras.callbacks.ModelCheckpoint(\n","  filepath=ckpt_prefix, save_weights_only=True\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TBsZncK9wfNA","colab_type":"text"},"source":["## Start Training"]},{"cell_type":"code","metadata":{"id":"rX9QMfQxwei6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":374},"outputId":"1de638ef-85a4-4195-b67f-1e706303d3b7","executionInfo":{"status":"ok","timestamp":1581668154759,"user_tz":-480,"elapsed":87524,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}}},"source":["history = model.fit(dataset, epochs=10, callbacks=[ckpt_callbacks])"],"execution_count":109,"outputs":[{"output_type":"stream","text":["Train for 172 steps\n","Epoch 1/10\n","172/172 [==============================] - 9s 55ms/step - loss: 2.6650 - accuracy: 0.1671\n","Epoch 2/10\n","172/172 [==============================] - 9s 49ms/step - loss: 1.9623 - accuracy: 0.1727\n","Epoch 3/10\n","172/172 [==============================] - 9s 50ms/step - loss: 1.6959 - accuracy: 0.1749\n","Epoch 4/10\n","172/172 [==============================] - 8s 49ms/step - loss: 1.5473 - accuracy: 0.1753\n","Epoch 5/10\n","172/172 [==============================] - 9s 50ms/step - loss: 1.4593 - accuracy: 0.1756\n","Epoch 6/10\n","172/172 [==============================] - 9s 50ms/step - loss: 1.3993 - accuracy: 0.1759\n","Epoch 7/10\n","172/172 [==============================] - 9s 50ms/step - loss: 1.3528 - accuracy: 0.1761\n","Epoch 8/10\n","172/172 [==============================] - 9s 50ms/step - loss: 1.3140 - accuracy: 0.1764\n","Epoch 9/10\n","172/172 [==============================] - 9s 50ms/step - loss: 1.2798 - accuracy: 0.1765\n","Epoch 10/10\n","172/172 [==============================] - 9s 50ms/step - loss: 1.2472 - accuracy: 0.1767\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yu1cATQQxNnj","colab_type":"text"},"source":["# Generate Text"]},{"cell_type":"markdown","metadata":{"id":"eehuCFgjxXBe","colab_type":"text"},"source":["## Restore the Latest Checkpoint"]},{"cell_type":"markdown","metadata":{"id":"CV-DUy9wyJYR","colab_type":"text"},"source":["To keep the prediction simple, use a batch size of 1. Because of the way the RNN state passed from timestamp to timestamp (stateful=True), the model only accepts the same batch size once it was built."]},{"cell_type":"code","metadata":{"id":"bb4lkgZtw2c3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"4ed23c1d-d047-46e8-9b74-b9f6e7f0a4ec","executionInfo":{"status":"ok","timestamp":1581669996406,"user_tz":-480,"elapsed":1107,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}}},"source":["latest_ckpt = tf.train.latest_checkpoint(ckpt_dir)\n","latest_ckpt"],"execution_count":154,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'./train_ckpt/ckpt_10'"]},"metadata":{"tags":[]},"execution_count":154}]},{"cell_type":"code","metadata":{"id":"CRdEtF6MyQLZ","colab_type":"code","colab":{}},"source":["loaded = build_model(vocab_size, embedding_dim, rnn_units, 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7WqflcQ5ygOp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"6d76e142-4703-4fa5-9bb8-5cf6e98fb208","executionInfo":{"status":"ok","timestamp":1581669999898,"user_tz":-480,"elapsed":524,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}}},"source":["loaded.load_weights(latest_ckpt)"],"execution_count":156,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f338f269f98>"]},"metadata":{"tags":[]},"execution_count":156}]},{"cell_type":"code","metadata":{"id":"OTxJnjPgzFHu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":289},"outputId":"4e83be60-e6f6-4bce-ac81-05b590964fe8","executionInfo":{"status":"ok","timestamp":1581670006211,"user_tz":-480,"elapsed":1297,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}}},"source":["# the batch size was not reset\n","loaded.summary()"],"execution_count":157,"outputs":[{"output_type":"stream","text":["Model: \"model_10\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_22 (InputLayer)        [(1, None)]               0         \n","_________________________________________________________________\n","embedding_17 (Embedding)     (1, None, 256)            16640     \n","_________________________________________________________________\n","gru_17 (GRU)                 (1, None, 1024)           3938304   \n","_________________________________________________________________\n","dense_10 (Dense)             (1, None, 65)             66625     \n","=================================================================\n","Total params: 4,021,569\n","Trainable params: 4,021,569\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"18-96CnRzz2F","colab_type":"text"},"source":["## The Prediction Loop"]},{"cell_type":"markdown","metadata":{"id":"kd2pBoyG0LoI","colab_type":"text"},"source":["![](https://www.tensorflow.org/tutorials/text/images/text_generation_sampling.png)\n","\n","Refer to Tensorflow.org (2020)."]},{"cell_type":"code","metadata":{"id":"LJRnwPzRzGlV","colab_type":"code","colab":{}},"source":["def generate_text(model, start_string):\n","  # the number of characters to generate\n","  num_generate = 1000\n","\n","  input_eval = [char2idx[s] for s in start_string]\n","  input_eval = tf.expand_dims(input_eval, axis=0)\n","\n","  # for the generated characters\n","  text_generated = []\n","\n","  # low temperature results in more predictable characters\n","  # high temperature results in more surprising characters\n","  # this value requires experimenting\n","  temperature = 1.0\n","\n","  # now let's reset state for the first character\n","  model.reset_states()\n","\n","  for i in range(num_generate):\n","    predictions = model(input_eval)\n","\n","    # remove the batch dimension\n","    predictions = tf.squeeze(predictions, axis=0)\n","\n","    # using a categorical distribution to predict the character\n","    predictions = predictions / temperature\n","    # [-1, 0]: the output of the final character, select the first character\n","    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n","    text_generated.append(idx2char[predicted_id])\n","\n","    input_eval = tf.expand_dims([predicted_id], axis=0)\n","\n","  return start_string + ''.join(text_generated)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fjwO5-_T4Wgf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":527},"outputId":"f8a5a25e-d25e-4986-81a7-f572020ea88f","executionInfo":{"status":"ok","timestamp":1581670295419,"user_tz":-480,"elapsed":5257,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}}},"source":["print(generate_text(loaded, start_string=u\"ROMEO: \"))"],"execution_count":169,"outputs":[{"output_type":"stream","text":["ROMEO: you shall not follow\n","Our ancamest and turns how men here,\n","My good condament slilys that that were on you;\n","And till our converture dear chid and with a Clewere\n","They restoued between your day.\n","Forbear him; but, suchard take soon denied,\n","Which, being alloke of Grey, if I\n","be t, and not penury\n","What should prove suit in his mild, a saved\n","A rament impeach our sudsent on my father's\n","will'd mother indeed, hath sound our spirit,\n","Dre my tongue QuQUEEN ELIZABETH:\n","And be proservey; and, let him be fear,\n","I'll try us: what he doth curst\n","And sads the banish'd Henry's langul wings.\n","Go to, a way o'erwholess ribbons than a frantifle.\n","\n","YORK\n","I most not receive and clor to Rome\n","To fly o' the vigions and lords about this\n","oars have put on conscarced sensible in your daughter's pleasing in\n","thy father than the world, thou shalt temper it,\n","And figrer\n","Than you have wealy with your title.\n","How will they come with God's two better nobly fruit, they arr\n","remedy.\n","\n","YORK:\n","Why, thank'dy fault!\n","I have forged in thy blood, \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PStJ_pcH5egH","colab_type":"text"},"source":["You can train the model with more epochs, stack RNN layers to the model, or change the temperature value to check the model performance."]},{"cell_type":"markdown","metadata":{"id":"IzdOYSBk536-","colab_type":"text"},"source":["# Customized Training"]},{"cell_type":"markdown","metadata":{"id":"UNFBV4UE6zll","colab_type":"text"},"source":["These advanced operations help you in controlling the training step and help stabilize the model's open-loop output."]},{"cell_type":"code","metadata":{"id":"GhHbIxrM5SUL","colab_type":"code","colab":{}},"source":["adv_model = build_model(vocab_size, embedding_dim, rnn_units, BATCH_SIZE)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2sRwUj5C69zT","colab_type":"code","colab":{}},"source":["optimizer = tf.keras.optimizers.Adam()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RQcEElQo7A1M","colab_type":"code","colab":{}},"source":["@tf.function\n","def train_step(inputs, targets):\n","  with tf.GradientTape() as tape:\n","    predictions = adv_model(inputs)\n","    loss = tf.reduce_mean(\n","      tf.keras.losses.sparse_categorical_crossentropy(targets, predictions, from_logits=True)\n","    )\n","  grads = tape.gradient(loss, adv_model.trainable_variables)\n","  optimizer.apply_gradients(zip(grads, adv_model.trainable_variables))\n","  return loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AUzVUV1l7vqr","colab_type":"code","colab":{}},"source":["def train(epochs=10):\n","  for epoch in range(epochs):\n","    # initializing the hidden state at the beginning of every epoch\n","    # initial hidden state is None\n","    hidden = adv_model.reset_states()\n","\n","    for (batch_n, (inputs, targets)) in enumerate(dataset):\n","      loss = train_step(inputs, targets)\n","\n","      if batch_n % 100 == 0:\n","        template = \"Epoch {} Batch {} Loss {}\"\n","        print(template.format(epoch, batch_n, loss))\n","      \n","    # save the checkpoints\n","    if (epoch + 1) % 5 == 0:\n","      adv_model.save_weights(ckpt_prefix.format(epoch=epoch))\n","\n","    print(\"Epoch {} Loss {:.4f}\".format(epoch + 1, loss))\n","\n","  adv_model.save_weights(ckpt_prefix.format(epoch=epoch))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2dCBmvR989Ss","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":527},"outputId":"d5d95068-c203-4a41-87b5-802a03ce49e7","executionInfo":{"status":"ok","timestamp":1581671353011,"user_tz":-480,"elapsed":74762,"user":{"displayName":"王DevOps","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzLB0C3whTHAdHpq24UrEWqGtbhJElQxTU5_b_4g=s64","userId":"04300517850278510646"}}},"source":["train(epochs=10)"],"execution_count":176,"outputs":[{"output_type":"stream","text":["Epoch 0 Batch 0 Loss 2.1382858753204346\n","Epoch 0 Batch 100 Loss 1.9485670328140259\n","Epoch 1 Loss 1.7835\n","Epoch 1 Batch 0 Loss 1.8019925355911255\n","Epoch 1 Batch 100 Loss 1.7318795919418335\n","Epoch 2 Loss 1.6036\n","Epoch 2 Batch 0 Loss 1.5783309936523438\n","Epoch 2 Batch 100 Loss 1.5621082782745361\n","Epoch 3 Loss 1.5282\n","Epoch 3 Batch 0 Loss 1.4577150344848633\n","Epoch 3 Batch 100 Loss 1.4812841415405273\n","Epoch 4 Loss 1.4588\n","Epoch 4 Batch 0 Loss 1.416590929031372\n","Epoch 4 Batch 100 Loss 1.4205050468444824\n","Epoch 5 Loss 1.3977\n","Epoch 5 Batch 0 Loss 1.3192777633666992\n","Epoch 5 Batch 100 Loss 1.352297306060791\n","Epoch 6 Loss 1.3392\n","Epoch 6 Batch 0 Loss 1.2877389192581177\n","Epoch 6 Batch 100 Loss 1.341284155845642\n","Epoch 7 Loss 1.3229\n","Epoch 7 Batch 0 Loss 1.2206844091415405\n","Epoch 7 Batch 100 Loss 1.3187882900238037\n","Epoch 8 Loss 1.2878\n","Epoch 8 Batch 0 Loss 1.2013981342315674\n","Epoch 8 Batch 100 Loss 1.2553431987762451\n","Epoch 9 Loss 1.2984\n","Epoch 9 Batch 0 Loss 1.2264318466186523\n","Epoch 9 Batch 100 Loss 1.2362143993377686\n","Epoch 10 Loss 1.2188\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tJbwU_j19lgz","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}