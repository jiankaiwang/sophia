{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"TF2Keras_NMT_Attention.ipynb","provenance":[],"collapsed_sections":["-1nphg0bkPjF","NTyHIFyHkPjT","TUDrZwYOLtI7","Y9FkV-8GkPjf","fqHmcTQ-V8Se"]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["This tutorial guides you on how to train a sequence-to-sequence model to translate from Spanish to English. Second, you will build up the attention mechanism into the model. \n","\n","The following shows how to build up the attention mechanism from scratch. Now in Tensorflow, there are several latest API, like `tf.keras.layers.AdditiveAttention()`, to help you build it quickly.\n","\n","After training, you can plot a word-to-word plot showing the attention between words. The example plot shows which part of input sequence has the model's attention while translating.\n","\n","![](https://tensorflow.org/images/spanish-english.png)\n","Refer to Tensorflow.Org (2020).\n","\n","Reference:\n","* Neural machine translation with attention: https://www.tensorflow.org/tutorials/text/nmt_with_attention\n","* Neural Machine Translation (seq2seq) Tutorial: https://github.com/tensorflow/nmt"],"metadata":{"id":"DF4_6VAskPiM"}},{"cell_type":"code","source":["import logging\n","logging.basicConfig(level=logging.INFO, \n","                    format=\"%(asctime)s - %(levelname)s : %(message)s\")\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","from sklearn.model_selection import train_test_split\n","import unicodedata\n","import re\n","import numpy as np\n","import os\n","import io\n","\n","import tensorflow as tf\n","log = logging.getLogger('tensorflow')\n","print(\"Tensorflow Version: {}\".format(tf.__version__))\n","print(\"GPU is{} available.\".format(\n","    \"\" if tf.config.experimental.list_physical_devices(\"GPU\") else \" not\"))"],"metadata":{"id":"4MVVrj5skPiW","execution":{"iopub.status.busy":"2022-04-01T01:35:25.249268Z","iopub.execute_input":"2022-04-01T01:35:25.249613Z","iopub.status.idle":"2022-04-01T01:35:30.310099Z","shell.execute_reply.started":"2022-04-01T01:35:25.249525Z","shell.execute_reply":"2022-04-01T01:35:30.309361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data Preprocessing\n","\n","We'll use a language dataset provided by [http://www.manythings.org/anki/](http://www.manythings.org/anki/). The dataset contains the language-translation pairs in the format `Sentence1 Translated_Sentence2`.\n","\n","```text\n","May I borrow this book? 多Puedo tomar prestado este libro?\n","```\n","\n","You can download the desired dataset. After you downloaded the dataset, the following is the preprocessing step.\n","\n","1. Add a `start` and an `end` token to each sequence.\n","2. Clean the sentences by removing special characters.\n","3. Create mapping dictionaries that one maps from words to indices and the other maps from indices to words.\n","4. To do the batch training, we need to pad each sequence to a maximum length. However, there are different strategies to do padding, for example, a better way is masking."],"metadata":{"id":"i6qqPz26kPic"}},{"cell_type":"code","source":["# Download the dataset\n","path_to_dir = tf.keras.utils.get_file('spa-eng.zip', \n","                                      origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip', \n","                                      extract=True)\n","logging.info(\"Path to the directory: {}\".format(path_to_dir))"],"metadata":{"id":"8BlXpPkskPid","execution":{"iopub.status.busy":"2022-04-01T01:35:30.311768Z","iopub.execute_input":"2022-04-01T01:35:30.312454Z","iopub.status.idle":"2022-04-01T01:35:31.642882Z","shell.execute_reply.started":"2022-04-01T01:35:30.312392Z","shell.execute_reply":"2022-04-01T01:35:31.642177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path_to_file = os.path.join(os.path.dirname(path_to_dir), \"spa-eng\", \"spa.txt\")\n","assert os.path.exists(path_to_file), \"File was not found.\""],"metadata":{"id":"R9pZ3jZOkPih","execution":{"iopub.status.busy":"2022-04-01T01:35:31.645580Z","iopub.execute_input":"2022-04-01T01:35:31.645814Z","iopub.status.idle":"2022-04-01T01:35:31.653519Z","shell.execute_reply.started":"2022-04-01T01:35:31.645788Z","shell.execute_reply":"2022-04-01T01:35:31.652680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!tail -n 3 {path_to_file}"],"metadata":{"id":"IvWarm5CDpj5","execution":{"iopub.status.busy":"2022-04-01T01:35:31.657004Z","iopub.execute_input":"2022-04-01T01:35:31.657500Z","iopub.status.idle":"2022-04-01T01:35:32.322300Z","shell.execute_reply.started":"2022-04-01T01:35:31.657471Z","shell.execute_reply":"2022-04-01T01:35:32.321394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Convert a file encoding from the unicode to ascii."],"metadata":{"id":"VE-dw2VmBapr"}},{"cell_type":"code","source":["def unicode_to_ascii(s):\n","  \"\"\"\n","  normalize: Return the normal form form for the Unicode string unistr.\n","  category: Returns the general category assigned to the character chr as string.\n","  \"\"\"\n","  return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')"],"metadata":{"id":"YpA24KA4kPil","execution":{"iopub.status.busy":"2022-04-01T01:35:32.323790Z","iopub.execute_input":"2022-04-01T01:35:32.324069Z","iopub.status.idle":"2022-04-01T01:35:32.331460Z","shell.execute_reply.started":"2022-04-01T01:35:32.324033Z","shell.execute_reply":"2022-04-01T01:35:32.329269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The following is the example of preprocessing the sentence with cleaning the special chars and adding the start and end tag."],"metadata":{"id":"q8jVP70xB7hx"}},{"cell_type":"code","source":["def preprocess_sentence(w):\n","  \"\"\"Preprocess the sentence, and add tags on the head and the tail of it.\"\"\"\n","  w = unicode_to_ascii(w.lower().strip())\n","  \n","  # create a space between a word and the punctuation following it\n","  # \"This is the end.\" -> \"This is the end .\"\n","  w = re.sub(r\"([?.!,多])\", r\" \\1 \", w)\n","  w = re.sub(r'[\" \"]+', \" \", w)\n","\n","  # replacing everything with a space except (a-z, A-Z, '.', '?', '!', ',')\n","  w = re.sub(r\"[^a-zA-Z?.!,多]+\", \" \", w)\n","\n","  w = w.rstrip().strip()\n","\n","  # add a start and a end token\n","  w = '<start> ' + w + ' <end>'\n","  return w"],"metadata":{"id":"kOizjBrLkPio","execution":{"iopub.status.busy":"2022-04-01T01:35:32.334779Z","iopub.execute_input":"2022-04-01T01:35:32.335034Z","iopub.status.idle":"2022-04-01T01:35:32.341284Z","shell.execute_reply.started":"2022-04-01T01:35:32.335007Z","shell.execute_reply":"2022-04-01T01:35:32.340191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's try some examples. \n","\n","For the seq2seq task, it is necessary to add the start tag and the end tag for identifying where the sentence starts and ends. This operation is required by both of input and output sequences."],"metadata":{"id":"XPCDRmQNkPis"}},{"cell_type":"code","source":["en_sentence = u\"May I borrow this book?\"\n","sp_sentence = u\"多Puedo tomar prestado este libro?\"\n","\n","print(preprocess_sentence(en_sentence))\n","print(preprocess_sentence(sp_sentence).encode('utf-8'))"],"metadata":{"id":"WbDD5VCvkPiu","execution":{"iopub.status.busy":"2022-04-01T01:35:32.343261Z","iopub.execute_input":"2022-04-01T01:35:32.343484Z","iopub.status.idle":"2022-04-01T01:35:32.351350Z","shell.execute_reply.started":"2022-04-01T01:35:32.343460Z","shell.execute_reply":"2022-04-01T01:35:32.350458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Create a dataset with the preprocessings."],"metadata":{"id":"4iLuFGI4kPix"}},{"cell_type":"code","source":["def create_dataset(path, num_examples):\n","  \"\"\"Create the datasets for both the input sequence and the output sequence.\"\"\"\n","  lines = io.open(path, encoding='utf-8').read().strip().split('\\n')\n","  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')] for l in lines[:num_examples]]\n","  return zip(*word_pairs)"],"metadata":{"id":"PjovH-iakPiy","execution":{"iopub.status.busy":"2022-04-01T01:35:32.353144Z","iopub.execute_input":"2022-04-01T01:35:32.353481Z","iopub.status.idle":"2022-04-01T01:35:32.360745Z","shell.execute_reply.started":"2022-04-01T01:35:32.353417Z","shell.execute_reply":"2022-04-01T01:35:32.360076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["en, sp = create_dataset(path_to_file, None)\n","\n","logging.info(\"There are {} sequences.\".format(len(en)))\n","\n","print(en[-1])\n","print(sp[-1])"],"metadata":{"id":"IQ9_GDgFkPi2","execution":{"iopub.status.busy":"2022-04-01T01:35:32.362419Z","iopub.execute_input":"2022-04-01T01:35:32.362684Z","iopub.status.idle":"2022-04-01T01:35:38.909366Z","shell.execute_reply.started":"2022-04-01T01:35:32.362652Z","shell.execute_reply":"2022-04-01T01:35:38.908560Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The function tokenize implements how the sequence is tokenized. In the latest version of tensorflow (r2.8), you can simply use `tf.keras.layers.TextVectorization()` to tokenize the sequence with ease."],"metadata":{"id":"jii3uySJGbs6"}},{"cell_type":"code","source":["def tokenize(text):\n","  \"\"\"Implement the tokenizer.\"\"\"\n","  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n","  lang_tokenizer.fit_on_texts(text)\n","  tensor = lang_tokenizer.texts_to_sequences(text)\n","  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n","  return tensor, lang_tokenizer"],"metadata":{"id":"3A1V7JZmkPi-","execution":{"iopub.status.busy":"2022-04-01T01:35:38.912659Z","iopub.execute_input":"2022-04-01T01:35:38.913795Z","iopub.status.idle":"2022-04-01T01:35:38.919525Z","shell.execute_reply.started":"2022-04-01T01:35:38.913749Z","shell.execute_reply":"2022-04-01T01:35:38.918602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We warp all of the above procedures as a function. The function takes file path as the input and returns the input tensor (the input sequence), the target tensor (the output sequence), the input tokenizer, and the target tokenizer."],"metadata":{"id":"DDyubWC2HH43"}},{"cell_type":"code","source":["def load_dataset(path, num_examples=None):\n","  \"\"\"\n","  create cleaned input, output pairs\n","  to train a model from Spanish to English,\n","  the target language is English, and input language is Spanish\n","  \"\"\"\n","  targ_lang, inp_lang = create_dataset(path, num_examples)\n","  \n","  input_tensor, input_tokenizer = tokenize(inp_lang)\n","  target_tensor, target_tokenizer = tokenize(targ_lang)\n","\n","  return input_tensor, target_tensor, input_tokenizer, target_tokenizer"],"metadata":{"id":"6_sgg20GkPjB","execution":{"iopub.status.busy":"2022-04-01T01:35:38.920759Z","iopub.execute_input":"2022-04-01T01:35:38.921020Z","iopub.status.idle":"2022-04-01T01:35:38.930529Z","shell.execute_reply.started":"2022-04-01T01:35:38.920986Z","shell.execute_reply":"2022-04-01T01:35:38.929859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Limit the Size of Datasets\n","\n","Before training a model on the whole dataset, you can limit the dataset size to train it faster."],"metadata":{"id":"-1nphg0bkPjF"}},{"cell_type":"code","source":["num_examples = None  # you can try different numbers\n","input_tensor, target_tensor, input_tokenizer, target_tokenizer = load_dataset(path_to_file, num_examples)\n","\n","logging.info(\"Input tensor shape: {}\".format(input_tensor.shape))\n","logging.info(\"Target tensor shape: {}\".format(target_tensor.shape))\n","logging.info(\"Input tokenizer's vocabulary size: {}\".format(\n","    len(input_tokenizer.index_word)))\n","logging.info(\"Target tokenizer's vocabulary size: {}\".format(\n","    len(target_tokenizer.index_word)))"],"metadata":{"id":"r6AY1FHJkPjG","execution":{"iopub.status.busy":"2022-04-01T01:35:38.931675Z","iopub.execute_input":"2022-04-01T01:35:38.932061Z","iopub.status.idle":"2022-04-01T01:35:51.377273Z","shell.execute_reply.started":"2022-04-01T01:35:38.932019Z","shell.execute_reply":"2022-04-01T01:35:51.376568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def max_length(tensor):\n","  \"\"\"Get the max length of the sequence.\"\"\"\n","  tmp, maxlen = 0, 0\n","  for t in tensor:\n","    tmp = len(t)\n","    if tmp > maxlen:\n","      maxlen = tmp\n","  return maxlen\n","\n","# the max sequence length\n","max_length_target, max_length_input = max_length(target_tensor), max_length(input_tensor)\n","logging.info(\"The max length of input sequences is {}.\".format(max_length_input))\n","logging.info(\"The max length of target sequences is {}.\".format(max_length_target))"],"metadata":{"id":"4lJQraUtKsg8","execution":{"iopub.status.busy":"2022-04-01T01:35:51.378579Z","iopub.execute_input":"2022-04-01T01:35:51.378829Z","iopub.status.idle":"2022-04-01T01:35:51.451966Z","shell.execute_reply.started":"2022-04-01T01:35:51.378796Z","shell.execute_reply":"2022-04-01T01:35:51.451131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = \\\n","  train_test_split(input_tensor, target_tensor, test_size=0.2)\n","\n","logging.info(\"There are {} sequences for training.\".format(len(input_tensor_train)))\n","logging.info(\"There are {} sequences for validation.\".format(len(input_tensor_val)))"],"metadata":{"id":"z3rVOKDWkPjJ","execution":{"iopub.status.busy":"2022-04-01T01:35:51.453538Z","iopub.execute_input":"2022-04-01T01:35:51.454041Z","iopub.status.idle":"2022-04-01T01:35:51.499858Z","shell.execute_reply.started":"2022-04-01T01:35:51.454004Z","shell.execute_reply":"2022-04-01T01:35:51.499102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's examine the decoder first."],"metadata":{"id":"CBeDHQRFKM8y"}},{"cell_type":"code","source":["input_tensor_train[0]"],"metadata":{"id":"0E9_73FEKaXJ","execution":{"iopub.status.busy":"2022-04-01T01:35:51.501278Z","iopub.execute_input":"2022-04-01T01:35:51.501733Z","iopub.status.idle":"2022-04-01T01:35:51.512470Z","shell.execute_reply.started":"2022-04-01T01:35:51.501694Z","shell.execute_reply":"2022-04-01T01:35:51.511752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["target_tensor_train[0]"],"metadata":{"id":"3vYbV25KKeK0","execution":{"iopub.status.busy":"2022-04-01T01:35:51.514671Z","iopub.execute_input":"2022-04-01T01:35:51.515112Z","iopub.status.idle":"2022-04-01T01:35:51.522193Z","shell.execute_reply.started":"2022-04-01T01:35:51.515076Z","shell.execute_reply":"2022-04-01T01:35:51.521365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def decode(tokenizer, tensor):\n","  \"\"\"Decode the indices into the tokens.\"\"\"\n","  for t in tensor:\n","    if t != 0: print(\"  {} --> {}\".format(t, tokenizer.index_word[t]))\n","\n","print(\"Input (Spanish): Index to Word\")\n","decode(input_tokenizer, input_tensor_train[0])\n","print(\"\\nTarget (English): Index to Word\")\n","decode(target_tokenizer, target_tensor_train[0])"],"metadata":{"id":"iu3sdqaskPjQ","execution":{"iopub.status.busy":"2022-04-01T01:35:51.523689Z","iopub.execute_input":"2022-04-01T01:35:51.524207Z","iopub.status.idle":"2022-04-01T01:35:51.534540Z","shell.execute_reply.started":"2022-04-01T01:35:51.524170Z","shell.execute_reply":"2022-04-01T01:35:51.533461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Create a tf.data.Dataset\n","\n","Here we use the `tensorflow.data.Dataset.from_tensor_slices` APIs to warp the data (input sequence) and labeling (output sequence)."],"metadata":{"id":"NTyHIFyHkPjT"}},{"cell_type":"code","source":["BUFFER_SIZE = len(input_tensor_train)\n","BATCH_SIZE = 64\n","\n","dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train))\\\n","            .shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n","val_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val))\\\n","            .batch(BATCH_SIZE, drop_remainder=True)\n","dataset"],"metadata":{"id":"JQ8mqpNfkPjU","execution":{"iopub.status.busy":"2022-04-01T01:35:51.535440Z","iopub.execute_input":"2022-04-01T01:35:51.535617Z","iopub.status.idle":"2022-04-01T01:35:53.859742Z","shell.execute_reply.started":"2022-04-01T01:35:51.535593Z","shell.execute_reply":"2022-04-01T01:35:53.859004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's get the input and the output sequences first."],"metadata":{"id":"p0Ic-r5xNTi8"}},{"cell_type":"code","source":["example_input_batch, example_target_batch = next(iter(dataset))\n","logging.info(\"Input sequence's shape: {}\".format(example_input_batch.shape))\n","logging.info(\"Target sequence's shape: {}\".format(example_target_batch.shape))\n","\n","print(example_input_batch[0])\n","print(example_target_batch[0])"],"metadata":{"id":"-JDJfAY9kPjW","execution":{"iopub.status.busy":"2022-04-01T01:35:53.861095Z","iopub.execute_input":"2022-04-01T01:35:53.861714Z","iopub.status.idle":"2022-04-01T01:35:54.106459Z","shell.execute_reply.started":"2022-04-01T01:35:53.861672Z","shell.execute_reply":"2022-04-01T01:35:54.105305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["It's also allowed for decoding the data in the pipeline."],"metadata":{"id":"CEFHdlGMN1zJ"}},{"cell_type":"code","source":["' '.join([input_tokenizer.index_word[n] for n in example_input_batch[8].numpy() if n != 0]), \\\n","' '.join([target_tokenizer.index_word[n] for n in example_target_batch[8].numpy() if n != 0])"],"metadata":{"id":"OujBrnYWkPjd","execution":{"iopub.status.busy":"2022-04-01T01:35:54.107832Z","iopub.execute_input":"2022-04-01T01:35:54.108339Z","iopub.status.idle":"2022-04-01T01:35:54.117209Z","shell.execute_reply.started":"2022-04-01T01:35:54.108296Z","shell.execute_reply":"2022-04-01T01:35:54.116504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Seq2Seq Model with the Attention\n","\n","The seq2seq model basically consists of two parts, one is the encoder, and the other is the decoder. The encoder encodes the raw text into a intermediate matrix, the decoder decodes the sequence from the matrix."],"metadata":{"id":"n9jCJdnBK2vG"}},{"cell_type":"markdown","source":["### Encoder\n","\n","The encoder, the blue part of the below image, does:\n","\n","- Take a list of token IDs. (from the previous dataset pipeline)\n","- Look up an embedding vector for each token (here is tf.keras.layers.Embedding)\n","- Process the embeddings into a new sequence (here using a layers.GPU)\n","\n",", and returns:\n","\n","- The processed sequence for the attention head.\n","- The state for initializing the decoder."],"metadata":{"id":"TUDrZwYOLtI7"}},{"cell_type":"code","source":["class Encoder(tf.keras.Model):\n","  \"\"\"Define the Encoder model.\"\"\"\n","\n","  def __init__(self, vocab_size, embedding_dim, enc_units, batch_size):\n","    super(Encoder, self).__init__()\n","    self.batch_size = batch_size\n","    self.enc_units = enc_units\n","    self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size, \n","                                               output_dim=embedding_dim)\n","    self.gru = tf.keras.layers.GRU(units=enc_units, \n","                                   return_sequences=True, \n","                                   return_state=True, \n","                                   recurrent_initializer='glorot_uniform')\n","    \n","  def call(self, x, hidden):\n","    \"\"\"\n","    args:\n","      x: (batch_size, sequence_length)\n","      hidden: (batch_size, enc_units)\n","      \n","    returns:\n","      sequence_output: (batch_size, sequence_length, enc_units)\n","      final_state: (batch_size, enc_units)\n","    \"\"\"\n","    embed = self.embedding(x)\n","    sequence_output, final_state = self.gru(embed, initial_state=hidden)\n","    return sequence_output, final_state\n","\n","  def initial_hidden_state(self):\n","    \"\"\"Initialize the hidden state to all zeros.\"\"\"\n","    return tf.zeros((self.batch_size, self.enc_units))\n","\n","vocab_size_input = len(input_tokenizer.word_index) + 1\n","vocab_size_target = len(target_tokenizer.word_index) + 1\n","embedding_dim = 256\n","units = 1024\n","\n","encoder = Encoder(vocab_size_input, embedding_dim, units, BATCH_SIZE)"],"metadata":{"id":"DSn7Fo7lkPjq","execution":{"iopub.status.busy":"2022-04-01T01:35:54.118478Z","iopub.execute_input":"2022-04-01T01:35:54.120695Z","iopub.status.idle":"2022-04-01T01:35:54.155039Z","shell.execute_reply.started":"2022-04-01T01:35:54.120666Z","shell.execute_reply":"2022-04-01T01:35:54.154428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# sample input\n","sample_hidden = encoder.initial_hidden_state()\n","sequence_output, final_state = encoder(example_input_batch, sample_hidden)\n","\n","print('Encoder output shape (batch_size, sequence_length (variable, timestamp), units): {}'.format(sequence_output.shape))\n","print('Encoder hidden state shape (batch_size, units): {}'.format(final_state.shape))"],"metadata":{"id":"g6_xmcJwkPjt","execution":{"iopub.status.busy":"2022-04-01T01:35:54.156148Z","iopub.execute_input":"2022-04-01T01:35:54.156451Z","iopub.status.idle":"2022-04-01T01:35:55.275051Z","shell.execute_reply.started":"2022-04-01T01:35:54.156415Z","shell.execute_reply":"2022-04-01T01:35:55.274310Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Attention Mechanism\n","\n","Now let's take a look at the attention mechanism. Look at the below diagram, each input word taken by an encoder is assigned a weight by the attention mechanism that is used further by the decoder to predict the words in the sentence.\n","\n","![](https://www.tensorflow.org/images/seq2seq/attention_mechanism.jpg)\n","Refer to Tensorflow.Org (2020).\n","\n","**More specifically, the attention mechanism provides an idea of weighting the timestamp.** In an RNN model, a hidden state is a relationship between timestamps, it is generated after each iteration. \n","\n","First, the sequence generated from each iteration is in the shape of `(batch_size, sequence_length, hidden_state_size)`. \n","\n","The attention weights are randomly initialized on the shape of `(batch_size, sequence_length)` in batch data. It expands dimensions and repeats values alongside the final axis at the hidden state to become `(batch_size, sequence_length, hidden_state_size)`. \n","\n","Next, multiply the hidden state matrix and expanded attention matrix to get the new matrix which contains the information of time stamps. Sum this new matrix at the axis of timestamps to summarize overall impacts at hidden states (shape becomes `(batch_size, hidden_state_size)`). Such a summarized matrix is called `context vector`. \n","\n","This context vector could be further passed into an activation layer (normally a Tanh layer) to become an attention vector. \n","\n","This attention vector is further multiplied with the hidden state of the decoder to predict the words.\n","\n","More details and formulas as the below.\n","![](https://www.tensorflow.org/images/seq2seq/attention_equation_0.jpg)\n","![](https://www.tensorflow.org/images/seq2seq/attention_equation_1.jpg)\n","Refer to Tensorflow.Org (2020).\n","\n","The pseduo-code (refer to Tensorflow.Org (2020)):\n","\n","where\n","\n","- $s$ is the encoder index. In other words, $s$ stands for the timestamp.\n","- $t$ is the decoder index.\n","- $a_{ts}$ is the attention weights.\n","- $h_s$ is the sequence of encoder outputs being attented to (the attention `key` and `value` in transformer teminology)\n","- $h_t$ is the decoder state attending to the sequence (the attention `query` in transformer terminology)\n","- $c_t$ is the resulting context vector\n","- $a_t$ is the final output combining the `context` and `query`\n","\n","In details,\n","\n","* `attention weights = softmax(score, axis = 1)`. Softmax by default is applied on the last axis but here we want to apply it on the 1st axis, since the shape of score is `(batch_size, max_length, hidden_size)`. Max_length is the length of our input (for the timestamps). Since we are trying to assign a weight to each input, softmax should be applied on that axis.\n","\n","* `context vector = sum(attention weights * encoder outputs, axis = 1)`. Same reason as above for choosing axis as 1.\n","\n","* `merged vector = concat(embedding output, context vector)` This merged vector is then passed to the GRU (a gated RNNCell) layer.\n","\n","* The last is the `score` function. Its job is to calculate a scalar logit-score for each key-query pair. There are two common approaches.\n","You can use the `tf.keras.layers.Attention` for the multiplicative style, and the `tf.keras.layers.AdditiveAttention` for the additive style, in the Tensorflow."],"metadata":{"id":"Y9FkV-8GkPjf"}},{"cell_type":"markdown","source":["Next, you are going to build a Bahdanau attention layer."],"metadata":{"id":"XM9YBfaYkPjx"}},{"cell_type":"code","source":["class BahdanauAttention(tf.keras.layers.Layer):\n","  \"\"\"An Attention Layer\"\"\"\n","  def __init__(self, units):\n","    \"\"\"Constructor\n","    \n","    args:\n","      units: the potential number of timestamps\n","    \"\"\"\n","    super(BahdanauAttention, self).__init__()\n","    self.W1 = tf.keras.layers.Dense(units)\n","    self.W2 = tf.keras.layers.Dense(units)\n","    self.V = tf.keras.layers.Dense(1)\n","\n","  def call(self, query, values):\n","    \"\"\"call is the layer function\n","    \n","    args:\n","      query: the hidden state from the decoder, (batch_size, hidden_size == encoder_units)\n","      values: the encoder outputs with return_sequence=True\n","              (batch_size, sequence_length, encoder_units)\n","      \n","    returns:\n","      context_vector: (batch_size, units == hidden_size)\n","      attention_weights: (batch_size, max_length, 1)\n","    \"\"\"\n","    # hidden state shape == (batch size, hidden size)\n","    # to expand dimension at the time axis == (batch size, 1, hidden size)\n","    # perform this to calculate the score\n","    hidden_time_axis = tf.expand_dims(query, axis=1)\n","    \n","    # time addition (batch_size, sequence_length, units) == \\\n","    #               (batch_size, sequence_length, units) + (batch_size, 1, units)\n","    # score shape == (batch size, sequence_length, 1)\n","    addition = tf.nn.tanh(self.W1(values) + self.W2(hidden_time_axis))\n","    score = self.V(addition)\n","    \n","    # attention weights shape == (batch size, sequence_length, 1)\n","    attention_weights = tf.nn.softmax(score, axis=1)\n","    \n","    # context vector shape after sum == (batch_size, units == hidden_size)\n","    context_vector = attention_weights * values\n","    context_vector = tf.reduce_sum(context_vector, axis=1)\n","    \n","    return context_vector, attention_weights"],"metadata":{"id":"nOPr6fjzkPjy","execution":{"iopub.status.busy":"2022-04-01T01:35:55.276539Z","iopub.execute_input":"2022-04-01T01:35:55.276818Z","iopub.status.idle":"2022-04-01T01:35:55.286747Z","shell.execute_reply.started":"2022-04-01T01:35:55.276783Z","shell.execute_reply":"2022-04-01T01:35:55.285860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["attention_layer = BahdanauAttention(10)\n","context_vector, attention_weights = attention_layer(final_state, sequence_output)\n","\n","print(\"Context vector Shape (batch size, hidden size): {}\".format(context_vector.shape))\n","print(\"Attention Weights Shape (batch size, sequence length, 1): {}\".format(attention_weights.shape))"],"metadata":{"id":"jzfEsmIskPj1","execution":{"iopub.status.busy":"2022-04-01T01:35:55.288390Z","iopub.execute_input":"2022-04-01T01:35:55.288854Z","iopub.status.idle":"2022-04-01T01:35:56.148320Z","shell.execute_reply.started":"2022-04-01T01:35:55.288819Z","shell.execute_reply":"2022-04-01T01:35:56.147543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Decoder\n","\n","The decoder's job is to generate predictions for the next output token. (The decoder is the red part of the above image.)\n","\n","- The decoder receives the complete encoder output.\n","- Here we use the GRU layer to keep track of what it has generated so far.\n","- It uses it RNN output as the query to the attention over the encoder's output to produce the context vector.\n","- It combines the decoder's output with the context vector to generate the `attention vector`.\n","- It generates logit predictions for the next token based on `attention vector`."],"metadata":{"id":"fqHmcTQ-V8Se"}},{"cell_type":"code","source":["class Decoder(tf.keras.Model):\n","  \"\"\"Implement the decoder.\"\"\"\n","\n","  def __init__(self, vocab_size, embedding_dim, dec_units, batch_size):\n","    super(Decoder, self).__init__()\n","    self.dec_units = dec_units\n","    self.batch_size = batch_size\n","    self.embedding = tf.keras.layers.Embedding(\n","        input_dim=vocab_size, \n","        output_dim=embedding_dim)\n","    self.gru = tf.keras.layers.GRU(\n","        units=dec_units, \n","        return_sequences=True, \n","        return_state=True, \n","        recurrent_initializer='glorot_uniform')\n","    self.dense = tf.keras.layers.Dense(units=vocab_size)\n","    self.attention = BahdanauAttention(dec_units)\n","    \n","  def call(self, x, hidden, enc_output):\n","    \"\"\"\n","    args:\n","      x: (batch_size, 1) an input of the decoder, \n","         it is generated from the previous timestamp or the encoder at the beginning\n","      hidden: (batch_size, encoder_units)\n","         the hidden state from the previous timestamp or the encoder at the beginning\n","      enc_output: (batch_size, sequence_length, encoder_units)\n","    \"\"\"\n","    \n","    # the embedding features (batch_size, 1) => (batch_size, 1, embedding_dims)\n","    x = self.embedding(x)\n","    \n","    # context_vector: (batch_size, encoder_units == hidden_size)\n","    # attentions_weights: (batch_size, sequence_length, 1)\n","    context_vector, attention_weights = self.attention(hidden, enc_output)\n","    \n","    # (batch_size, 1, hidden_size + embedding_size)\n","    attention_vector = tf.concat([tf.expand_dims(context_vector, axis=1), x], axis=-1)\n","    \n","    # gru_seq: (batch_size, 1, dec_units)\n","    # gru_state: (batch_size dec_units)\n","    gru_seq, gru_state = self.gru(attention_vector)\n","    \n","    # shape: (batch_size, dec_units)\n","    gru_seq = tf.reshape(gru_seq, (-1, gru_seq.shape[2]))\n","    \n","    # results: (batch_size, vocab_size)\n","    results = self.dense(gru_seq)\n","    \n","    return results, gru_state, attention_weights"],"metadata":{"id":"-TpFZYmTkPj4","execution":{"iopub.status.busy":"2022-04-01T01:35:56.152868Z","iopub.execute_input":"2022-04-01T01:35:56.153358Z","iopub.status.idle":"2022-04-01T01:35:56.173731Z","shell.execute_reply.started":"2022-04-01T01:35:56.153320Z","shell.execute_reply":"2022-04-01T01:35:56.172922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's try some examples passed into the decoder."],"metadata":{"id":"7SjHvs4AkPj6"}},{"cell_type":"code","source":["decoder = Decoder(vocab_size_target, embedding_dim, units, BATCH_SIZE)\n","\n","decoder_output, decode_state, sample_attention = decoder(\n","  tf.random.uniform((BATCH_SIZE, 1)), final_state, sequence_output)\n","\n","print(\"Decoder output shape (batch_size, vocab_size): {}\".format(decoder_output.shape))\n","print(\"Decoder state shape (batch_size, decoder_units): {}\".format(decode_state.shape))\n","print(\"Attention Weights shape (batch_size, sequence_length, 1): {}\".format(sample_attention.shape))"],"metadata":{"id":"fh6c2j17kPj7","execution":{"iopub.status.busy":"2022-04-01T01:35:56.178367Z","iopub.execute_input":"2022-04-01T01:35:56.179047Z","iopub.status.idle":"2022-04-01T01:35:56.247413Z","shell.execute_reply.started":"2022-04-01T01:35:56.179011Z","shell.execute_reply":"2022-04-01T01:35:56.246668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"pO-BkAkunJoh"}},{"cell_type":"markdown","source":["## Define the Optimizer and the Loss Function"],"metadata":{"id":"ZTs0fJEmkPj-"}},{"cell_type":"markdown","source":["Here, we can address this problem (or training) as a classification issue. Further, we can use the `tf.keras.losses.SparseCategoricalCrossentropy` to calculate the loss value. In the loss function, we only calculate and add the loss of the target token.\n","\n","Here we use masking to hidden the padded token so that the `reduction` is set to `none` for `SparseCategoricalCrossentropy`."],"metadata":{"id":"uSUukthHkPj_"}},{"cell_type":"code","source":["optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","  from_logits=True, reduction='none')\n","\n","def loss_function(real, pred):\n","  \"\"\"Loss function with masking.\"\"\"\n","  \n","  mask = tf.math.logical_not(tf.math.equal(real, 0))\n","  loss = loss_object(real, pred)\n","    \n","  mask = tf.cast(mask, dtype=loss.dtype)\n","  loss *= mask\n","\n","  return tf.reduce_mean(loss)"],"metadata":{"id":"MC9DZYGmkPkA","execution":{"iopub.status.busy":"2022-04-01T01:35:56.251729Z","iopub.execute_input":"2022-04-01T01:35:56.252277Z","iopub.status.idle":"2022-04-01T01:35:56.264166Z","shell.execute_reply.started":"2022-04-01T01:35:56.252242Z","shell.execute_reply":"2022-04-01T01:35:56.263140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Define the callback for saving models."],"metadata":{"id":"wlqxo9GskPkD"}},{"cell_type":"code","source":["ckpt_dir = os.path.join('./train_ckpt')\n","ckpt_path = os.path.join(ckpt_dir, 'ckpt')\n","checkpoint = tf.train.Checkpoint(optimizer=optimizer, \n","                                 encoder=encoder, \n","                                 decoder=decoder)"],"metadata":{"id":"-31ayJGukPkF","execution":{"iopub.status.busy":"2022-04-01T01:35:56.272826Z","iopub.execute_input":"2022-04-01T01:35:56.273384Z","iopub.status.idle":"2022-04-01T01:35:56.283487Z","shell.execute_reply.started":"2022-04-01T01:35:56.273349Z","shell.execute_reply":"2022-04-01T01:35:56.282411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training Steps\n","\n","The following is the basic training flow of the NMT (or the seq2seq) model.\n","\n","1. Pass the input (a batch of text sequences) and an initialized hidden state into the encoder that returns encoder output and encoder statue.\n","2. The encoder output, encoder status and input of decoder (or a start token) are passed into the decoder that returns decoder results (or the vocabulary predictions), decoder status, and attention weights.\n","3. Continue passing both the decoder result and hidden status back to the decoder to generate next result.\n","\n","- Pass the decoder hidden status back to the decoder for the next prediction.\n","\n","- Use `Teacher forcing` to decide the next input to the decoder. (The `Teacher Forcing` is a method where the target word is passed as the next input to the decoder.)\n","\n","4. Calculate the gradients and an optimizer applies them to the trainable variables."],"metadata":{"id":"u-QdTGMHkPkI"}},{"cell_type":"code","source":["@tf.function\n","def train_step(inputs, targets, enc_hidden):\n","  \"\"\"train_step calculates the loss and apply it to variable using an optimizer\"\"\"\n","  loss = 0.0\n","\n","  with tf.GradientTape() as tape:\n","    encoder_output, encoder_state = \\\n","      encoder(inputs, enc_hidden, training=True)\n","    \n","    # the hidden state from the encoder is passed into the decoder as the hidden state at the beginning\n","    decoder_hidden = encoder_state \n","    \n","    # before training alongside the time axis, define the start token, (BATCH_SIZE, 1)\n","    decoder_inputs = tf.expand_dims([target_tokenizer.word_index['<start>']] * BATCH_SIZE, axis=-1)\n","    \n","    # the way implementing the `Teacher Forcing` method\n","    for t in range(1, targets.shape[1]):\n","      # predictions: (batch_size, vocab_size)\n","      predictions, decoder_hidden, _ = \\\n","        decoder(decoder_inputs, decoder_hidden, encoder_output, training=True)\n","      \n","      loss += loss_function(targets[:, t], predictions)\n","        \n","      # for the next timestamp\n","      decoder_inputs = tf.expand_dims(targets[:, t], 1)\n","\n","  batch_loss = loss / int(targets.shape[1])\n","  trainable_variables = encoder.trainable_variables + decoder.trainable_variables\n","    \n","  # TODO: why not use batch_loss\n","  gradients = tape.gradient(loss, trainable_variables)\n","  optimizer.apply_gradients(zip(gradients, trainable_variables))\n","\n","  return batch_loss"],"metadata":{"id":"ZMZpv2ubkPkJ","execution":{"iopub.status.busy":"2022-04-01T01:35:56.288176Z","iopub.execute_input":"2022-04-01T01:35:56.288526Z","iopub.status.idle":"2022-04-01T01:35:56.305308Z","shell.execute_reply.started":"2022-04-01T01:35:56.288493Z","shell.execute_reply":"2022-04-01T01:35:56.304182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@tf.function\n","def val_step(inputs, targets, enc_hidden):\n","  \"\"\"val_step calculates the loss to the validation step.\"\"\"\n","\n","  loss = 0.0\n","\n","  encoder_output, encoder_state = \\\n","    encoder(inputs, enc_hidden, training=False)\n","  decoder_hidden = encoder_state\n","  decoder_inputs = tf.expand_dims([target_tokenizer.word_index['<start>']] * BATCH_SIZE, axis=-1)\n","\n","  for t in range(1, targets.shape[1]):\n","    results, decoder_hidden, _ = \\\n","      decoder(decoder_inputs, decoder_hidden, encoder_output, training=False)\n","    loss += loss_function(targets[:, t], results)\n","\n","    best_predict_ids = tf.argmax(results, axis=1)\n","    decoder_inputs = tf.expand_dims(best_predict_ids, axis=-1)\n","  \n","  batch_loss = loss / targets.shape[0]\n","\n","  return batch_loss"],"metadata":{"id":"bL-cJY60uu_v","execution":{"iopub.status.busy":"2022-04-01T01:35:56.310417Z","iopub.execute_input":"2022-04-01T01:35:56.310767Z","iopub.status.idle":"2022-04-01T01:35:56.325279Z","shell.execute_reply.started":"2022-04-01T01:35:56.310733Z","shell.execute_reply":"2022-04-01T01:35:56.324355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["EPOCHS = 10\n","steps_per_epoch = len(input_tensor_train) // BATCH_SIZE\n","\n","for epoch in range(EPOCHS):\n","    \n","  enc_hidden = encoder.initial_hidden_state()\n","\n","  total_loss = 0.\n","  for (idx, (inputs, targets)) in enumerate(dataset.take(steps_per_epoch)):\n","    batch_loss = train_step(inputs, targets, enc_hidden)\n","    total_loss += batch_loss\n","    \n","    if (idx + 1) % 400 == 0:\n","      print(\"  Epoch {}, Batch: {}, Loss: {:.8f}\".format(\n","        epoch + 1, idx + 1, batch_loss))\n","  \n","  # saving the model every 2 epochs\n","  if (epoch + 1) % 2 == 0:\n","    checkpoint.save(file_prefix=ckpt_path)\n","\n","  val_loss = 0.\n","  for idx, (inputs, targets) in enumerate(val_dataset.take(steps_per_epoch)):\n","    batch_loss = val_step(inputs, targets, enc_hidden)\n","    val_loss += batch_loss\n","\n","  print(\"Epoch {}, Loss: {:.6f}, Val Loss: {:.6f}\".format(\n","    epoch+1, total_loss / steps_per_epoch, val_loss / steps_per_epoch))"],"metadata":{"id":"f1-GDAwTkPkM","execution":{"iopub.status.busy":"2022-04-01T01:35:56.330487Z","iopub.execute_input":"2022-04-01T01:35:56.330919Z","iopub.status.idle":"2022-04-01T03:25:16.721792Z","shell.execute_reply.started":"2022-04-01T01:35:56.330884Z","shell.execute_reply":"2022-04-01T03:25:16.720769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Translation\n","\n","* The translation is a series of predictions and is similar to the training loop, but is different from it on no the teacher forcing method involved. The input to the decoder at each time is the output from the previous prediction along with its hidden status and encoder output.\n","* Stop prediction when reaching the end token.\n","* We can also store the attention weights for each time prediction.\n","\n","Now let's translate from Spanish (input) to English (target) using the model."],"metadata":{"id":"SNeQONbckPkS"}},{"cell_type":"code","source":["def generate(sentence):\n","  \"\"\"Translate a sentence.\"\"\"\n","  input_length = max_length_input\n","  target_length = max_length_target\n","  attention_plots = np.zeros((target_length, input_length))\n","  \n","  # preprocess sentence\n","  sentence = preprocess_sentence(sentence)\n","  inputs = [input_tokenizer.word_index[i] for i in sentence.split(' ')]\n","  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=input_length, padding=\"post\")\n","  inputs = tf.convert_to_tensor(inputs)\n","\n","  # store the result\n","  result = ''\n","\n","  hidden = tf.zeros((1, units))  # (batch_size, hidden_size): (1, 1024)\n","  enc_output, enc_hidden = encoder(inputs, hidden, training=False)\n","  dec_hidden = enc_hidden\n","  dec_input = tf.expand_dims([target_tokenizer.word_index['<start>']], axis=0)  # (batch_size, sequence_length), (1, 1)\n","\n","  for t in range(target_length):\n","    predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_output, training=False)\n","    \n","    # storing the attention weights\n","    attention_weights = tf.reshape(attention_weights, (-1, )) \n","    attention_plots[t] = attention_weights.numpy()\n","    \n","    # predicted id, [0] to get the element\n","    prediced_id = tf.argmax(predictions, axis=-1).numpy()[0]\n","    result += target_tokenizer.index_word[prediced_id] + \" \"\n","    \n","    if target_tokenizer.index_word[prediced_id] == \"<end>\":\n","      break\n","    \n","    # continue predicting the word\n","    dec_input = tf.expand_dims([prediced_id], axis=0)\n","  return result, sentence, attention_plots"],"metadata":{"id":"mg_xNai-kPkT","execution":{"iopub.status.busy":"2022-04-01T03:25:16.723265Z","iopub.execute_input":"2022-04-01T03:25:16.723467Z","iopub.status.idle":"2022-04-01T03:25:16.736248Z","shell.execute_reply.started":"2022-04-01T03:25:16.723442Z","shell.execute_reply":"2022-04-01T03:25:16.735565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_attention(attention, sentence, predicted_sentence):\n","  \"\"\"plot for attention\"\"\"\n","  fig = plt.figure(figsize=(8, 8))\n","  ax = fig.add_subplot(1,1,1)\n","  ax.matshow(attention, cmap=\"viridis\")\n","  ax.set_xticklabels([''] + sentence, rotation=90)\n","  ax.set_yticklabels([''] + predicted_sentence)\n","  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n","  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n","  plt.show()"],"metadata":{"id":"Q4j-rTUCkPkY","execution":{"iopub.status.busy":"2022-04-01T03:25:16.737512Z","iopub.execute_input":"2022-04-01T03:25:16.737852Z","iopub.status.idle":"2022-04-01T03:25:16.748728Z","shell.execute_reply.started":"2022-04-01T03:25:16.737798Z","shell.execute_reply":"2022-04-01T03:25:16.747985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def translate(sentence):\n","  result, sentence, attention_plots = generate(sentence)\n","\n","  print(\"Input: {}\".format(sentence))\n","  print(\"Translation: {}\".format(result))\n","\n","  attention_plot = attention_plots[:len(result.split(' ')), :len(sentence.split(' '))]\n","  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"],"metadata":{"id":"QOCkEE2QkPka","execution":{"iopub.status.busy":"2022-04-01T03:25:16.749999Z","iopub.execute_input":"2022-04-01T03:25:16.750308Z","iopub.status.idle":"2022-04-01T03:25:16.757425Z","shell.execute_reply.started":"2022-04-01T03:25:16.750273Z","shell.execute_reply":"2022-04-01T03:25:16.756671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Restore the Latest Checkpoint"],"metadata":{"id":"gKVVhCEmkPkd"}},{"cell_type":"code","source":["checkpoint.restore(tf.train.latest_checkpoint(ckpt_dir))"],"metadata":{"id":"QRvXjU_SkPkd","execution":{"iopub.status.busy":"2022-04-01T03:25:16.758945Z","iopub.execute_input":"2022-04-01T03:25:16.759280Z","iopub.status.idle":"2022-04-01T03:25:17.069265Z","shell.execute_reply.started":"2022-04-01T03:25:16.759244Z","shell.execute_reply":"2022-04-01T03:25:17.068575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translate(u\"hace mucho frio aqui.\")"],"metadata":{"id":"bVJ5IPjQkPkh","execution":{"iopub.status.busy":"2022-04-01T03:25:17.070560Z","iopub.execute_input":"2022-04-01T03:25:17.070840Z","iopub.status.idle":"2022-04-01T03:25:17.409812Z","shell.execute_reply.started":"2022-04-01T03:25:17.070806Z","shell.execute_reply":"2022-04-01T03:25:17.409019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translate(u'多todavia estan en casa?')"],"metadata":{"id":"caUA2uPGkPkm","execution":{"iopub.status.busy":"2022-04-01T03:25:17.411015Z","iopub.execute_input":"2022-04-01T03:25:17.411267Z","iopub.status.idle":"2022-04-01T03:25:18.424372Z","shell.execute_reply.started":"2022-04-01T03:25:17.411227Z","shell.execute_reply":"2022-04-01T03:25:18.423312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# wrong translation (Try to find out.)\n","translate(u'trata de averiguarlo.')"],"metadata":{"id":"XJnqaYDKkPkp","execution":{"iopub.status.busy":"2022-04-01T03:25:18.429796Z","iopub.execute_input":"2022-04-01T03:25:18.430140Z","iopub.status.idle":"2022-04-01T03:25:18.754338Z","shell.execute_reply.started":"2022-04-01T03:25:18.430093Z","shell.execute_reply":"2022-04-01T03:25:18.753621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"VDWMXaVgKe9d"},"execution_count":null,"outputs":[]}]}